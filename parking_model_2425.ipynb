{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from sqlalchemy import null\n",
    "from datetime import datetime\n",
    "\n",
    "from prefect.blocks.system import Secret\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rates by tier and lot\n",
    "\n",
    "q = \"\"\"\n",
    "with prepaid as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         location_group\n",
    "    from\n",
    "        custom.ctp_v_ticket_2324\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    from\n",
    "        custom.ctp_v_ticket_2425\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date),\n",
    "prepaid_agg as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        count(*) as prepaid_passes\n",
    "    from\n",
    "        prepaid\n",
    "    group by\n",
    "        event_datetime, location_group),\n",
    "scans as\n",
    "    (select\n",
    "        season,\n",
    "        cth_game_descriptions.event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "            else 0 end as num_scans\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        cth_game_descriptions.event_datetime is not Null\n",
    "        and season in ('2023-24','2024-25')),\n",
    "scans_agg as\n",
    "    (select\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        sum(num_scans) as num_scans\n",
    "    from\n",
    "        scans\n",
    "    group by\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group)\n",
    "select\n",
    "    season,\n",
    "    prepaid_agg.event_datetime,\n",
    "    tier,\n",
    "    prepaid_agg.location_group,\n",
    "    prepaid_passes,\n",
    "    num_scans,\n",
    "    num_scans*1.0/prepaid_passes::float as show_rate\n",
    "from\n",
    "    scans_agg\n",
    "left join\n",
    "    prepaid_agg on scans_agg.event_datetime = prepaid_agg.event_datetime\n",
    "    and scans_agg.location_group = prepaid_agg.location_group\n",
    "where\n",
    "    prepaid_agg.event_datetime is not Null\n",
    "\"\"\"\n",
    "\n",
    "show_rate_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_34552\\3821290929.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# weigh this past season more heavily\n",
    "\n",
    "weights = {'2023-24':1.25,'2024-25':2.75}\n",
    "\n",
    "show_rate_df['weights'] = show_rate_df['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical prepaid parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with prepaid as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         location_group,\n",
    "         date(transaction_date) as transaction_date\n",
    "    from\n",
    "        custom.ctp_v_ticket_2324\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        date(transaction_date) as transaction_date\n",
    "    from\n",
    "        custom.ctp_v_ticket_2425\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date)\n",
    "select\n",
    "    date(event_datetime) as event_date,\n",
    "    location_group,\n",
    "    'prepaid' as parking_type,\n",
    "    datediff('days',transaction_date, event_datetime) as days_out,\n",
    "    case\n",
    "        when days_out >= 150 then 0\n",
    "        else count(*) \n",
    "    end as num_passes\n",
    "from\n",
    "    prepaid\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    event_datetime,\n",
    "    location_group,\n",
    "    transaction_date\n",
    "order by\n",
    "    event_datetime,\n",
    "    location_group,\n",
    "    transaction_date desc\n",
    "\"\"\"\n",
    "\n",
    "historical_prepaid_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "location_map = {\n",
    "    'Club': 4,\n",
    "    'Garage': 3,\n",
    "    'General': 2,\n",
    "    'Valet': 1\n",
    "}\n",
    "\n",
    "historical_prepaid_parking_info['location_num'] = historical_prepaid_parking_info.apply(\n",
    "    lambda row: location_map.get(row['location_group'], 0), axis=1)\n",
    "\n",
    "historical_prepaid_parking_info['cumulative_num_passes']  = historical_prepaid_parking_info.groupby(['event_date', 'location_group'])['num_passes'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical game data (ie tier, dow, and start time)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    date(cth_game_descriptions.event_date) as event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    total_tickets\n",
    "FROM\n",
    "    custom.cth_v_historical_attendance_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions on cth_v_historical_attendance_summary.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    tier in ('A','B','C','D','E')\n",
    "\"\"\"\n",
    "\n",
    "all_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "all_game_info['weekend'] = all_game_info.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "all_game_info['start_time_num'] = all_game_info.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming game data including current prepaid totals by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "select\n",
    "    date(cth_game_descriptions.event_datetime) as event_date,\n",
    "    datediff('day', current_date, cth_game_descriptions.event_datetime) as days_out,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity::int,\n",
    "    sum(paid_seats)+sum(comp_seats) as prepaid_cars,\n",
    "    sum(gross_revenue) as current_gross_revenue,\n",
    "    capacity::int - prepaid_cars as cap_remaining\n",
    "from\n",
    "    custom.ctp_v_ticket_2425\n",
    "left join\n",
    "    custom.ctp_parking_capacities on ctp_v_ticket_2425.location_group = ctp_parking_capacities.location_group\n",
    "left join\n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "where\n",
    "    cth_game_descriptions.event_datetime is not null and\n",
    "    cth_game_descriptions.event_datetime >= current_date\n",
    "group by\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity\n",
    "order by\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group\n",
    "\"\"\"\n",
    "\n",
    "upcoming_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming pricing data by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    tier,\n",
    "    location_group,\n",
    "    max(transaction_date) AS \"transaction_date\",\n",
    "    max(adjusted_price) AS \"highest_price\"\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN             \n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    is_comp = FALSE\n",
    "    AND price_type ILIKE 'IA%'\n",
    "GROUP BY\n",
    "    tier, \n",
    "    location_group\n",
    "\"\"\"\n",
    "\n",
    "pricing_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict remaining prepaid cars\n",
    "\n",
    "def run_prepaid_model(df, df_future, lot):\n",
    "\n",
    "    total_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = total_table[['days_out','weekend','start_time_num']]\n",
    "    y_train = total_table[['cumulative_num_passes']]\n",
    "\n",
    "    total_future_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = total_future_table[['days_out','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_table = historical_prepaid_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_table = total_table[total_table['tier'].isin(['A','B','C','D','E'])]\n",
    "\n",
    "# merge upcoming parking data with hisorical game data for testing model\n",
    "\n",
    "total_future_table = upcoming_game_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_future_table = total_future_table[total_future_table['tier'].isin(['A','B','C','D','E'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general and garage not  club, valet or executive\n",
    "\n",
    "lots = ['General','Garage']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = total_future_table[total_future_table['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
    "\n",
    "    final_df = pd.concat([final_df,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\1184624018.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  club_totals['predicted_parking'] = 0\n"
     ]
    }
   ],
   "source": [
    "# concat club totals for onsite model next\n",
    "\n",
    "club_totals = total_future_table[total_future_table['location_group'] == 'Club']\n",
    "club_totals['predicted_parking'] = 0\n",
    "\n",
    "final_df = pd.concat([final_df, club_totals], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no negative predictions are made\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['predicted_parking'] < 0, 0, final_df['predicted_parking'])\n",
    "\n",
    "# get total prepaid tickets (current + predicted additional)\n",
    "\n",
    "final_df['total_predicted_prepaid_cars'] = final_df['prepaid_cars'] + final_df['predicted_parking']\n",
    "\n",
    "# get number of parked cars using historical show rates\n",
    "\n",
    "final_df = final_df.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "final_df['prepaid_cars_parked'] = (final_df['total_predicted_prepaid_cars'] * final_df['weighted_average']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the capacity remaining \n",
    "\n",
    "final_df['cap_remaining'] = final_df['capacity'] - final_df['prepaid_cars_parked']\n",
    "\n",
    "# if predicted cars over capacity subtract overflow out\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['cap_remaining'] < 0, final_df['predicted_prepaid_additional_parking']+final_df['cap_remaining'], final_df['predicted_prepaid_additional_parking'])\n",
    "final_df['prepaid_cars_parked'] = np.where(final_df['cap_remaining'] < 0, final_df['prepaid_cars_parked']+final_df['cap_remaining'], final_df['prepaid_cars_parked'])\n",
    "final_df['cap_remaining'] = np.where(final_df['cap_remaining'] < 0, 0, final_df['prepaid_cars_parked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['event_date','days_out','tier', 'start_time_num','weekend',\n",
    "                     'location_group','capacity','prepaid_cars','current_gross_revenue', \n",
    "                     'predicted_prepaid_additional_parking', 'total_predicted_prepaid_cars',\n",
    "                     'prepaid_cars_parked','cap_remaining']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hisotrical onsite parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with onsite as\n",
    "    (select\n",
    "        date(cth_game_descriptions.event_datetime) as event_date,\n",
    "        location_group,\n",
    "        0 as days_out,\n",
    "        case\n",
    "            when paid_amount > 0 then 1\n",
    "        else 0\n",
    "        end as num_onsite_cars,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "        else 0\n",
    "        end as num_prepaid_cars\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        season in ('2023-24','2024-25'))\n",
    "select\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    'onsite' as parking_type,\n",
    "    days_out,\n",
    "    sum(num_onsite_cars) as num_cars,\n",
    "    capacity - sum(num_prepaid_cars) as cap_remaining\n",
    "from\n",
    "    onsite\n",
    "left join\n",
    "    custom.ctp_parking_capacities on onsite.location_group = ctp_parking_capacities.location_group\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    parking_type,\n",
    "    days_out,\n",
    "    capacity\n",
    "\"\"\"\n",
    "\n",
    "historical_onsite_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_onsite_table = historical_onsite_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_onsite_table = total_onsite_table[total_onsite_table['tier'].isin(['A','B','C','D','E'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict onsite cars\n",
    "\n",
    "def run_onsite_model(df, df_future, lot):\n",
    "\n",
    "    x_train_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = x_train_table[['cap_remaining','weekend','start_time_num']]\n",
    "    y_train = x_train_table[['num_cars']]\n",
    "\n",
    "    x_test_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = x_test_table[['cap_remaining','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    #predicted_test = polynomial.predict(poly_features2)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general, garage, and club not valet or executive\n",
    "\n",
    "lots = ['General','Garage','Club']\n",
    "\n",
    "final_df_onsite = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = final_df[final_df['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
    "\n",
    "    final_df_onsite = pd.concat([final_df_onsite,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\3926685836.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_24804\\3926685836.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n"
     ]
    }
   ],
   "source": [
    "# add back executive and valet parking and match fields from final_df\n",
    "\n",
    "exec_and_valet = total_future_table[total_future_table['location_group'].isin(['Executive','Valet'])]\n",
    "\n",
    "exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
    "exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n",
    "\n",
    "exec_and_valet = exec_and_valet.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "exec_and_valet['weighted_average'] = exec_and_valet['weighted_average'].fillna(1)\n",
    "\n",
    "exec_and_valet['prepaid_cars_parked'] = (exec_and_valet['total_predicted_prepaid_cars'] * exec_and_valet['weighted_average']).astype(int)\n",
    "exec_and_valet['predicted_onsite_parking'] = 0\n",
    "exec_and_valet['total_parking'] = exec_and_valet['prepaid_cars_parked'] \n",
    "\n",
    "exec_and_valet = exec_and_valet[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked',\n",
    "                                       'predicted_onsite_parking','total_parking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if predicted total over capacity subtract overflow out\n",
    "\n",
    "final_df_onsite['predicted_onsite_parking'] = [pred_onsite if pred_onsite <= cap_remaining else cap_remaining for pred_onsite, cap_remaining in zip(final_df_onsite['predicted_onsite_parking'], final_df_onsite['cap_remaining'])]\n",
    "\n",
    "final_df_onsite['total_parking'] = final_df_onsite['prepaid_cars_parked'] + final_df_onsite['predicted_onsite_parking']\n",
    "\n",
    "final_parking_model = final_df_onsite[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking','total_predicted_prepaid_cars',\n",
    "                                       'prepaid_cars_parked','predicted_onsite_parking','total_parking']]\n",
    "\n",
    "# merge with executive and valet parking info\n",
    "\n",
    "final_parking_model_df = pd.concat([final_parking_model, exec_and_valet], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parking_model_df = final_parking_model_df.merge(pricing_info, how = 'left', on = ['tier', 'location_group'])\n",
    "\n",
    "final_parking_model_df['predicted_prepaid_additional_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_onsite_parking_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']*1.25).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_gross_revenue'] = final_parking_model_df['predicted_prepaid_additional_gross_revenue'] + final_parking_model_df['predicted_onsite_parking_gross_revenue'] + final_parking_model_df['current_gross_revenue']\n",
    "\n",
    "final_parking_model_df = final_parking_model_df[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking', 'predicted_prepaid_additional_gross_revenue',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked', 'predicted_onsite_parking',\n",
    "                                       'predicted_onsite_parking_gross_revenue','total_parking', 'predicted_gross_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_parking_model_df.to_csv('C:\\\\Users\\\\riffere\\\\Desktop\\\\output_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_parking</th>\n",
       "      <th>predicted_gross_revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-07</th>\n",
       "      <td>4202</td>\n",
       "      <td>87673.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-09</th>\n",
       "      <td>4587</td>\n",
       "      <td>107245.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-12</th>\n",
       "      <td>4170</td>\n",
       "      <td>86573.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>4168</td>\n",
       "      <td>86232.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-16</th>\n",
       "      <td>4682</td>\n",
       "      <td>104848.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-23</th>\n",
       "      <td>4571</td>\n",
       "      <td>107990.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-25</th>\n",
       "      <td>4206</td>\n",
       "      <td>89693.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-27</th>\n",
       "      <td>4698</td>\n",
       "      <td>105043.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-30</th>\n",
       "      <td>4561</td>\n",
       "      <td>109048.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-07</th>\n",
       "      <td>4609</td>\n",
       "      <td>109920.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20</th>\n",
       "      <td>4283</td>\n",
       "      <td>94022.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>4746</td>\n",
       "      <td>110699.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-28</th>\n",
       "      <td>4568</td>\n",
       "      <td>114284.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>4544</td>\n",
       "      <td>113519.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02</th>\n",
       "      <td>4241</td>\n",
       "      <td>95777.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03</th>\n",
       "      <td>4331</td>\n",
       "      <td>97725.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11</th>\n",
       "      <td>4872</td>\n",
       "      <td>117820.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16</th>\n",
       "      <td>4303</td>\n",
       "      <td>99854.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-18</th>\n",
       "      <td>4680</td>\n",
       "      <td>118374.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29</th>\n",
       "      <td>4308</td>\n",
       "      <td>102407.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>4735</td>\n",
       "      <td>121593.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-02</th>\n",
       "      <td>4721</td>\n",
       "      <td>122288.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-08</th>\n",
       "      <td>4786</td>\n",
       "      <td>120992.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-22</th>\n",
       "      <td>4727</td>\n",
       "      <td>126027.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27</th>\n",
       "      <td>4364</td>\n",
       "      <td>109613.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>4782</td>\n",
       "      <td>126963.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03</th>\n",
       "      <td>4746</td>\n",
       "      <td>125108.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-06</th>\n",
       "      <td>4363</td>\n",
       "      <td>108640.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-08</th>\n",
       "      <td>4758</td>\n",
       "      <td>128863.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-23</th>\n",
       "      <td>4779</td>\n",
       "      <td>132951.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28</th>\n",
       "      <td>4476</td>\n",
       "      <td>114007.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-30</th>\n",
       "      <td>4966</td>\n",
       "      <td>132733.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-08</th>\n",
       "      <td>4951</td>\n",
       "      <td>132550.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-10</th>\n",
       "      <td>4446</td>\n",
       "      <td>116919.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-12</th>\n",
       "      <td>4809</td>\n",
       "      <td>136916.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-14</th>\n",
       "      <td>4953</td>\n",
       "      <td>134524.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_parking  predicted_gross_revenue\n",
       "event_date                                        \n",
       "2024-11-07           4202                 87673.26\n",
       "2024-11-09           4587                107245.53\n",
       "2024-11-12           4170                 86573.29\n",
       "2024-11-14           4168                 86232.98\n",
       "2024-11-16           4682                104848.81\n",
       "2024-11-23           4571                107990.18\n",
       "2024-11-25           4206                 89693.00\n",
       "2024-11-27           4698                105043.06\n",
       "2024-11-30           4561                109048.28\n",
       "2024-12-07           4609                109920.15\n",
       "2024-12-20           4283                 94022.40\n",
       "2024-12-23           4746                110699.83\n",
       "2024-12-28           4568                114284.75\n",
       "2024-12-30           4544                113519.51\n",
       "2025-01-02           4241                 95777.65\n",
       "2025-01-03           4331                 97725.59\n",
       "2025-01-11           4872                117820.97\n",
       "2025-01-16           4303                 99854.82\n",
       "2025-01-18           4680                118374.37\n",
       "2025-01-29           4308                102407.15\n",
       "2025-02-01           4735                121593.01\n",
       "2025-02-02           4721                122288.10\n",
       "2025-02-08           4786                120992.13\n",
       "2025-02-22           4727                126027.17\n",
       "2025-02-27           4364                109613.18\n",
       "2025-03-01           4782                126963.53\n",
       "2025-03-03           4746                125108.29\n",
       "2025-03-06           4363                108640.49\n",
       "2025-03-08           4758                128863.65\n",
       "2025-03-23           4779                132951.13\n",
       "2025-03-28           4476                114007.38\n",
       "2025-03-30           4966                132733.96\n",
       "2025-04-08           4951                132550.99\n",
       "2025-04-10           4446                116919.84\n",
       "2025-04-12           4809                136916.11\n",
       "2025-04-14           4953                134524.74"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_parking_model_df.groupby(by = 'event_date').sum()[['total_parking', 'predicted_gross_revenue']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

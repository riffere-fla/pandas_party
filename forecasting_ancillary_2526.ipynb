{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e96dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from prefect import flow, task\n",
    "from prefect.blocks.system import Secret\n",
    "\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6d2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e566cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf93083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_historical(redshift_credentials: Dict) -> pd.DataFrame:\n",
    "\n",
    "    q = \"\"\"\n",
    "        WITH attendance AS\n",
    "            (SELECT\n",
    "                event_datetime,\n",
    "                COUNT(*) AS attendance\n",
    "            FROM\n",
    "                custom.cth_v_attendance_2425\n",
    "            GROUP BY\n",
    "                event_datetime)\n",
    "        SELECT\n",
    "            cth_game_descriptions.season,\n",
    "            cth_game_descriptions.event_date,\n",
    "            tier,\n",
    "            day_of_week,\n",
    "            start_time,\n",
    "            attendance,\n",
    "            SUM(gross_revenue) AS gross_revenue,\n",
    "            SUM(qty) AS quantity,\n",
    "            COUNT(distinct invoice_id) AS num_orders,\n",
    "            (SUM(gross_revenue)/attendance)/11.91 AS multiplier\n",
    "        FROM\n",
    "            custom.retailpro_v_invoice_items\n",
    "        LEFT JOIN\n",
    "            custom.cth_game_descriptions ON retailpro_v_invoice_items.event_date = cth_game_descriptions.event_date\n",
    "        LEFT JOIN\n",
    "            attendance ON retailpro_v_invoice_items.event_date = date(attendance.event_datetime)\n",
    "        WHERE\n",
    "            season IN ('2024-25')\n",
    "            AND tier IN ('A','B','C','D','E')\n",
    "        GROUP BY\n",
    "            cth_game_descriptions.season,\n",
    "            cth_game_descriptions.event_date,\n",
    "            tier,\n",
    "            is_premier,\n",
    "            original_six_plus_extra,\n",
    "            day_of_week,\n",
    "            start_time,\n",
    "            attendance\n",
    "    \"\"\"\n",
    "\n",
    "    return FLA_Redshift(**redshift_credentials).query_warehouse(sql_string=q)\n",
    "\n",
    "@task(log_prints = True)\n",
    "def extract_upcoming(redshift_credentials: Dict) -> pd.DataFrame:\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "        season,\n",
    "        date(cth_game_descriptions.event_date) AS event_date,\n",
    "        day_of_week,\n",
    "        cth_game_descriptions.tier,\n",
    "        start_time,\n",
    "        predicted_turnstile\n",
    "    FROM\n",
    "        custom.cth_game_descriptions\n",
    "    LEFT JOIN\n",
    "        custom.forecasting_hockey_turnstile_2425_playoffs on cth_game_descriptions.event_date = forecasting_hockey_turnstile_2425_playoffs.event_date\n",
    "    WHERE\n",
    "        cth_game_descriptions.event_date >= current_date\n",
    "    \"\"\"\n",
    "\n",
    "    return FLA_Redshift(**redshift_credentials).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    def create_start_time_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Define the dictionary with lists of start times\n",
    "        lookup = {\n",
    "            1: ['12:30 PM', '12:45 PM', '1:00 PM', '3:00 PM', '3:30 PM'],\n",
    "            2: ['4:00 PM', '5:00 PM', '6:00 PM']\n",
    "        }\n",
    "\n",
    "        # Default to 0 for any start time not in the lookup\n",
    "        df['start_time_num'] = 0\n",
    "        for key, times in lookup.items():\n",
    "            df.loc[df['start_time'].isin(times), 'start_time_num'] = key\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def create_tier_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # lookup = {\n",
    "        #     'SC': 4,\n",
    "        #     'R3': 3,\n",
    "        #     'R2': 2,\n",
    "        #     'R1': 1\n",
    "        # }\n",
    "\n",
    "        # df['tier_num'] = 0\n",
    "        # for key, value in lookup.items():\n",
    "        #     df.loc[df['tier'] == key, 'tier_num'] = value\n",
    "\n",
    "        df = pd.get_dummies(df, columns=['tier'], prefix = '', prefix_sep = '')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def create_weekend_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        lookup = {\n",
    "                'Fri': 1,\n",
    "                'Sat': 1,\n",
    "                'Sun': 1,\n",
    "                'Mon': 0,\n",
    "                'Tue': 0,\n",
    "                'Wed': 0,\n",
    "                'Thu': 0\n",
    "        }\n",
    "\n",
    "        for key, value in lookup.items():\n",
    "            df.loc[df['day_of_week'] == key, 'weekend_num'] = value\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = create_start_time_num(df)\n",
    "    df = create_tier_num(df)\n",
    "    df = create_weekend_num(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_atp = 11.91\n",
    "\n",
    "def run_model(df: pd.DataFrame, df_future: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    x_train = df[['attendance','weekend_num','start_time_num','tier_num']]\n",
    "    y_train = df[['multiplier']]\n",
    "\n",
    "    x_test = df_future[['predicted_turnstile','weekend_num','start_time_num','tier_num']]\n",
    "\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    poly_features_2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features_2).astype(int)\n",
    "\n",
    "def get_predictions(df_historical: pd.DataFrame, df_upcoming: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df_historical['predicted_gross_revenue'] = df_historical['gross_revenue'].fillna(0)\n",
    "    df_upcoming['predicted_gross_revenue'] = run_model(df_historical, df_upcoming)\n",
    "\n",
    "    df = pd.concat([df_historical, df_upcoming], axis=0, ignore_index=True)\n",
    "\n",
    "    df = df[df['season'] == '2024-25']\n",
    "    df = df.rename(columns={'gross_revenue': 'current_gross_revenue'})\n",
    "\n",
    "    df = df[[\n",
    "        'event_date',\n",
    "        'attendance',\n",
    "        'current_gross_revenue',\n",
    "        'predicted_gross_revenue'\n",
    "    ]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6beb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_historical(redshift_credentials: Dict) -> pd.DataFrame:\n",
    "\n",
    "    q = \"\"\"\n",
    "        WITH attendance AS (\n",
    "            SELECT\n",
    "                event_datetime,\n",
    "                COUNT(*) AS attendance\n",
    "            FROM\n",
    "                custom.cth_v_attendance_2425\n",
    "            GROUP BY\n",
    "                event_datetime\n",
    "        )\n",
    "        SELECT\n",
    "            cth_game_descriptions.season,\n",
    "            cth_game_descriptions.event_date,\n",
    "            tier,\n",
    "            day_of_week,\n",
    "            start_time,\n",
    "            attendance,\n",
    "            gross_revenue,\n",
    "            num_orders,\n",
    "            quantity_sold,\n",
    "            (gross_revenue/attendance)/26.84 AS multiplier\n",
    "        FROM\n",
    "            custom.cheq_v_hockey_summary\n",
    "        LEFT JOIN\n",
    "            custom.cth_game_descriptions\n",
    "            ON DATE(cheq_v_hockey_summary.event_date) = DATE(cth_game_descriptions.event_date)\n",
    "        LEFT JOIN\n",
    "            attendance\n",
    "            ON DATE(attendance.event_datetime) = DATE(cheq_v_hockey_summary.event_date)\n",
    "        WHERE\n",
    "            tier IN ('A','B','C','D','E')\n",
    "            AND cth_game_descriptions.season = '2024-25'\n",
    "    \"\"\"\n",
    "\n",
    "    return FLA_Redshift(**redshift_credentials).query_warehouse(sql_string=q)\n",
    "\n",
    "@task(log_prints = True)\n",
    "def extract_upcoming(redshift_credentials: Dict) -> pd.DataFrame:\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "        season,\n",
    "        date(cth_game_descriptions.event_date) AS event_date,\n",
    "        day_of_week,\n",
    "        cth_game_descriptions.tier,\n",
    "        start_time,\n",
    "        predicted_turnstile\n",
    "    FROM\n",
    "        custom.cth_game_descriptions\n",
    "    LEFT JOIN\n",
    "        custom.forecasting_hockey_turnstile_2425_playoffs on cth_game_descriptions.event_date = forecasting_hockey_turnstile_2425_playoffs.event_date\n",
    "    WHERE\n",
    "        cth_game_descriptions.event_date >= current_date\n",
    "    \"\"\"\n",
    "\n",
    "    return FLA_Redshift(**redshift_credentials).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f67a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    def create_start_time_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Define the dictionary with lists of start times\n",
    "        lookup = {\n",
    "            1: ['12:30 PM', '12:45 PM', '1:00 PM', '3:00 PM', '3:30 PM'],\n",
    "            2: ['4:00 PM', '5:00 PM', '6:00 PM']\n",
    "        }\n",
    "\n",
    "        # Default to 0 for any start time not in the lookup\n",
    "        df['start_time_num'] = 0\n",
    "        for key, times in lookup.items():\n",
    "            df.loc[df['start_time'].isin(times), 'start_time_num'] = key\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def create_tier_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # lookup = {\n",
    "        #     'SC': 4,\n",
    "        #     'R3': 3,\n",
    "        #     'R2': 2,\n",
    "        #     'R1': 1\n",
    "        # }\n",
    "\n",
    "        # df['tier_num'] = 0\n",
    "        # for key, value in lookup.items():\n",
    "        #     df.loc[df['tier'] == key, 'tier_num'] = value\n",
    "\n",
    "        df = pd.get_dummies(df, columns=['tier'], prefix = '', prefix_sep = '')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def create_weekend_num(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        lookup = {\n",
    "                'Fri': 1,\n",
    "                'Sat': 1,\n",
    "                'Sun': 1,\n",
    "                'Mon': 0,\n",
    "                'Tue': 0,\n",
    "                'Wed': 0,\n",
    "                'Thu': 0\n",
    "        }\n",
    "\n",
    "        for key, value in lookup.items():\n",
    "            df.loc[df['day_of_week'] == key, 'weekend_num'] = value\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = create_start_time_num(df)\n",
    "    df = create_tier_num(df)\n",
    "    df = create_weekend_num(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(df: pd.DataFrame, df_future: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    x_train = df[['attendance','weekend_num','start_time_num','tier_num']]\n",
    "    y_train = df[['multiplier']]\n",
    "\n",
    "    x_test = df_future[['predicted_turnstile','weekend_num','start_time_num','tier_num']]\n",
    "\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    poly_features_2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features_2).astype(int)\n",
    "\n",
    "def get_predictions(df_historical: pd.DataFrame, df_upcoming: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df_historical['predicted_gross_revenue'] = df_historical['gross_revenue']\n",
    "    df_upcoming['predicted_gross_revenue'] = run_model(df_historical, df_upcoming)\n",
    "\n",
    "    df = pd.concat([df_historical, df_upcoming], axis=0, ignore_index=True)\n",
    "\n",
    "    df = df[df['season'] == '2024-25']\n",
    "    df = df.rename(columns={'gross_revenue': 'current_gross_revenue'})\n",
    "\n",
    "    df = df[[\n",
    "        'event_date',\n",
    "        'attendance',\n",
    "        'current_gross_revenue',\n",
    "        'predicted_gross_revenue'\n",
    "    ]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444f2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[\n",
    "#     'event_date', \n",
    "#     'days_out',\n",
    "#     'tier',\n",
    "#     'location_group',\n",
    "#     'capacity',\n",
    "#     'current_prepaid_passes',\n",
    "#     'expected_additional_prepaid_passes',\n",
    "#     'total_expected_prepaid_passes',\n",
    "#     'expected_prepaid_passes_parked',\n",
    "#     'expected_onsite_parking',\n",
    "#     'total_expected_cars_parked'\n",
    "# ]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

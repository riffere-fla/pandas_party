{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22518629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124f244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69e2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tickets, Nightly Suites, Turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get past singles data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH playoffs_22_23 AS (\n",
    "    SELECT\n",
    "        '2022-23' AS season,\n",
    "        LEFT(RIGHT(event_name, 4), 2) AS round,\n",
    "        event_name,\n",
    "        date(event_date) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(add_datetime), DATE(event_date)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(add_datetime), DATE(event_date))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(block_purchase_price) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_ticket_expanded_all_playoffs_2223\n",
    "    WHERE\n",
    "        event_name IN ('23POR1G1', '23POR1G2', '23POR1G3', '23POR2G1', '23POR2G2', '23POR3G1', '23POR3G2', '23POR4G1', '23POR4G2')\n",
    "        AND ticket_type IN ('Singles')\n",
    "    GROUP BY\n",
    "        event_name,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type\n",
    "),\n",
    "playoffs_23_24 AS (\n",
    "    SELECT\n",
    "        '2023-24' AS season,\n",
    "        RIGHT(LEFT(product_description, 6), 2) AS round,\n",
    "        LEFT(product_description, 8) AS event_name,\n",
    "        date(event_datetime) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(gross_revenue) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2324_playoffs\n",
    "    WHERE\n",
    "        ticket_type_playoffs IN ('Singles')\n",
    "        AND event_name != '23-24 Pl'\n",
    "    GROUP BY\n",
    "        product_description,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type_playoffs\n",
    "),\n",
    "playoffs_24_25 AS (\n",
    "    SELECT\n",
    "        '2024-25' AS season,\n",
    "        RIGHT(LEFT(product_description, 6), 2) AS round,\n",
    "        LEFT(product_description, 8) AS event_name,\n",
    "        date(event_datetime) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(gross_revenue) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2425_playoffs\n",
    "    WHERE\n",
    "        ticket_type_playoffs IN ('Singles')\n",
    "        AND event_name != '24-25 Pl'\n",
    "    GROUP BY\n",
    "        product_description,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type_playoffs\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_22_23\n",
    "UNION ALL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_23_24\n",
    "UNION ALL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_24_25\n",
    "ORDER BY\n",
    "    season,\n",
    "    round,\n",
    "    event_name,\n",
    "    days_out DESC\n",
    "\"\"\"\n",
    "\n",
    "ticket_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511c32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\2629162886.py:5: FutureWarning: The 'axis' keyword in DataFrame.groupby is deprecated and will be removed in a future version.\n",
      "  cumdf = ticket_df.groupby(by = ['round','event_name','event_date'], axis = 0)[['gross_revenue','paid_seats']].cumsum().rename(columns = {'gross_revenue':'cum_gross_rev', 'paid_seats':'cum_num_seats'})\n"
     ]
    }
   ],
   "source": [
    "# get average tickets sold by days out from previous seasons\n",
    "\n",
    "ticket_df['min_days_out'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])]['days_out'].min(), axis = 1)\n",
    "\n",
    "cumdf = ticket_df.groupby(by = ['round','event_name','event_date'], axis = 0)[['gross_revenue','paid_seats']].cumsum().rename(columns = {'gross_revenue':'cum_gross_rev', 'paid_seats':'cum_num_seats'})\n",
    "\n",
    "ticket_df = pd.concat([ticket_df,cumdf], axis = 1)\n",
    "\n",
    "ticket_df['final_seats'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])&\n",
    "                                                  (ticket_df['days_out'] == row['min_days_out'])]['cum_num_seats'].item(), axis = 1)\n",
    "\n",
    "ticket_df['per_seats_in'] = [x/y for x,y in zip(ticket_df['cum_num_seats'],ticket_df['final_seats'])]\n",
    "\n",
    "ticket_df['final_rev'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])&\n",
    "                                                  (ticket_df['days_out'] == row['min_days_out'])]['cum_gross_rev'].item(), axis = 1)\n",
    "\n",
    "ticket_df['per_rev_in'] = [x/y for x,y in zip(ticket_df['cum_gross_rev'],ticket_df['final_rev'])]\n",
    "\n",
    "ticket_df = ticket_df[['season','round', 'event_name', 'event_date','days_out','gross_revenue','paid_seats', 'cum_gross_rev','cum_num_seats','per_seats_in','per_rev_in']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2273bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge averages back to 24/25 season\n",
    "\n",
    "df_train = ticket_df[ticket_df['season'] != '2024-25']\n",
    "\n",
    "df_2425 = ticket_df[ticket_df['season'] == '2024-25']\n",
    "\n",
    "df_avgs = df_train.groupby(by = ['round','days_out'])[['per_seats_in','per_rev_in']].mean().rename(columns = {'per_seats_in':'avg_per_seats_in','per_rev_in':'avg_per_rev_in'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93cd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict final singles totals for 24/25\n",
    "\n",
    "df_merged = df_2425.merge(right = df_avgs, how = 'left', on = ['round','days_out'])\n",
    "\n",
    "df_merged['paid_seats'] = df_merged['cum_num_seats']/df_merged['avg_per_seats_in']\n",
    "\n",
    "df_merged['gross_revenue'] = df_merged['cum_gross_rev']/df_merged['avg_per_rev_in']\n",
    "\n",
    "min_indices = df_merged.groupby('event_name')['days_out'].idxmin()\n",
    "\n",
    "result = df_merged.loc[min_indices]\n",
    "\n",
    "result['ticket_type_playoffs'] = 'Singles'\n",
    "\n",
    "result['tier'] = result['event_name'].str[-4:].str[:2]\n",
    "\n",
    "result = result[['event_name','event_date','tier','ticket_type_playoffs','paid_seats','gross_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87583ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current in from other ticket types\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    LEFT(product_description, 8) AS event_name,\n",
    "    RIGHT(LEFT(product_description,6),2) AS tier,\n",
    "    date(event_datetime) as event_date,\n",
    "    ticket_type_playoffs,\n",
    "    sum(gross_revenue) as gross_revenue,\n",
    "    sum(paid_seats) as paid_seats\n",
    "FROM\n",
    "    custom.cth_v_ticket_2425_playoffs\n",
    "WHERE\n",
    "    date(event_datetime) <= '2025-05-02'\n",
    "    and ticket_type_playoffs != 'Singles'\n",
    "GROUP BY\n",
    "    product_description,\n",
    "    event_date,\n",
    "    ticket_type_playoffs\n",
    "\"\"\"\n",
    "\n",
    "current_in = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8826198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3898573725.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate.groupby(by = ['tier']).apply(weighted_paid_average).reset_index()\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3898573725.py:85: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comp_tiers = show_rate.groupby(by = ['tier']).apply(weighted_comp_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# get weighted show_rate avergaes over last 4 seasons\n",
    "\n",
    "# get historical show rate data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "        game_desc.season,\n",
    "        game_desc.tier,\n",
    "        ticket.event_date::date,\n",
    "        ticket.comp_seats::float,\n",
    "        ticket.paid_seats::float,\n",
    "        CASE\n",
    "            WHEN ticket.is_comp = TRUE AND ticket.did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"comp_seats_attended\",\n",
    "        CASE\n",
    "            WHEN is_comp = FALSE AND did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"paid_seats_attended\"\n",
    "    FROM\n",
    "        custom.cth_v_historical_ticket ticket\n",
    "    INNER JOIN\n",
    "        custom.cth_game_descriptions game_desc\n",
    "            ON ticket.event_datetime::date = game_desc.event_datetime::date\n",
    "            AND game_desc.season IN ('2021-22', '2022-23', '2023-24', '2024-25')\n",
    "            AND game_desc.event_datetime < current_date\n",
    "),\n",
    "tier_show_rate AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        tier,\n",
    "        sum(historical.comp_seats_attended)::float / nullif(sum(historical.comp_seats),0) AS \"comp_show_rate\",\n",
    "        sum(historical.paid_seats_attended)::float / nullif(sum(historical.paid_seats),0) AS \"paid_show_rate\"\n",
    "    FROM\n",
    "        historical\n",
    "    GROUP BY\n",
    "        season,\n",
    "        tier\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tier_show_rate\n",
    "where\n",
    "    tier in ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "show_rate = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "weights = {'2022-23': .5, '2023-24':1,'2024-25':1.5}\n",
    "\n",
    "show_rate['weights'] = show_rate['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['paid_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_paid_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate.groupby(by = ['tier']).apply(weighted_paid_average).reset_index()\n",
    "\n",
    "def weighted_comp_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['comp_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_comp_average': wavg\n",
    "    })\n",
    "\n",
    "comp_tiers = show_rate.groupby(by = ['tier']).apply(weighted_comp_average).reset_index()\n",
    "\n",
    "tiers = pd.merge(paid_tiers, comp_tiers, on = ['tier'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f46b2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto 24/25 data and predict attendance\n",
    "\n",
    "df_final = pd.concat([result,current_in])\n",
    "\n",
    "final_tickets_and_attendance = df_final.groupby(by = ['event_name','event_date', 'tier'])[['paid_seats','gross_revenue']].sum().reset_index()\n",
    "\n",
    "final_tickets_and_attendance = final_tickets_and_attendance.merge(tiers, how = 'left', on = 'tier')\n",
    "\n",
    "final_tickets_and_attendance['total_attendance'] = final_tickets_and_attendance['paid_seats'] * final_tickets_and_attendance['weighted_paid_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e2b08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nightly suite tickets\n",
    "\n",
    "q = \"\"\"\n",
    "WITH sold_suites AS (\n",
    "\n",
    "    WITH comp_temp AS (\n",
    "        SELECT\n",
    "            product_id,\n",
    "            section,\n",
    "            product_id || '-' || section AS \"id\",\n",
    "            'COMP'::varchar AS \"status\",\n",
    "            NULL::varchar AS \"locks\",\n",
    "            'Comp'::varchar AS \"allocations\",\n",
    "            sum(gross_revenue) AS \"gross_revenue\"\n",
    "        FROM\n",
    "            custom.cth_v_ticket_status_2425_playoffs\n",
    "        WHERE\n",
    "            (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "            AND status = 'SOLD'\n",
    "        GROUP BY\n",
    "            product_id,\n",
    "            section\n",
    "        HAVING\n",
    "            sum(gross_revenue) = 0\n",
    "    )\n",
    "\n",
    "    -- sold suites\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'SOLD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Sold'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'SOLD'\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "    HAVING\n",
    "        sum(gross_revenue) > 0\n",
    "    UNION ALL\n",
    "\n",
    "    -- killed suites\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'SOLD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Sold'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (\n",
    "            pc_one IN ('U', 'V', 'W')\n",
    "            OR section = 'House'\n",
    "        )\n",
    "        AND (\n",
    "            allocations ilike '%kill%'\n",
    "            OR locks ilike '%kill%'\n",
    "            OR allocations ilike '%panthers players%'\n",
    "            OR allocations ilike '%owner%'\n",
    "            OR allocations ilike '%hockey operations%'\n",
    "            OR allocations ilike '%visiting team%'\n",
    "        )\n",
    "        AND \"id\" NOT IN (SELECT ct.id FROM comp_temp ct)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "    UNION ALL\n",
    "\n",
    "    -- comp suites\n",
    "    SELECT * FROM comp_temp\n",
    "),\n",
    "held_suites AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'HELD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Held'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'HELD'\n",
    "        AND \"id\" NOT IN (SELECT s.id FROM sold_suites s)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "),\n",
    "-- SELECT * FROM held_suites;\n",
    "available_suites AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'AVAIL'::varchar AS \"status\",\n",
    "        LISTAGG(DISTINCT locks, ', ') AS \"locks\",\n",
    "        LISTAGG(DISTINCT allocations, ', ') WITHIN GROUP (ORDER BY allocations) AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'AVAIL'\n",
    "        AND \"id\" NOT IN (SELECT s.id FROM sold_suites s)\n",
    "        AND \"id\" NOT IN (SELECT h.id FROM held_suites h)\n",
    "        AND (allocations <> '[\"Standing Room Only\"]' OR allocations IS NULL)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "),\n",
    "temp AS (\n",
    "    SELECT * FROM sold_suites\n",
    "    UNION ALL\n",
    "    SELECT * FROM held_suites\n",
    "    UNION ALL\n",
    "    SELECT * FROM available_suites\n",
    ")\n",
    "SELECT\n",
    "    split_part(products.product_description, ' - ', 1) AS \"event_name\",\n",
    "    CASE\n",
    "        WHEN RIGHT(LEFT(product_description,6),2) = 'R4' THEN 'SC'\n",
    "        ELSE RIGHT(LEFT(product_description,6),2)\n",
    "    END AS tier,\n",
    "    event_date,\n",
    "    temp.*\n",
    "FROM\n",
    "    temp\n",
    "LEFT JOIN\n",
    "    custom.seatgeek_v_products products ON temp.product_id = products.product_id\n",
    "ORDER BY\n",
    "    \"event_name\",\n",
    "    event_date,\n",
    "    section\n",
    "\"\"\"\n",
    "\n",
    "current_nightly_suites = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c4db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites.groupby(by = ['event_name','event_date','status'])[['section']].count().reset_index()\n",
    "\n",
    "current_nightly_suites = current_nightly_suites.pivot_table(index=['event_name','event_date', 'tier'], columns='status', \n",
    "             values='section', aggfunc='count').reset_index()\n",
    "\n",
    "current_nightly_suites['event_date'] = pd.to_datetime(current_nightly_suites['event_date'])\n",
    "\n",
    "current_nightly_suites['days_out_from_event'] = (current_nightly_suites['event_date'] - datetime.now()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676d6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    custom.forecasting_hockey_nightly_suites_playoffs\n",
    "\"\"\"\n",
    "\n",
    "forecasting_nightly_suites = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f88575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites = current_nightly_suites.merge(forecasting_nightly_suites, how = 'left', on = ['tier', 'days_out_from_event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64ecfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites['is_going_to_sellout'] = current_nightly_suites['cumulative_avg_sold'] > current_nightly_suites['AVAIL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e10d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites = current_nightly_suites[['event_name','event_date','days_out_from_event','tier','AVAIL','COMP','HELD','SOLD','cumulative_avg_sold','is_going_to_sellout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cb8bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merch, F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH attendance AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        COUNT(*) AS attendance\n",
    "    FROM\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    GROUP BY\n",
    "        event_datetime\n",
    ")\n",
    "SELECT\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    gross_revenue,\n",
    "    num_orders,\n",
    "    quantity_sold\n",
    "FROM\n",
    "    custom.cheq_v_hockey_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON DATE(cheq_v_hockey_summary.event_date) = DATE(cth_game_descriptions.event_date)\n",
    "LEFT JOIN\n",
    "    attendance \n",
    "    ON DATE(attendance.event_datetime) = DATE(cheq_v_hockey_summary.event_date)\n",
    "WHERE\n",
    "    tier IN ('R1', 'R2', 'R3', 'SC')\n",
    "\"\"\"\n",
    "\n",
    "historical_f_and_b = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c7e25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_columns(df):\n",
    "\n",
    "    day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "    df['weekend'] = df.apply(\n",
    "        lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "    start_time_map = {\n",
    "        '12:30 PM': 1,\n",
    "        '12:45 PM': 1,\n",
    "        '1:00 PM': 1,\n",
    "        '3:00 PM': 1,\n",
    "        '3:30 PM': 1,\n",
    "        '4:00 PM': 2,\n",
    "        '5:00 PM': 2,\n",
    "        '6:00 PM': 2\n",
    "    }\n",
    "\n",
    "    df['start_time_num'] = df.apply(\n",
    "        lambda row: start_time_map.get(row['start_time'], 0),\n",
    "        axis=1)\n",
    "\n",
    "    tier_mapping = {\n",
    "        'A': 5,\n",
    "        'B': 4,\n",
    "        'C': 3,\n",
    "        'D': 2,\n",
    "        'E': 1\n",
    "    }\n",
    "\n",
    "    df['tier_num'] = df.apply(\n",
    "        lambda row: tier_mapping.get(row['tier'], 0),\n",
    "        axis=1) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c22eb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_f_and_b = get_model_columns(historical_f_and_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ea073",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH attendance AS\n",
    "    (SELECT\n",
    "        event_datetime,\n",
    "        COUNT(*) AS attendance\n",
    "    FROM\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    GROUP BY\n",
    "        event_datetime)\n",
    "SELECT\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    SUM(gross_revenue) AS gross_revenue,\n",
    "    SUM(qty) AS quantity,\n",
    "    COUNT(distinct invoice_id) AS num_orders\n",
    "FROM\n",
    "    custom.retailpro_v_invoice_items\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions ON retailpro_v_invoice_items.event_date = cth_game_descriptions.event_date\n",
    "LEFT JOIN\n",
    "    attendance ON retailpro_v_invoice_items.event_date = date(attendance.event_datetime)\n",
    "WHERE\n",
    "    season IN ('2023-24','2024-25')\n",
    "    AND tier IN ('R1','R2','R3','SC')\n",
    "GROUP BY\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance\n",
    "\"\"\"\n",
    "\n",
    "historical_merch = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39eb8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_merch = get_model_columns(historical_merch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "    season,\n",
    "    date(event_date) AS event_date,\n",
    "    day_of_week,\n",
    "    tier,\n",
    "    start_time\n",
    "FROM\n",
    "    custom.cth_game_descriptions\n",
    "WHERE\n",
    "    event_date >= current_date\n",
    "\"\"\"\n",
    "\n",
    "future_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "future_game_info = future_game_info.merge(final_tickets_and_attendance, how = 'left', on = ['event_date', 'tier'])\n",
    "\n",
    "future_game_info = get_model_columns(future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3df84fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_f_and_b_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['total_attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcbadb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_f_and_b_gross_rev'] = run_f_and_b_model(historical_f_and_b, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "721fe792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_merch_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['total_attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "631c7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_merch_gross_rev'] = run_merch_model(historical_merch, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2b3f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rates by tier and lot\n",
    "\n",
    "q = \"\"\"\n",
    "WITH prepaid AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2324\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2425\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "),\n",
    "prepaid_agg AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        COUNT(*) AS prepaid_passes\n",
    "    FROM\n",
    "        prepaid\n",
    "    GROUP BY\n",
    "        event_datetime, \n",
    "        location_group\n",
    "),\n",
    "scans AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        cth_game_descriptions.event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        CASE\n",
    "            WHEN paid_amount = 0 THEN 1\n",
    "            ELSE 0 \n",
    "        END AS num_scans\n",
    "    FROM\n",
    "        custom.parkhub_v_transactions\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions \n",
    "        ON parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    WHERE\n",
    "        cth_game_descriptions.event_datetime IS NOT NULL\n",
    "        AND season IN ('2023-24', '2024-25')\n",
    "),\n",
    "scans_agg AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        SUM(num_scans) AS num_scans\n",
    "    FROM\n",
    "        scans\n",
    "    GROUP BY\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group\n",
    ")\n",
    "SELECT\n",
    "    season,\n",
    "    prepaid_agg.event_datetime,\n",
    "    tier,\n",
    "    prepaid_agg.location_group,\n",
    "    prepaid_passes,\n",
    "    num_scans,\n",
    "    num_scans * 1.0 / prepaid_passes::FLOAT AS show_rate\n",
    "FROM\n",
    "    scans_agg\n",
    "LEFT JOIN\n",
    "    prepaid_agg \n",
    "    ON scans_agg.event_datetime = prepaid_agg.event_datetime\n",
    "    AND scans_agg.location_group = prepaid_agg.location_group\n",
    "WHERE\n",
    "    prepaid_agg.event_datetime IS NOT NULL\n",
    "    AND tier IN ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "show_rate_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56aa7e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3821290929.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# weigh this past season more heavily\n",
    "\n",
    "weights = {'2023-24':1.25,'2024-25':2.75}\n",
    "\n",
    "show_rate_df['weights'] = show_rate_df['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e77dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical prepaid parking data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH prepaid AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        DATE(transaction_date) AS transaction_date\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2324\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        DATE(transaction_date) AS transaction_date\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2425\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    ")\n",
    "SELECT\n",
    "    DATE(prepaid.event_datetime) AS event_date,\n",
    "    location_group,\n",
    "    'prepaid' AS parking_type,\n",
    "    DATEDIFF('days', transaction_date, prepaid.event_datetime) AS days_out,\n",
    "    CASE\n",
    "        WHEN DATEDIFF('days', transaction_date, prepaid.event_datetime) >= 150 THEN 0\n",
    "        ELSE COUNT(*)\n",
    "    END AS num_passes\n",
    "FROM\n",
    "    prepaid\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON prepaid.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    DATEDIFF('days', transaction_date, prepaid.event_datetime) >= 0\n",
    "    AND tier IN ('R1', 'R2', 'R3', 'SC')\n",
    "GROUP BY\n",
    "    prepaid.event_datetime,\n",
    "    location_group,\n",
    "    transaction_date\n",
    "ORDER BY\n",
    "    prepaid.event_datetime,\n",
    "    location_group,\n",
    "    transaction_date DESC\n",
    "\"\"\"\n",
    "\n",
    "historical_prepaid_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "location_map = {\n",
    "    'Club': 4,\n",
    "    'Garage': 3,\n",
    "    'General': 2,\n",
    "    'Valet': 1\n",
    "}\n",
    "\n",
    "historical_prepaid_parking_info['location_num'] = historical_prepaid_parking_info.apply(\n",
    "    lambda row: location_map.get(row['location_group'], 0), axis=1)\n",
    "\n",
    "historical_prepaid_parking_info['cumulative_num_passes']  = historical_prepaid_parking_info.groupby(['event_date', 'location_group'])['num_passes'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "528d7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical game data (ie tier, dow, and start time)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    date(cth_game_descriptions.event_date) AS event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    total_tickets\n",
    "FROM\n",
    "    custom.cth_v_historical_attendance_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions ON cth_v_historical_attendance_summary.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    tier IN ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "all_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "all_game_info['weekend'] = all_game_info.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "all_game_info['start_time_num'] = all_game_info.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "046cb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming game data including current prepaid totals by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    DATE(cth_game_descriptions.event_datetime) AS event_date,\n",
    "    DATEDIFF('day', CURRENT_DATE, cth_game_descriptions.event_datetime) AS days_out,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity::INT,\n",
    "    SUM(paid_seats) + SUM(comp_seats) AS prepaid_cars,\n",
    "    SUM(gross_revenue) AS current_gross_revenue,\n",
    "    capacity::INT - (SUM(paid_seats) + SUM(comp_seats)) AS cap_remaining\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN\n",
    "    custom.ctp_parking_capacities \n",
    "    ON ctp_v_ticket_2425.location_group = ctp_parking_capacities.location_group\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    cth_game_descriptions.event_datetime IS NOT NULL \n",
    "    AND cth_game_descriptions.event_datetime >= CURRENT_DATE\n",
    "GROUP BY\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity\n",
    "ORDER BY\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group\n",
    "\"\"\"\n",
    "\n",
    "upcoming_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24488c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming pricing data by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    tier,\n",
    "    location_group,\n",
    "    max(transaction_date) AS \"transaction_date\",\n",
    "    max(adjusted_price) AS \"highest_price\"\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN             \n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    is_comp = FALSE\n",
    "    AND price_type ILIKE 'IA%'\n",
    "GROUP BY\n",
    "    tier, \n",
    "    location_group\n",
    "\"\"\"\n",
    "\n",
    "pricing_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2729752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict remaining prepaid cars\n",
    "\n",
    "def run_prepaid_model(df, df_future, lot):\n",
    "\n",
    "    total_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = total_table[['days_out','weekend','start_time_num']]\n",
    "    y_train = total_table[['cumulative_num_passes']]\n",
    "\n",
    "    total_future_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = total_future_table[['days_out','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daa7cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_table = historical_prepaid_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_table = total_table[total_table['tier'].isin(['R1','R2','R3','SC'])]\n",
    "\n",
    "# merge upcoming parking data with hisorical game data for testing model\n",
    "\n",
    "total_future_table = upcoming_game_info.merge(future_game_info, how = 'left', on = 'event_date')\n",
    "total_future_table = total_future_table[total_future_table['tier'].isin(['R1','R2','R3','SC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7351843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general and garage not  club, valet or executive\n",
    "\n",
    "lots = ['General','Garage']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = total_future_table[total_future_table['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
    "\n",
    "    final_df = pd.concat([final_df,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d5ddaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\1184624018.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  club_totals['predicted_parking'] = 0\n"
     ]
    }
   ],
   "source": [
    "# concat club totals for onsite model next\n",
    "\n",
    "club_totals = total_future_table[total_future_table['location_group'] == 'Club']\n",
    "club_totals['predicted_parking'] = 0\n",
    "\n",
    "final_df = pd.concat([final_df, club_totals], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cad384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no negative predictions are made\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['predicted_parking'] < 0, 0, final_df['predicted_parking'])\n",
    "\n",
    "# get total prepaid tickets (current + predicted additional)\n",
    "\n",
    "final_df['total_predicted_prepaid_cars'] = final_df['prepaid_cars'] + final_df['predicted_parking']\n",
    "\n",
    "# get number of parked cars using historical show rates\n",
    "\n",
    "final_df = final_df.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "final_df['prepaid_cars_parked'] = (final_df['total_predicted_prepaid_cars'] * final_df['weighted_average']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6360b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the capacity remaining \n",
    "\n",
    "final_df['cap_remaining'] = final_df['capacity'] - final_df['prepaid_cars_parked']\n",
    "\n",
    "# if predicted cars over capacity subtract overflow out\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['cap_remaining'] < 0, final_df['predicted_prepaid_additional_parking']+final_df['cap_remaining'], final_df['predicted_prepaid_additional_parking'])\n",
    "final_df['prepaid_cars_parked'] = np.where(final_df['cap_remaining'] < 0, final_df['prepaid_cars_parked']+final_df['cap_remaining'], final_df['prepaid_cars_parked'])\n",
    "final_df['cap_remaining'] = np.where(final_df['cap_remaining'] < 0, 0, final_df['prepaid_cars_parked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af0a2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['event_date','days_out','tier', 'start_time_num','weekend',\n",
    "                     'location_group','capacity','prepaid_cars','current_gross_revenue', \n",
    "                     'predicted_prepaid_additional_parking', 'total_predicted_prepaid_cars',\n",
    "                     'prepaid_cars_parked','cap_remaining']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83c43672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "days_out",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weekend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "location_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepaid_cars",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "current_gross_revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_prepaid_additional_parking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_predicted_prepaid_cars",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepaid_cars_parked",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cap_remaining",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c4016bb-7c7b-47e0-a576-6e07a7a138df",
       "rows": [
        [
         "0",
         "2025-04-26",
         "3",
         "R1",
         "1",
         "1",
         "General",
         "4360",
         "2101",
         "54326.0",
         "627",
         "2728",
         "2362",
         "2362"
        ],
        [
         "1",
         "2025-04-28",
         "5",
         "R1",
         "0",
         "0",
         "General",
         "4360",
         "1838",
         "43368.0",
         "1323",
         "3161",
         "2737",
         "2737"
        ],
        [
         "2",
         "2025-04-26",
         "3",
         "R1",
         "1",
         "1",
         "Garage",
         "200",
         "100",
         "5520.0",
         "1",
         "101",
         "76",
         "76"
        ],
        [
         "3",
         "2025-04-28",
         "5",
         "R1",
         "0",
         "0",
         "Garage",
         "200",
         "100",
         "5520.0",
         "59",
         "159",
         "120",
         "120"
        ],
        [
         "4",
         "2025-04-26",
         "3",
         "R1",
         "1",
         "1",
         "Club",
         "1861",
         "1253",
         "40590.0",
         "0",
         "1253",
         "1074",
         "1074"
        ],
        [
         "5",
         "2025-04-28",
         "5",
         "R1",
         "0",
         "0",
         "Club",
         "1861",
         "1253",
         "40590.0",
         "0",
         "1253",
         "1074",
         "1074"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>days_out</th>\n",
       "      <th>tier</th>\n",
       "      <th>start_time_num</th>\n",
       "      <th>weekend</th>\n",
       "      <th>location_group</th>\n",
       "      <th>capacity</th>\n",
       "      <th>prepaid_cars</th>\n",
       "      <th>current_gross_revenue</th>\n",
       "      <th>predicted_prepaid_additional_parking</th>\n",
       "      <th>total_predicted_prepaid_cars</th>\n",
       "      <th>prepaid_cars_parked</th>\n",
       "      <th>cap_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>4360</td>\n",
       "      <td>2101</td>\n",
       "      <td>54326.0</td>\n",
       "      <td>627</td>\n",
       "      <td>2728</td>\n",
       "      <td>2362</td>\n",
       "      <td>2362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>4360</td>\n",
       "      <td>1838</td>\n",
       "      <td>43368.0</td>\n",
       "      <td>1323</td>\n",
       "      <td>3161</td>\n",
       "      <td>2737</td>\n",
       "      <td>2737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Garage</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>5520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Garage</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>5520.0</td>\n",
       "      <td>59</td>\n",
       "      <td>159</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Club</td>\n",
       "      <td>1861</td>\n",
       "      <td>1253</td>\n",
       "      <td>40590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1253</td>\n",
       "      <td>1074</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Club</td>\n",
       "      <td>1861</td>\n",
       "      <td>1253</td>\n",
       "      <td>40590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1253</td>\n",
       "      <td>1074</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date  days_out tier  start_time_num  weekend location_group  \\\n",
       "0  2025-04-26         3   R1               1        1        General   \n",
       "1  2025-04-28         5   R1               0        0        General   \n",
       "2  2025-04-26         3   R1               1        1         Garage   \n",
       "3  2025-04-28         5   R1               0        0         Garage   \n",
       "4  2025-04-26         3   R1               1        1           Club   \n",
       "5  2025-04-28         5   R1               0        0           Club   \n",
       "\n",
       "   capacity  prepaid_cars  current_gross_revenue  \\\n",
       "0      4360          2101                54326.0   \n",
       "1      4360          1838                43368.0   \n",
       "2       200           100                 5520.0   \n",
       "3       200           100                 5520.0   \n",
       "4      1861          1253                40590.0   \n",
       "5      1861          1253                40590.0   \n",
       "\n",
       "   predicted_prepaid_additional_parking  total_predicted_prepaid_cars  \\\n",
       "0                                   627                          2728   \n",
       "1                                  1323                          3161   \n",
       "2                                     1                           101   \n",
       "3                                    59                           159   \n",
       "4                                     0                          1253   \n",
       "5                                     0                          1253   \n",
       "\n",
       "   prepaid_cars_parked  cap_remaining  \n",
       "0                 2362           2362  \n",
       "1                 2737           2737  \n",
       "2                   76             76  \n",
       "3                  120            120  \n",
       "4                 1074           1074  \n",
       "5                 1074           1074  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1c556e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hisotrical onsite parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with onsite as\n",
    "    (select\n",
    "        date(cth_game_descriptions.event_datetime) as event_date,\n",
    "        location_group,\n",
    "        0 as days_out,\n",
    "        case\n",
    "            when paid_amount > 0 then 1\n",
    "        else 0\n",
    "        end as num_onsite_cars,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "        else 0\n",
    "        end as num_prepaid_cars\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        season in ('2023-24','2024-25'))\n",
    "select\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    'onsite' as parking_type,\n",
    "    days_out,\n",
    "    sum(num_onsite_cars) as num_cars,\n",
    "    capacity - sum(num_prepaid_cars) as cap_remaining\n",
    "from\n",
    "    onsite\n",
    "left join\n",
    "    custom.ctp_parking_capacities on onsite.location_group = ctp_parking_capacities.location_group\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    parking_type,\n",
    "    days_out,\n",
    "    capacity\n",
    "\"\"\"\n",
    "\n",
    "historical_onsite_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d00413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_onsite_table = historical_onsite_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_onsite_table = total_onsite_table[total_onsite_table['tier'].isin(['R1','R2','R3','SC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ce33fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict onsite cars\n",
    "\n",
    "def run_onsite_model(df, df_future, lot):\n",
    "\n",
    "    x_train_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = x_train_table[['cap_remaining','weekend','start_time_num']]\n",
    "    y_train = x_train_table[['num_cars']]\n",
    "\n",
    "    x_test_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = x_test_table[['cap_remaining','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    #predicted_test = polynomial.predict(poly_features2)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58fc0429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general, garage, and club not valet or executive\n",
    "\n",
    "lots = ['General','Garage','Club']\n",
    "\n",
    "final_df_onsite = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = final_df[final_df['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
    "\n",
    "    final_df_onsite = pd.concat([final_df_onsite,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eee0a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3926685836.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3926685836.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n"
     ]
    }
   ],
   "source": [
    "# add back executive and valet parking and match fields from final_df\n",
    "\n",
    "exec_and_valet = total_future_table[total_future_table['location_group'].isin(['Executive','Valet'])]\n",
    "\n",
    "exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
    "exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n",
    "\n",
    "exec_and_valet = exec_and_valet.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "exec_and_valet['weighted_average'] = exec_and_valet['weighted_average'].fillna(1)\n",
    "\n",
    "exec_and_valet['prepaid_cars_parked'] = (exec_and_valet['total_predicted_prepaid_cars'] * exec_and_valet['weighted_average']).astype(int)\n",
    "exec_and_valet['predicted_onsite_parking'] = 0\n",
    "exec_and_valet['total_parking'] = exec_and_valet['prepaid_cars_parked'] \n",
    "\n",
    "exec_and_valet = exec_and_valet[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked',\n",
    "                                       'predicted_onsite_parking','total_parking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8b53053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if predicted total over capacity subtract overflow out\n",
    "\n",
    "final_df_onsite['predicted_onsite_parking'] = [pred_onsite if pred_onsite <= cap_remaining else cap_remaining for pred_onsite, cap_remaining in zip(final_df_onsite['predicted_onsite_parking'], final_df_onsite['cap_remaining'])]\n",
    "\n",
    "final_df_onsite['total_parking'] = final_df_onsite['prepaid_cars_parked'] + final_df_onsite['predicted_onsite_parking']\n",
    "\n",
    "final_parking_model = final_df_onsite[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking','total_predicted_prepaid_cars',\n",
    "                                       'prepaid_cars_parked','predicted_onsite_parking','total_parking']]\n",
    "\n",
    "# merge with executive and valet parking info\n",
    "\n",
    "final_parking_model_df = pd.concat([final_parking_model, exec_and_valet], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f37d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parking_model_df = final_parking_model_df.merge(pricing_info, how = 'left', on = ['tier', 'location_group'])\n",
    "\n",
    "final_parking_model_df['predicted_prepaid_additional_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_onsite_parking_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']*1.25).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_gross_revenue'] = final_parking_model_df['predicted_prepaid_additional_gross_revenue'] + final_parking_model_df['predicted_onsite_parking_gross_revenue'] + final_parking_model_df['current_gross_revenue']\n",
    "\n",
    "final_parking_model_df = final_parking_model_df[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking', 'predicted_prepaid_additional_gross_revenue',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked', 'predicted_onsite_parking',\n",
    "                                       'predicted_onsite_parking_gross_revenue','total_parking', 'predicted_gross_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd788f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "days_out",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepaid_cars",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "current_gross_revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "predicted_prepaid_additional_parking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_prepaid_additional_gross_revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_predicted_prepaid_cars",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepaid_cars_parked",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_onsite_parking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_onsite_parking_gross_revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_parking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "predicted_gross_revenue",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9b25bd84-11cd-4446-9d9f-e74252c1bef6",
       "rows": [
        [
         "0",
         "2025-04-26",
         "3",
         "R1",
         "General",
         "4360",
         "2101",
         "54326.0",
         "627",
         "28215.0",
         "2728",
         "2362",
         "1172",
         "35268.75",
         "3534",
         "117809.75"
        ],
        [
         "1",
         "2025-04-28",
         "5",
         "R1",
         "General",
         "4360",
         "1838",
         "43368.0",
         "1323",
         "59535.0",
         "3161",
         "2737",
         "1063",
         "74418.75",
         "3800",
         "177321.75"
        ],
        [
         "2",
         "2025-04-26",
         "3",
         "R1",
         "Garage",
         "200",
         "100",
         "5520.0",
         "1",
         "0.0",
         "101",
         "76",
         "0",
         "0.0",
         "76",
         "5520.0"
        ],
        [
         "3",
         "2025-04-28",
         "5",
         "R1",
         "Garage",
         "200",
         "100",
         "5520.0",
         "59",
         "0.0",
         "159",
         "120",
         "0",
         "0.0",
         "120",
         "5520.0"
        ],
        [
         "4",
         "2025-04-26",
         "3",
         "R1",
         "Club",
         "1861",
         "1253",
         "40590.0",
         "0",
         "0.0",
         "1253",
         "1074",
         "311",
         "0.0",
         "1385",
         "40590.0"
        ],
        [
         "5",
         "2025-04-28",
         "5",
         "R1",
         "Club",
         "1861",
         "1253",
         "40590.0",
         "0",
         "0.0",
         "1253",
         "1074",
         "255",
         "0.0",
         "1329",
         "40590.0"
        ],
        [
         "6",
         "2025-04-26",
         "3",
         "R1",
         "Executive",
         "79",
         "31",
         "2480.0",
         "0",
         "0.0",
         "31",
         "31",
         "0",
         "0.0",
         "31",
         "2480.0"
        ],
        [
         "7",
         "2025-04-26",
         "3",
         "R1",
         "Valet",
         "292",
         "333",
         "16240.0",
         "0",
         "0.0",
         "333",
         "189",
         "0",
         "0.0",
         "189",
         "16240.0"
        ],
        [
         "8",
         "2025-04-28",
         "5",
         "R1",
         "Executive",
         "79",
         "31",
         "2480.0",
         "0",
         "0.0",
         "31",
         "31",
         "0",
         "0.0",
         "31",
         "2480.0"
        ],
        [
         "9",
         "2025-04-28",
         "5",
         "R1",
         "Valet",
         "292",
         "330",
         "16080.0",
         "0",
         "0.0",
         "330",
         "188",
         "0",
         "0.0",
         "188",
         "16080.0"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>days_out</th>\n",
       "      <th>tier</th>\n",
       "      <th>location_group</th>\n",
       "      <th>capacity</th>\n",
       "      <th>prepaid_cars</th>\n",
       "      <th>current_gross_revenue</th>\n",
       "      <th>predicted_prepaid_additional_parking</th>\n",
       "      <th>predicted_prepaid_additional_gross_revenue</th>\n",
       "      <th>total_predicted_prepaid_cars</th>\n",
       "      <th>prepaid_cars_parked</th>\n",
       "      <th>predicted_onsite_parking</th>\n",
       "      <th>predicted_onsite_parking_gross_revenue</th>\n",
       "      <th>total_parking</th>\n",
       "      <th>predicted_gross_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>General</td>\n",
       "      <td>4360</td>\n",
       "      <td>2101</td>\n",
       "      <td>54326.0</td>\n",
       "      <td>627</td>\n",
       "      <td>28215.0</td>\n",
       "      <td>2728</td>\n",
       "      <td>2362</td>\n",
       "      <td>1172</td>\n",
       "      <td>35268.75</td>\n",
       "      <td>3534</td>\n",
       "      <td>117809.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>General</td>\n",
       "      <td>4360</td>\n",
       "      <td>1838</td>\n",
       "      <td>43368.0</td>\n",
       "      <td>1323</td>\n",
       "      <td>59535.0</td>\n",
       "      <td>3161</td>\n",
       "      <td>2737</td>\n",
       "      <td>1063</td>\n",
       "      <td>74418.75</td>\n",
       "      <td>3800</td>\n",
       "      <td>177321.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>Garage</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>5520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76</td>\n",
       "      <td>5520.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>Garage</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>5520.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120</td>\n",
       "      <td>5520.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>Club</td>\n",
       "      <td>1861</td>\n",
       "      <td>1253</td>\n",
       "      <td>40590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1253</td>\n",
       "      <td>1074</td>\n",
       "      <td>311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1385</td>\n",
       "      <td>40590.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>Club</td>\n",
       "      <td>1861</td>\n",
       "      <td>1253</td>\n",
       "      <td>40590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1253</td>\n",
       "      <td>1074</td>\n",
       "      <td>255</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1329</td>\n",
       "      <td>40590.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>2480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>3</td>\n",
       "      <td>R1</td>\n",
       "      <td>Valet</td>\n",
       "      <td>292</td>\n",
       "      <td>333</td>\n",
       "      <td>16240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>189</td>\n",
       "      <td>16240.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>2480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>5</td>\n",
       "      <td>R1</td>\n",
       "      <td>Valet</td>\n",
       "      <td>292</td>\n",
       "      <td>330</td>\n",
       "      <td>16080.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188</td>\n",
       "      <td>16080.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_date  days_out tier location_group  capacity  prepaid_cars  \\\n",
       "0  2025-04-26         3   R1        General      4360          2101   \n",
       "1  2025-04-28         5   R1        General      4360          1838   \n",
       "2  2025-04-26         3   R1         Garage       200           100   \n",
       "3  2025-04-28         5   R1         Garage       200           100   \n",
       "4  2025-04-26         3   R1           Club      1861          1253   \n",
       "5  2025-04-28         5   R1           Club      1861          1253   \n",
       "6  2025-04-26         3   R1      Executive        79            31   \n",
       "7  2025-04-26         3   R1          Valet       292           333   \n",
       "8  2025-04-28         5   R1      Executive        79            31   \n",
       "9  2025-04-28         5   R1          Valet       292           330   \n",
       "\n",
       "   current_gross_revenue  predicted_prepaid_additional_parking  \\\n",
       "0                54326.0                                   627   \n",
       "1                43368.0                                  1323   \n",
       "2                 5520.0                                     1   \n",
       "3                 5520.0                                    59   \n",
       "4                40590.0                                     0   \n",
       "5                40590.0                                     0   \n",
       "6                 2480.0                                     0   \n",
       "7                16240.0                                     0   \n",
       "8                 2480.0                                     0   \n",
       "9                16080.0                                     0   \n",
       "\n",
       "   predicted_prepaid_additional_gross_revenue  total_predicted_prepaid_cars  \\\n",
       "0                                     28215.0                          2728   \n",
       "1                                     59535.0                          3161   \n",
       "2                                         0.0                           101   \n",
       "3                                         0.0                           159   \n",
       "4                                         0.0                          1253   \n",
       "5                                         0.0                          1253   \n",
       "6                                         0.0                            31   \n",
       "7                                         0.0                           333   \n",
       "8                                         0.0                            31   \n",
       "9                                         0.0                           330   \n",
       "\n",
       "   prepaid_cars_parked  predicted_onsite_parking  \\\n",
       "0                 2362                      1172   \n",
       "1                 2737                      1063   \n",
       "2                   76                         0   \n",
       "3                  120                         0   \n",
       "4                 1074                       311   \n",
       "5                 1074                       255   \n",
       "6                   31                         0   \n",
       "7                  189                         0   \n",
       "8                   31                         0   \n",
       "9                  188                         0   \n",
       "\n",
       "   predicted_onsite_parking_gross_revenue  total_parking  \\\n",
       "0                                35268.75           3534   \n",
       "1                                74418.75           3800   \n",
       "2                                    0.00             76   \n",
       "3                                    0.00            120   \n",
       "4                                    0.00           1385   \n",
       "5                                    0.00           1329   \n",
       "6                                    0.00             31   \n",
       "7                                    0.00            189   \n",
       "8                                    0.00             31   \n",
       "9                                    0.00            188   \n",
       "\n",
       "   predicted_gross_revenue  \n",
       "0                117809.75  \n",
       "1                177321.75  \n",
       "2                  5520.00  \n",
       "3                  5520.00  \n",
       "4                 40590.00  \n",
       "5                 40590.00  \n",
       "6                  2480.00  \n",
       "7                 16240.00  \n",
       "8                  2480.00  \n",
       "9                 16080.00  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_parking_model_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

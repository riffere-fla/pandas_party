{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22518629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124f244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tickets, Nightly Suites, Turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29721c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get game info data\n",
    "\n",
    "q = \"\"\"\n",
    "select \n",
    "    date(event_date) as event_date,\n",
    "    tier,\n",
    "    is_premier, \n",
    "    cast(original_six_plus_extra*100 as int) as original_six_plus_extra\n",
    "from  \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "tier_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "pl_tier_df = pl.from_pandas(tier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba38c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 23/24 playoff ticket data\n",
    "\n",
    "#df_2324 = pl.read_csv(\"C:\\\\Users\\\\riffere\\\\Florida Panthers\\\\SP-BS - Documents\\\\Data Science\\\\Resources\\\\Files\\\\emily_ticket_sales_model_data_final.csv\")  \n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "         event_date,\n",
    "        CASE\n",
    "            WHEN pc_one IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN pc_one IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN pc_one IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN pc_one IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN pc_one IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        case\n",
    "            when allocations like '%Kill%' or locks like '%Kill%' then 0\n",
    "            else 1\n",
    "        end as capacity\n",
    "    from\n",
    "        custom.cth_v_ticket_status_2324_playoffs),\n",
    "arena_level_agg as\n",
    "    (select\n",
    "         event_date,\n",
    "         arena_level_internal,\n",
    "         sum(capacity) as capacity\n",
    "    from\n",
    "        arena_levels\n",
    "    group by\n",
    "        event_date,\n",
    "        arena_level_internal),\n",
    "ticket_info as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        datediff('days',date(transaction_date), date(event_datetime)) as days_out,\n",
    "        arena_level_internal,\n",
    "        sum(paid_seats) as paid_seats,\n",
    "        sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2324_playoffs\n",
    "    group by\n",
    "        event_datetime,\n",
    "        date(transaction_date),\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(arena_level_agg.event_date) as event_date,\n",
    "    ticket_info.days_out,\n",
    "    arena_level_agg.arena_level_internal,\n",
    "    capacity,\n",
    "    case\n",
    "        when arena_level_agg.arena_level_internal = 'Lowers' AND days_out > 80 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Uppers' AND days_out > 100 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Clubs' AND days_out > 50 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Premium' AND days_out > 30 THEN 0\n",
    "        else paid_seats\n",
    "        end as paid_seats\n",
    "from\n",
    "    arena_level_agg\n",
    "left join\n",
    "    ticket_info on date(arena_level_agg.event_date) = date(ticket_info.event_datetime)\n",
    "    and arena_level_agg.arena_level_internal = ticket_info.arena_level_internal\n",
    "order by\n",
    "    event_date,\n",
    "    arena_level_internal,\n",
    "    days_out\n",
    "\"\"\"\n",
    "\n",
    "df_2324 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "df_2324 = pl.from_pandas(df_2324)\n",
    "\n",
    "### coalesce(gross_revenue::int,0) as gross_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tickets left to sell by days out descending\n",
    "\n",
    "#df_2324['cumulative_tickets']  = df_2324.groupby(['event_date', 'arena_level_internal'])['paid_seats'].cumsum()\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col(\"paid_seats\").cum_sum().over([\"event_date\", \"arena_level_internal\"]).cast(pl.Int16).alias(\"cumulative_tickets\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join game info data on 24/25 ticket data\n",
    "\n",
    "#df_2324 = df_2324.merge(tier_df, on = 'event_date', how = 'left')\n",
    "df_2324 = df_2324.join(pl_tier_df, on=\"event_date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f19fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2324.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('event_date').cast(pl.Date)\n",
    "# ])\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('gross_revenue').cast(pl.Int16)\n",
    "# ])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
    ")\n",
    "\n",
    "arena_level_mapping = {\n",
    "    'Clubs': 5,\n",
    "    'Lowers': 4,\n",
    "    'Uppers': 3,\n",
    "    'Suites': 2,\n",
    "    'Premium': 1\n",
    "}\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('arena_level_internal')\n",
    "      .replace(arena_level_mapping, default=0)\n",
    "      .cast(pl.Int16)\n",
    "      .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining')\n",
    ")\n",
    "\n",
    "df_2324 = df_2324.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) &\n",
    "    (pl.col(\"days_out\") >= 0) &\n",
    "    (pl.col('arena_level_internal').is_in(['Clubs','Lowers','Uppers','Suites','Premium']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 23/24 playoff ticket data\n",
    "\n",
    "#df_2324 = pl.read_csv(\"C:\\\\Users\\\\riffere\\\\Florida Panthers\\\\SP-BS - Documents\\\\Data Science\\\\Resources\\\\Files\\\\emily_ticket_sales_model_data_final.csv\")  \n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "         event_date,\n",
    "        CASE\n",
    "            WHEN pc_one IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN pc_one IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN pc_one IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN pc_one IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN pc_one IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        case\n",
    "            when allocations like '%Kill%' or locks like '%Kill%' then 0\n",
    "            else 1\n",
    "        end as capacity\n",
    "    from\n",
    "        custom.cth_v_ticket_status_2425_playoffs),\n",
    "arena_level_agg as\n",
    "    (select\n",
    "         event_date,\n",
    "         arena_level_internal,\n",
    "         sum(capacity) as capacity\n",
    "    from\n",
    "        arena_levels\n",
    "    group by\n",
    "        event_date,\n",
    "        arena_level_internal),\n",
    "ticket_info as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        datediff('days',date(transaction_date), date(event_datetime)) as days_out,\n",
    "        arena_level_internal,\n",
    "        sum(paid_seats) as paid_seats,\n",
    "        sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2425_playoffs\n",
    "    group by\n",
    "        event_datetime,\n",
    "        date(transaction_date),\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(arena_level_agg.event_date) as event_date,\n",
    "    ticket_info.days_out,\n",
    "    arena_level_agg.arena_level_internal,\n",
    "    capacity,\n",
    "    case\n",
    "        when arena_level_agg.arena_level_internal = 'Lowers' AND days_out > 80 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Uppers' AND days_out > 100 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Clubs' AND days_out > 50 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Premium' AND days_out > 30 THEN 0\n",
    "        else paid_seats\n",
    "        end as paid_seats\n",
    "from\n",
    "    arena_level_agg\n",
    "left join\n",
    "    ticket_info on date(arena_level_agg.event_date) = date(ticket_info.event_datetime)\n",
    "    and arena_level_agg.arena_level_internal = ticket_info.arena_level_internal\n",
    "order by\n",
    "    event_date,\n",
    "    arena_level_internal,\n",
    "    days_out\n",
    "\"\"\"\n",
    "\n",
    "df_2324 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "df_2324 = pl.from_pandas(df_2324)\n",
    "\n",
    "### coalesce(gross_revenue::int,0) as gross_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2425['dow'] = [datetime.weekday(x) for x in df_2425['event_datetime']]\n",
    "# df_2425['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2425['tier']]\n",
    "#df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "\n",
    "\n",
    "# df_2425['arena_level_num'] = [6 if arena_level_internal == 'Premium' else (5 if arena_level_internal == 'Clubs' else (4 if arena_level_internal == 'Lowers' else \n",
    "#                             (3 if arena_level_internal == 'Uppers' else (2 if arena_level_internal == 'Suites' else 1)))) for arena_level_internal in df_2425['arena_level_internal']]\n",
    "\n",
    "#df_2425 = df_2425.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2425 = df_2425.reset_index()\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2425['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2425 = df_2425.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
    "])\n",
    "\n",
    "arena_level_mapping = {\n",
    "    'Clubs': 5,\n",
    "    'Lowers': 4,\n",
    "    'Uppers': 3,\n",
    "    'Suites': 2,\n",
    "    'Premium': 1\n",
    "}\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('arena_level_internal')\n",
    "      .replace(arena_level_mapping, default=0)\n",
    "      .cast(pl.Int16)\n",
    "      .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "# df_2425 = df_2425.with_columns(\n",
    "#     pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining'))\n",
    "\n",
    "df_2425 = df_2425.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) &\n",
    "    (pl.col(\"days_out\") >= 0) &\n",
    "     (pl.col('arena_level_internal').is_in(['Clubs','Lowers','Uppers','Suites','Premium']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2425.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "# def run_model(df, df_future, arena_level):\n",
    "\n",
    "#     x_train_table = df.filter(\n",
    "#         (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "\n",
    "#     X_train = x_train_table.select(['tier_num', 'arena_level_num', 'days_out', 'cap_remaining'])\n",
    "#     y_train = x_train_table.select(['cumulative_tickets'])\n",
    "\n",
    "#     x_test_table = df_future.filter(\n",
    "#         (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "#     X_test = x_test_table.select(['tier_num', 'arena_level_num', 'days_out', 'cap_remaining'])\n",
    "\n",
    "#     ss = StandardScaler()\n",
    "#     x_train_scaled = ss.fit_transform(X_train)\n",
    "#     x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "#     polynomial = LinearRegression().fit(x_train_scaled, np.array(y_train).ravel())\n",
    "\n",
    "#     return polynomial.predict(x_test_scaled)\n",
    "\n",
    "def run_model(df, df_future, arena_level):\n",
    "\n",
    "    x_train_table = df.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "\n",
    "    X_train = x_train_table.select(['tier_num', 'arena_level_num', 'days_out', 'is_premier'])\n",
    "    y_train = x_train_table.select(['cumulative_tickets'])\n",
    "\n",
    "    x_test_table = df_future.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    X_test = x_test_table.select(['tier_num', 'arena_level_num', 'days_out', 'is_premier'])\n",
    "\n",
    "    # poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "    # x_train_poly = poly.fit_transform(X_train)\n",
    "    # x_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    x_train_poly = ss.fit_transform(X_train)\n",
    "    x_test_poly = ss.fit_transform(X_test)\n",
    "\n",
    "    # x_train_poly = np.array(X_train)\n",
    "    # x_test_poly = np.array(X_test)\n",
    "\n",
    "    #polynomial = sm.OLS(np.array(y_train).ravel(), x_train_poly).fit()\n",
    "\n",
    "    y_log = np.nan_to_num(np.log(np.array(y_train).ravel()), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    polynomial = LinearRegression().fit(x_train_poly, y_log)\n",
    "\n",
    "    #print(polynomial.aic)\n",
    "\n",
    "    return polynomial.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run by arena_level NOT SUITES!\n",
    "\n",
    "arena_levels = ['Lowers','Premium','Uppers','Clubs']\n",
    "\n",
    "final_df = pl.DataFrame(\n",
    "    schema= {\n",
    "        'event_date': pl.Date,\n",
    "        'arena_level_internal': pl.String,\n",
    "        'days_out': pl.Int16,\n",
    "        'tier': pl.String,\n",
    "        'original_six_plus_extra': pl.Int16,\n",
    "        'is_premier': pl.Boolean,\n",
    "        'capacity': pl.Int16,\n",
    "        'gross_revenue' : pl.Float64,\n",
    "        'paid_seats': pl.Int16,\n",
    "        'cap_remaining': pl.Int16,\n",
    "        'dow': pl.Int16,\n",
    "        'tier_num': pl.Int16,\n",
    "        'arena_level_num': pl.Int16,\n",
    "        'literal' : pl.Float64\n",
    "    }\n",
    ")\n",
    "\n",
    "for arena_level in arena_levels:\n",
    "\n",
    "    temp = df_2425.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    result = run_model(df_2324, df_2425, arena_level)\n",
    "\n",
    "    temp = temp.with_columns([result])\n",
    "\n",
    "    final_df = pl.concat([final_df,temp], how = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6828a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_df = df_2425.filter((pl.col(\"arena_level_internal\").is_in(['Suites'])))\n",
    "suite_df = suite_df.with_columns(pl.zeros(pl.count()).alias('literal'))\n",
    "\n",
    "final_df = pl.concat([final_df,suite_df], how = 'vertical')\n",
    "final_df = final_df.rename({'literal':'cumulative_tickets_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total tickets prediction\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('cumulative_tickets_predicted')).exp()\n",
    "    .alias('cumulative_tickets_predicted'))\n",
    "])\n",
    "\n",
    "# create cumulative_tickets_predicted column so its greater than 0 and less than cap_remianing\n",
    "\n",
    "final_df = final_df.with_columns(\n",
    "        pl.when(pl.col(\"cumulative_tickets_predicted\") < 0)\n",
    "        .then(0)\n",
    "        .when(pl.col(\"cap_remaining\") < pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .then(pl.col(\"cap_remaining\"))\n",
    "        .otherwise(pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .alias(\"cumulative_tickets_predicted\")\n",
    ")\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('paid_seats') + pl.col('cumulative_tickets_predicted'))\n",
    "    .alias('total_predicted_tickets'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6590d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rate data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "    \n",
    "        game_desc.season,\n",
    "        game_desc.tier,\n",
    "        arena_level_internal,\n",
    "        ticket.event_date::date,\n",
    "        ticket.comp_seats::float,\n",
    "        ticket.paid_seats::float,\n",
    "        CASE\n",
    "            WHEN ticket.is_comp = TRUE AND ticket.did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"comp_seats_attended\",\n",
    "        CASE\n",
    "            WHEN is_comp = FALSE AND did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"paid_seats_attended\"\n",
    "    FROM\n",
    "        custom.cth_v_historical_ticket ticket\n",
    "    INNER JOIN\n",
    "        custom.cth_game_descriptions game_desc\n",
    "            ON ticket.event_datetime::date = game_desc.event_datetime::date\n",
    "            AND game_desc.season IN ('2021-22', '2022-23', '2023-24', '2024-25')\n",
    "            AND game_desc.event_datetime < current_date\n",
    "),\n",
    "tier_show_rate AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        tier,\n",
    "        arena_level_internal,\n",
    "        sum(historical.comp_seats_attended)::float / nullif(sum(historical.comp_seats),0) AS \"comp_show_rate\",\n",
    "        sum(historical.paid_seats_attended)::float / nullif(sum(historical.paid_seats),0) AS \"paid_show_rate\"\n",
    "    FROM\n",
    "        historical\n",
    "    GROUP BY\n",
    "        season, tier, arena_level_internal\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tier_show_rate\n",
    "where \n",
    "    tier != 'F'\n",
    "\"\"\"\n",
    "\n",
    "show_rate = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weighted show_rate avergaes over last 4 seasons\n",
    "\n",
    "weights = {'2021-22':0.5, '2022-23': .75, '2023-24':1.25,'2024-25':1.5}\n",
    "\n",
    "show_rate['weights'] = show_rate['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['paid_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_paid_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_paid_average).reset_index()\n",
    "\n",
    "def weighted_comp_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['comp_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_comp_average': wavg\n",
    "    })\n",
    "\n",
    "comp_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_comp_average).reset_index()\n",
    "\n",
    "tiers = pd.merge(paid_tiers, comp_tiers, on = ['tier', 'arena_level_internal'], how = 'left')\n",
    "tiers = pl.from_pandas(tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto 24/25 data and predict attendance\n",
    "\n",
    "final_df = final_df.join(tiers, on = ['tier','arena_level_internal'])\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('total_predicted_tickets') * pl.col('weighted_paid_average'))\n",
    "    .alias('total_attendance'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merch, F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "with attendance as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        count(*) as attendance\n",
    "    from\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    group by\n",
    "        event_datetime\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        count(*) as attendance\n",
    "    from\n",
    "        custom.cth_v_attendance_2425_playoffs\n",
    "    group by\n",
    "        event_datetime)\n",
    "select\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    gross_revenue,\n",
    "    num_orders,\n",
    "    quantity_sold\n",
    "from\n",
    "    custom.cheq_v_hockey_summary\n",
    "left join\n",
    "    custom.cth_game_descriptions on date(cheq_v_hockey_summary.event_date) = date(cth_game_descriptions.event_date)\n",
    "left join\n",
    "    attendance on date(attendance.event_datetime) = date(cheq_v_hockey_summary.event_date)\n",
    "where\n",
    "    tier in ('A','B','C','D','E')\n",
    "\"\"\"\n",
    "\n",
    "historical_f_and_b = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "historical_f_and_b['weekend'] = historical_f_and_b.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "historical_f_and_b['start_time_num'] = historical_f_and_b.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "historical_f_and_b['tier_num'] = historical_f_and_b.apply(\n",
    "    lambda row: tier_mapping.get(row['tier'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ea073",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "with attendance as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        count(*) as attendance\n",
    "    from\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    group by\n",
    "        event_datetime\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        count(*) as attendance\n",
    "    from\n",
    "        custom.cth_v_attendance_2425_playoffs\n",
    "    group by\n",
    "        event_datetime)\n",
    "select\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    sum(gross_revenue) as gross_revenue,\n",
    "    sum(qty) as quantity,\n",
    "    count(distinct invoice_id) as num_orders\n",
    "from\n",
    "    custom.retailpro_v_invoice_items\n",
    "left join\n",
    "    custom.cth_game_descriptions on retailpro_v_invoice_items.event_date = cth_game_descriptions.event_date\n",
    "left join\n",
    "    attendance on retailpro_v_invoice_items.event_date = date(attendance.event_datetime)\n",
    "where\n",
    "    season in ('2023-24','2024-25')\n",
    "group by\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance\n",
    "\"\"\"\n",
    "\n",
    "historical_merch = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "historical_merch['weekend'] = historical_merch.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "historical_merch['start_time_num'] = historical_merch.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "historical_merch['tier_num'] = historical_merch.apply(\n",
    "    lambda row: tier_mapping.get(row['tier'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    season,\n",
    "    event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time\n",
    "from\n",
    "    custom.cth_game_descriptions\n",
    "where\n",
    "    event_date >= current_date\n",
    "\"\"\"\n",
    "\n",
    "future_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "predicted_attendance = pd.read_csv('C:\\\\Users\\\\riffere\\\\Desktop\\\\output.csv')\n",
    "\n",
    "future_game_info = future_game_info.merge(predicted_attendance, how = 'left', on = 'event_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "future_game_info['weekend'] = future_game_info.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "future_game_info['start_time_num'] = future_game_info.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "future_game_info['tier_num'] = future_game_info.apply(\n",
    "    lambda row: tier_mapping.get(row['tier'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df84fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_f_and_b_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbadb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_f_and_b_gross_rev'] = run_f_and_b_model(historical_f_and_b, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fe792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_merch_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_merch_gross_rev'] = run_merch_model(historical_merch, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rates by tier and lot\n",
    "\n",
    "q = \"\"\"\n",
    "with prepaid as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         location_group\n",
    "    from\n",
    "        custom.ctp_v_ticket_2324\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    from\n",
    "        custom.ctp_v_ticket_2425\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date),\n",
    "prepaid_agg as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        count(*) as prepaid_passes\n",
    "    from\n",
    "        prepaid\n",
    "    group by\n",
    "        event_datetime, location_group),\n",
    "scans as\n",
    "    (select\n",
    "        season,\n",
    "        cth_game_descriptions.event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "            else 0 end as num_scans\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        cth_game_descriptions.event_datetime is not Null\n",
    "        and season in ('2023-24','2024-25')),\n",
    "scans_agg as\n",
    "    (select\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        sum(num_scans) as num_scans\n",
    "    from\n",
    "        scans\n",
    "    group by\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group)\n",
    "select\n",
    "    season,\n",
    "    prepaid_agg.event_datetime,\n",
    "    tier,\n",
    "    prepaid_agg.location_group,\n",
    "    prepaid_passes,\n",
    "    num_scans,\n",
    "    num_scans*1.0/prepaid_passes::float as show_rate\n",
    "from\n",
    "    scans_agg\n",
    "left join\n",
    "    prepaid_agg on scans_agg.event_datetime = prepaid_agg.event_datetime\n",
    "    and scans_agg.location_group = prepaid_agg.location_group\n",
    "where\n",
    "    prepaid_agg.event_datetime is not Null\n",
    "\"\"\"\n",
    "\n",
    "show_rate_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weigh this past season more heavily\n",
    "\n",
    "weights = {'2023-24':1.25,'2024-25':2.75}\n",
    "\n",
    "show_rate_df['weights'] = show_rate_df['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical prepaid parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with prepaid as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         location_group,\n",
    "         date(transaction_date) as transaction_date\n",
    "    from\n",
    "        custom.ctp_v_ticket_2324\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date\n",
    "    UNION ALL\n",
    "    select\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        date(transaction_date) as transaction_date\n",
    "    from\n",
    "        custom.ctp_v_ticket_2425\n",
    "    where\n",
    "        event_type ilike '%panthers%'\n",
    "        and event_datetime < current_date)\n",
    "select\n",
    "    date(event_datetime) as event_date,\n",
    "    location_group,\n",
    "    'prepaid' as parking_type,\n",
    "    datediff('days',transaction_date, event_datetime) as days_out,\n",
    "    case\n",
    "        when days_out >= 150 then 0\n",
    "        else count(*) \n",
    "    end as num_passes\n",
    "from\n",
    "    prepaid\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    event_datetime,\n",
    "    location_group,\n",
    "    transaction_date\n",
    "order by\n",
    "    event_datetime,\n",
    "    location_group,\n",
    "    transaction_date desc\n",
    "\"\"\"\n",
    "\n",
    "historical_prepaid_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "location_map = {\n",
    "    'Club': 4,\n",
    "    'Garage': 3,\n",
    "    'General': 2,\n",
    "    'Valet': 1\n",
    "}\n",
    "\n",
    "historical_prepaid_parking_info['location_num'] = historical_prepaid_parking_info.apply(\n",
    "    lambda row: location_map.get(row['location_group'], 0), axis=1)\n",
    "\n",
    "historical_prepaid_parking_info['cumulative_num_passes']  = historical_prepaid_parking_info.groupby(['event_date', 'location_group'])['num_passes'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical game data (ie tier, dow, and start time)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    date(cth_game_descriptions.event_date) as event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    total_tickets\n",
    "FROM\n",
    "    custom.cth_v_historical_attendance_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions on cth_v_historical_attendance_summary.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    tier in ('A','B','C','D','E')\n",
    "\"\"\"\n",
    "\n",
    "all_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "all_game_info['weekend'] = all_game_info.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "all_game_info['start_time_num'] = all_game_info.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming game data including current prepaid totals by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "select\n",
    "    date(cth_game_descriptions.event_datetime) as event_date,\n",
    "    datediff('day', current_date, cth_game_descriptions.event_datetime) as days_out,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity::int,\n",
    "    sum(paid_seats)+sum(comp_seats) as prepaid_cars,\n",
    "    sum(gross_revenue) as current_gross_revenue,\n",
    "    capacity::int - prepaid_cars as cap_remaining\n",
    "from\n",
    "    custom.ctp_v_ticket_2425\n",
    "left join\n",
    "    custom.ctp_parking_capacities on ctp_v_ticket_2425.location_group = ctp_parking_capacities.location_group\n",
    "left join\n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "where\n",
    "    cth_game_descriptions.event_datetime is not null and\n",
    "    cth_game_descriptions.event_datetime >= current_date\n",
    "group by\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity\n",
    "order by\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group\n",
    "\"\"\"\n",
    "\n",
    "upcoming_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24488c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming pricing data by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    tier,\n",
    "    location_group,\n",
    "    max(transaction_date) AS \"transaction_date\",\n",
    "    max(adjusted_price) AS \"highest_price\"\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN             \n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    is_comp = FALSE\n",
    "    AND price_type ILIKE 'IA%'\n",
    "GROUP BY\n",
    "    tier, \n",
    "    location_group\n",
    "\"\"\"\n",
    "\n",
    "pricing_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict remaining prepaid cars\n",
    "\n",
    "def run_prepaid_model(df, df_future, lot):\n",
    "\n",
    "    total_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = total_table[['days_out','weekend','start_time_num']]\n",
    "    y_train = total_table[['cumulative_num_passes']]\n",
    "\n",
    "    total_future_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = total_future_table[['days_out','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_table = historical_prepaid_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_table = total_table[total_table['tier'].isin(['A','B','C','D','E'])]\n",
    "\n",
    "# merge upcoming parking data with hisorical game data for testing model\n",
    "\n",
    "total_future_table = upcoming_game_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_future_table = total_future_table[total_future_table['tier'].isin(['A','B','C','D','E'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7351843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only predicting for general and garage not  club, valet or executive\n",
    "\n",
    "lots = ['General','Garage']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = total_future_table[total_future_table['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
    "\n",
    "    final_df = pd.concat([final_df,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ddaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat club totals for onsite model next\n",
    "\n",
    "club_totals = total_future_table[total_future_table['location_group'] == 'Club']\n",
    "club_totals['predicted_parking'] = 0\n",
    "\n",
    "final_df = pd.concat([final_df, club_totals], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no negative predictions are made\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['predicted_parking'] < 0, 0, final_df['predicted_parking'])\n",
    "\n",
    "# get total prepaid tickets (current + predicted additional)\n",
    "\n",
    "final_df['total_predicted_prepaid_cars'] = final_df['prepaid_cars'] + final_df['predicted_parking']\n",
    "\n",
    "# get number of parked cars using historical show rates\n",
    "\n",
    "final_df = final_df.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "final_df['prepaid_cars_parked'] = (final_df['total_predicted_prepaid_cars'] * final_df['weighted_average']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6360b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the capacity remaining \n",
    "\n",
    "final_df['cap_remaining'] = final_df['capacity'] - final_df['prepaid_cars_parked']\n",
    "\n",
    "# if predicted cars over capacity subtract overflow out\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['cap_remaining'] < 0, final_df['predicted_prepaid_additional_parking']+final_df['cap_remaining'], final_df['predicted_prepaid_additional_parking'])\n",
    "final_df['prepaid_cars_parked'] = np.where(final_df['cap_remaining'] < 0, final_df['prepaid_cars_parked']+final_df['cap_remaining'], final_df['prepaid_cars_parked'])\n",
    "final_df['cap_remaining'] = np.where(final_df['cap_remaining'] < 0, 0, final_df['prepaid_cars_parked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['event_date','days_out','tier', 'start_time_num','weekend',\n",
    "                     'location_group','capacity','prepaid_cars','current_gross_revenue', \n",
    "                     'predicted_prepaid_additional_parking', 'total_predicted_prepaid_cars',\n",
    "                     'prepaid_cars_parked','cap_remaining']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c556e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hisotrical onsite parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with onsite as\n",
    "    (select\n",
    "        date(cth_game_descriptions.event_datetime) as event_date,\n",
    "        location_group,\n",
    "        0 as days_out,\n",
    "        case\n",
    "            when paid_amount > 0 then 1\n",
    "        else 0\n",
    "        end as num_onsite_cars,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "        else 0\n",
    "        end as num_prepaid_cars\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        season in ('2023-24','2024-25'))\n",
    "select\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    'onsite' as parking_type,\n",
    "    days_out,\n",
    "    sum(num_onsite_cars) as num_cars,\n",
    "    capacity - sum(num_prepaid_cars) as cap_remaining\n",
    "from\n",
    "    onsite\n",
    "left join\n",
    "    custom.ctp_parking_capacities on onsite.location_group = ctp_parking_capacities.location_group\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    parking_type,\n",
    "    days_out,\n",
    "    capacity\n",
    "\"\"\"\n",
    "\n",
    "historical_onsite_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_onsite_table = historical_onsite_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_onsite_table = total_onsite_table[total_onsite_table['tier'].isin(['A','B','C','D','E'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce33fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict onsite cars\n",
    "\n",
    "def run_onsite_model(df, df_future, lot):\n",
    "\n",
    "    x_train_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = x_train_table[['cap_remaining','weekend','start_time_num']]\n",
    "    y_train = x_train_table[['num_cars']]\n",
    "\n",
    "    x_test_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = x_test_table[['cap_remaining','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    #predicted_test = polynomial.predict(poly_features2)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only predicting for general, garage, and club not valet or executive\n",
    "\n",
    "lots = ['General','Garage','Club']\n",
    "\n",
    "final_df_onsite = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = final_df[final_df['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
    "\n",
    "    final_df_onsite = pd.concat([final_df_onsite,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back executive and valet parking and match fields from final_df\n",
    "\n",
    "exec_and_valet = total_future_table[total_future_table['location_group'].isin(['Executive','Valet'])]\n",
    "\n",
    "exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
    "exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n",
    "\n",
    "exec_and_valet = exec_and_valet.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "exec_and_valet['weighted_average'] = exec_and_valet['weighted_average'].fillna(1)\n",
    "\n",
    "exec_and_valet['prepaid_cars_parked'] = (exec_and_valet['total_predicted_prepaid_cars'] * exec_and_valet['weighted_average']).astype(int)\n",
    "exec_and_valet['predicted_onsite_parking'] = 0\n",
    "exec_and_valet['total_parking'] = exec_and_valet['prepaid_cars_parked'] \n",
    "\n",
    "exec_and_valet = exec_and_valet[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked',\n",
    "                                       'predicted_onsite_parking','total_parking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b53053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if predicted total over capacity subtract overflow out\n",
    "\n",
    "final_df_onsite['predicted_onsite_parking'] = [pred_onsite if pred_onsite <= cap_remaining else cap_remaining for pred_onsite, cap_remaining in zip(final_df_onsite['predicted_onsite_parking'], final_df_onsite['cap_remaining'])]\n",
    "\n",
    "final_df_onsite['total_parking'] = final_df_onsite['prepaid_cars_parked'] + final_df_onsite['predicted_onsite_parking']\n",
    "\n",
    "final_parking_model = final_df_onsite[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking','total_predicted_prepaid_cars',\n",
    "                                       'prepaid_cars_parked','predicted_onsite_parking','total_parking']]\n",
    "\n",
    "# merge with executive and valet parking info\n",
    "\n",
    "final_parking_model_df = pd.concat([final_parking_model, exec_and_valet], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parking_model_df = final_parking_model_df.merge(pricing_info, how = 'left', on = ['tier', 'location_group'])\n",
    "\n",
    "final_parking_model_df['predicted_prepaid_additional_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_onsite_parking_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']*1.25).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_gross_revenue'] = final_parking_model_df['predicted_prepaid_additional_gross_revenue'] + final_parking_model_df['predicted_onsite_parking_gross_revenue'] + final_parking_model_df['current_gross_revenue']\n",
    "\n",
    "final_parking_model_df = final_parking_model_df[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking', 'predicted_prepaid_additional_gross_revenue',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked', 'predicted_onsite_parking',\n",
    "                                       'predicted_onsite_parking_gross_revenue','total_parking', 'predicted_gross_revenue']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

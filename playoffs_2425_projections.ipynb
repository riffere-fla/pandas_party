{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22518629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124f244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69e2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tickets, Nightly Suites, Turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get past singles data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH playoffs_22_23 AS (\n",
    "    SELECT\n",
    "        '2022-23' AS season,\n",
    "        LEFT(RIGHT(event_name, 4), 2) AS round,\n",
    "        event_name,\n",
    "        date(event_date) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(add_datetime), DATE(event_date)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(add_datetime), DATE(event_date))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(block_purchase_price) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_ticket_expanded_all_playoffs_2223\n",
    "    WHERE\n",
    "        event_name IN ('23POR1G1', '23POR1G2', '23POR1G3', '23POR2G1', '23POR2G2', '23POR3G1', '23POR3G2', '23POR4G1', '23POR4G2')\n",
    "        AND ticket_type IN ('Singles')\n",
    "    GROUP BY\n",
    "        event_name,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type\n",
    "),\n",
    "playoffs_23_24 AS (\n",
    "    SELECT\n",
    "        '2023-24' AS season,\n",
    "        RIGHT(LEFT(product_description, 6), 2) AS round,\n",
    "        LEFT(product_description, 8) AS event_name,\n",
    "        date(event_datetime) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(gross_revenue) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2324_playoffs\n",
    "    WHERE\n",
    "        ticket_type_playoffs IN ('Singles')\n",
    "        AND event_name != '23-24 Pl'\n",
    "    GROUP BY\n",
    "        product_description,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type_playoffs\n",
    "),\n",
    "playoffs_24_25 AS (\n",
    "    SELECT\n",
    "        '2024-25' AS season,\n",
    "        RIGHT(LEFT(product_description, 6), 2) AS round,\n",
    "        LEFT(product_description, 8) AS event_name,\n",
    "        date(event_datetime) as event_date,\n",
    "        CASE\n",
    "            WHEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime)) >= 0\n",
    "                THEN DATEDIFF('days', DATE(transaction_date), DATE(event_datetime))\n",
    "            ELSE 0\n",
    "        END AS days_out,\n",
    "        SUM(gross_revenue) AS gross_revenue,\n",
    "        SUM(paid_seats) AS paid_seats\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2425_playoffs\n",
    "    WHERE\n",
    "        ticket_type_playoffs IN ('Singles')\n",
    "        AND event_name != '24-25 Pl'\n",
    "    GROUP BY\n",
    "        product_description,\n",
    "        event_date,\n",
    "        days_out,\n",
    "        ticket_type_playoffs\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_22_23\n",
    "UNION ALL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_23_24\n",
    "UNION ALL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    playoffs_24_25\n",
    "ORDER BY\n",
    "    season,\n",
    "    round,\n",
    "    event_name,\n",
    "    days_out DESC\n",
    "\"\"\"\n",
    "\n",
    "ticket_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511c32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_20572\\2629162886.py:5: FutureWarning: The 'axis' keyword in DataFrame.groupby is deprecated and will be removed in a future version.\n",
      "  cumdf = ticket_df.groupby(by = ['round','event_name','event_date'], axis = 0)[['gross_revenue','paid_seats']].cumsum().rename(columns = {'gross_revenue':'cum_gross_rev', 'paid_seats':'cum_num_seats'})\n"
     ]
    }
   ],
   "source": [
    "# get average tickets sold by days out from previous seasons\n",
    "\n",
    "ticket_df['min_days_out'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])]['days_out'].min(), axis = 1)\n",
    "\n",
    "cumdf = ticket_df.groupby(by = ['round','event_name','event_date'], axis = 0)[['gross_revenue','paid_seats']].cumsum().rename(columns = {'gross_revenue':'cum_gross_rev', 'paid_seats':'cum_num_seats'})\n",
    "\n",
    "ticket_df = pd.concat([ticket_df,cumdf], axis = 1)\n",
    "\n",
    "ticket_df['final_seats'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])&\n",
    "                                                  (ticket_df['days_out'] == row['min_days_out'])]['cum_num_seats'].item(), axis = 1)\n",
    "\n",
    "ticket_df['per_seats_in'] = [x/y for x,y in zip(ticket_df['cum_num_seats'],ticket_df['final_seats'])]\n",
    "\n",
    "ticket_df['final_rev'] = ticket_df.apply(lambda row: ticket_df[(ticket_df['event_name'] == row['event_name'])&\n",
    "                                                  (ticket_df['days_out'] == row['min_days_out'])]['cum_gross_rev'].item(), axis = 1)\n",
    "\n",
    "ticket_df['per_rev_in'] = [x/y for x,y in zip(ticket_df['cum_gross_rev'],ticket_df['final_rev'])]\n",
    "\n",
    "ticket_df = ticket_df[['season','round', 'event_name', 'event_date','days_out','gross_revenue','paid_seats', 'cum_gross_rev','cum_num_seats','per_seats_in','per_rev_in']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2273bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge averages back to 24/25 season\n",
    "\n",
    "df_train = ticket_df[ticket_df['season'] != '2024-25']\n",
    "\n",
    "df_2425 = ticket_df[ticket_df['season'] == '2024-25']\n",
    "\n",
    "df_avgs = df_train.groupby(by = ['round','days_out'])[['per_seats_in','per_rev_in']].mean().rename(columns = {'per_seats_in':'avg_per_seats_in','per_rev_in':'avg_per_rev_in'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93cd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict final singles totals for 24/25\n",
    "\n",
    "df_merged = df_2425.merge(right = df_avgs, how = 'left', on = ['round','days_out'])\n",
    "\n",
    "df_merged['paid_seats'] = df_merged['cum_num_seats']/df_merged['avg_per_seats_in']\n",
    "\n",
    "df_merged['gross_revenue'] = df_merged['cum_gross_rev']/df_merged['avg_per_rev_in']\n",
    "\n",
    "min_indices = df_merged.groupby('event_name')['days_out'].idxmin()\n",
    "\n",
    "result = df_merged.loc[min_indices]\n",
    "\n",
    "result['ticket_type_playoffs'] = 'Singles'\n",
    "\n",
    "result['tier'] = result['event_name'].str[-4:].str[:2]\n",
    "\n",
    "result = result[['event_name','event_date','tier','ticket_type_playoffs','paid_seats','gross_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0a6c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "event_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ticket_type_playoffs",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "paid_seats",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gross_revenue",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "05efd90d-f43a-4dbf-b69e-8884849a75ae",
       "rows": [
        [
         "20",
         "25POR1G1",
         "2025-04-26",
         "R1",
         "Singles",
         "1821.0",
         "374553.18"
        ],
        [
         "42",
         "25POR1G2",
         "2025-04-28",
         "R1",
         "Singles",
         "1518.0",
         "281894.17"
        ],
        [
         "51",
         "25POR2G1",
         "2025-05-09",
         "R2",
         "Singles",
         "1628.0",
         "872777.04"
        ],
        [
         "62",
         "25POR2G2",
         "2025-05-11",
         "R2",
         "Singles",
         "1740.0",
         "809060.97"
        ],
        [
         "78",
         "25POR2G3",
         "2025-05-16",
         "R2",
         "Singles",
         "1258.0",
         "445490.72000000003"
        ],
        [
         "84",
         "25POR3G1",
         "2025-05-24",
         "R3",
         "Singles",
         "1815.0",
         "546105.93"
        ],
        [
         "92",
         "25POR3G2",
         "2025-05-26",
         "R3",
         "Singles",
         "1830.0",
         "549828.75"
        ],
        [
         "94",
         "25POR4G1",
         "2025-06-09",
         "R4",
         "Singles",
         "1318.55040588094",
         "1530093.6648744233"
        ],
        [
         "96",
         "25POR4G2",
         "2025-06-12",
         "R4",
         "Singles",
         "1440.9359994854783",
         "1894087.980388382"
        ],
        [
         "98",
         "25POR4G3",
         "2025-06-17",
         "R4",
         "Singles",
         "1102.3773173391494",
         "3532695.6177647104"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_date</th>\n",
       "      <th>tier</th>\n",
       "      <th>ticket_type_playoffs</th>\n",
       "      <th>paid_seats</th>\n",
       "      <th>gross_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25POR1G1</td>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>R1</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1821.000000</td>\n",
       "      <td>3.745532e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25POR1G2</td>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>R1</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1518.000000</td>\n",
       "      <td>2.818942e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>25POR2G1</td>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>R2</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>8.727770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>25POR2G2</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>R2</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>8.090610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>25POR2G3</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>R2</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>4.454907e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>25POR3G1</td>\n",
       "      <td>2025-05-24</td>\n",
       "      <td>R3</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1815.000000</td>\n",
       "      <td>5.461059e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>25POR3G2</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>R3</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>5.498288e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>25POR4G1</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>R4</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1318.550406</td>\n",
       "      <td>1.530094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>25POR4G2</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>R4</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1440.935999</td>\n",
       "      <td>1.894088e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>25POR4G3</td>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>R4</td>\n",
       "      <td>Singles</td>\n",
       "      <td>1102.377317</td>\n",
       "      <td>3.532696e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_name  event_date tier ticket_type_playoffs   paid_seats  \\\n",
       "20   25POR1G1  2025-04-26   R1              Singles  1821.000000   \n",
       "42   25POR1G2  2025-04-28   R1              Singles  1518.000000   \n",
       "51   25POR2G1  2025-05-09   R2              Singles  1628.000000   \n",
       "62   25POR2G2  2025-05-11   R2              Singles  1740.000000   \n",
       "78   25POR2G3  2025-05-16   R2              Singles  1258.000000   \n",
       "84   25POR3G1  2025-05-24   R3              Singles  1815.000000   \n",
       "92   25POR3G2  2025-05-26   R3              Singles  1830.000000   \n",
       "94   25POR4G1  2025-06-09   R4              Singles  1318.550406   \n",
       "96   25POR4G2  2025-06-12   R4              Singles  1440.935999   \n",
       "98   25POR4G3  2025-06-17   R4              Singles  1102.377317   \n",
       "\n",
       "    gross_revenue  \n",
       "20   3.745532e+05  \n",
       "42   2.818942e+05  \n",
       "51   8.727770e+05  \n",
       "62   8.090610e+05  \n",
       "78   4.454907e+05  \n",
       "84   5.461059e+05  \n",
       "92   5.498288e+05  \n",
       "94   1.530094e+06  \n",
       "96   1.894088e+06  \n",
       "98   3.532696e+06  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87583ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current in from other ticket types\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    LEFT(product_description, 8) AS event_name,\n",
    "    RIGHT(LEFT(product_description,6),2) AS tier,\n",
    "    date(event_datetime) as event_date,\n",
    "    ticket_type_playoffs,\n",
    "    sum(gross_revenue) as gross_revenue,\n",
    "    sum(paid_seats) as paid_seats\n",
    "FROM\n",
    "    custom.cth_v_ticket_2425_playoffs\n",
    "WHERE\n",
    "    ticket_type_playoffs != 'Singles'\n",
    "GROUP BY\n",
    "    product_description,\n",
    "    event_date,\n",
    "    ticket_type_playoffs\n",
    "\"\"\"\n",
    "\n",
    "current_in = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8826198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_20572\\3416735621.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate.groupby(by = ['tier']).apply(weighted_paid_average).reset_index()\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_20572\\3416735621.py:85: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comp_tiers = show_rate.groupby(by = ['tier']).apply(weighted_comp_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# get weighted show_rate avergaes over last 4 seasons\n",
    "\n",
    "# get historical show rate data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "        game_desc.season,\n",
    "        game_desc.tier,\n",
    "        ticket.event_date::date,\n",
    "        ticket.comp_seats::float,\n",
    "        ticket.paid_seats::float,\n",
    "        CASE\n",
    "            WHEN ticket.is_comp = TRUE AND ticket.did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"comp_seats_attended\",\n",
    "        CASE\n",
    "            WHEN is_comp = FALSE AND did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"paid_seats_attended\"\n",
    "    FROM\n",
    "        custom.cth_v_historical_ticket ticket\n",
    "    INNER JOIN\n",
    "        custom.cth_game_descriptions game_desc\n",
    "            ON ticket.event_datetime::date = game_desc.event_datetime::date\n",
    "            AND game_desc.season IN ('2022-23', '2023-24', '2024-25')\n",
    "            AND game_desc.event_datetime < current_date\n",
    "),\n",
    "tier_show_rate AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        tier,\n",
    "        sum(historical.comp_seats_attended)::float / nullif(sum(historical.comp_seats),0) AS \"comp_show_rate\",\n",
    "        sum(historical.paid_seats_attended)::float / nullif(sum(historical.paid_seats),0) AS \"paid_show_rate\"\n",
    "    FROM\n",
    "        historical\n",
    "    GROUP BY\n",
    "        season,\n",
    "        tier\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tier_show_rate\n",
    "where\n",
    "    tier in ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "show_rate = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "weights = {'2022-23': .5, '2023-24':1,'2024-25':1.5}\n",
    "\n",
    "show_rate['weights'] = show_rate['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['paid_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_paid_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate.groupby(by = ['tier']).apply(weighted_paid_average).reset_index()\n",
    "\n",
    "def weighted_comp_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['comp_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_comp_average': wavg\n",
    "    })\n",
    "\n",
    "comp_tiers = show_rate.groupby(by = ['tier']).apply(weighted_comp_average).reset_index()\n",
    "\n",
    "tiers = pd.merge(paid_tiers, comp_tiers, on = ['tier'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46b2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto 24/25 data and predict attendance\n",
    "\n",
    "df_final = pd.concat([result,current_in])\n",
    "\n",
    "final_tickets_and_attendance = df_final.groupby(by = ['event_name','event_date', 'tier'])[['paid_seats','gross_revenue']].sum().reset_index()\n",
    "\n",
    "final_tickets_and_attendance = final_tickets_and_attendance.merge(tiers, how = 'left', on = 'tier')\n",
    "\n",
    "final_tickets_and_attendance['total_attendance'] = final_tickets_and_attendance['paid_seats'] * final_tickets_and_attendance['weighted_paid_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6822c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tickets_and_attendance = final_tickets_and_attendance[['event_name','event_date','tier','paid_seats','gross_revenue','total_attendance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcdea26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "event_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "paid_seats",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gross_revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_attendance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1ce8b02e-35ee-4dae-ad7e-4644a0e891c7",
       "rows": [
        [
         "0",
         "2024-25 ",
         "2025-06-30",
         "-2",
         "0.0",
         "0.0",
         null
        ],
        [
         "1",
         "25POR1G1",
         "2025-04-26",
         "R1",
         "18800.0",
         "2571834.209999972",
         "17783.72521188372"
        ],
        [
         "2",
         "25POR1G2",
         "2025-04-28",
         "R1",
         "18758.0",
         "2495215.939999972",
         "17743.995613006107"
        ],
        [
         "3",
         "25POR2G1",
         "2025-05-09",
         "R2",
         "19139.0",
         "3362859.360000024",
         "18342.064202058045"
        ],
        [
         "4",
         "25POR2G2",
         "2025-05-11",
         "R2",
         "19158.0",
         "3268123.990000035",
         "18360.273054131772"
        ],
        [
         "5",
         "25POR2G3",
         "2025-05-16",
         "R2",
         "18952.0",
         "3381040.050000043",
         "18162.850763227132"
        ],
        [
         "6",
         "25POR3G1",
         "2025-05-24",
         "R3",
         "19048.0",
         "4067036.250000016",
         "18404.560898098847"
        ],
        [
         "7",
         "25POR3G2",
         "2025-05-26",
         "R3",
         "19162.0",
         "4133486.260000016",
         "18514.70999209209"
        ],
        [
         "8",
         "25POR4G1",
         "2025-06-09",
         "R4",
         "18008.55040588094",
         "6681227.574874377",
         null
        ],
        [
         "9",
         "25POR4G2",
         "2025-06-12",
         "R4",
         "18145.93599948548",
         "7081371.160388323",
         null
        ],
        [
         "10",
         "25POR4G3",
         "2025-06-17",
         "R4",
         "17807.37731733915",
         "8736985.44776465",
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_date</th>\n",
       "      <th>tier</th>\n",
       "      <th>paid_seats</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>total_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-25</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25POR1G1</td>\n",
       "      <td>2025-04-26</td>\n",
       "      <td>R1</td>\n",
       "      <td>18800.000000</td>\n",
       "      <td>2.571834e+06</td>\n",
       "      <td>17783.725212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25POR1G2</td>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>R1</td>\n",
       "      <td>18758.000000</td>\n",
       "      <td>2.495216e+06</td>\n",
       "      <td>17743.995613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25POR2G1</td>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>R2</td>\n",
       "      <td>19139.000000</td>\n",
       "      <td>3.362859e+06</td>\n",
       "      <td>18342.064202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25POR2G2</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>R2</td>\n",
       "      <td>19158.000000</td>\n",
       "      <td>3.268124e+06</td>\n",
       "      <td>18360.273054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25POR2G3</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>R2</td>\n",
       "      <td>18952.000000</td>\n",
       "      <td>3.381040e+06</td>\n",
       "      <td>18162.850763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25POR3G1</td>\n",
       "      <td>2025-05-24</td>\n",
       "      <td>R3</td>\n",
       "      <td>19048.000000</td>\n",
       "      <td>4.067036e+06</td>\n",
       "      <td>18404.560898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25POR3G2</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>R3</td>\n",
       "      <td>19162.000000</td>\n",
       "      <td>4.133486e+06</td>\n",
       "      <td>18514.709992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25POR4G1</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>R4</td>\n",
       "      <td>18008.550406</td>\n",
       "      <td>6.681228e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25POR4G2</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>R4</td>\n",
       "      <td>18145.935999</td>\n",
       "      <td>7.081371e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25POR4G3</td>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>R4</td>\n",
       "      <td>17807.377317</td>\n",
       "      <td>8.736985e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_name  event_date tier    paid_seats  gross_revenue  total_attendance\n",
       "0    2024-25   2025-06-30   -2      0.000000   0.000000e+00               NaN\n",
       "1    25POR1G1  2025-04-26   R1  18800.000000   2.571834e+06      17783.725212\n",
       "2    25POR1G2  2025-04-28   R1  18758.000000   2.495216e+06      17743.995613\n",
       "3    25POR2G1  2025-05-09   R2  19139.000000   3.362859e+06      18342.064202\n",
       "4    25POR2G2  2025-05-11   R2  19158.000000   3.268124e+06      18360.273054\n",
       "5    25POR2G3  2025-05-16   R2  18952.000000   3.381040e+06      18162.850763\n",
       "6    25POR3G1  2025-05-24   R3  19048.000000   4.067036e+06      18404.560898\n",
       "7    25POR3G2  2025-05-26   R3  19162.000000   4.133486e+06      18514.709992\n",
       "8    25POR4G1  2025-06-09   R4  18008.550406   6.681228e+06               NaN\n",
       "9    25POR4G2  2025-06-12   R4  18145.935999   7.081371e+06               NaN\n",
       "10   25POR4G3  2025-06-17   R4  17807.377317   8.736985e+06               NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tickets_and_attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e2b08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nightly suite tickets\n",
    "\n",
    "q = \"\"\"\n",
    "WITH sold_suites AS (\n",
    "\n",
    "    WITH comp_temp AS (\n",
    "        SELECT\n",
    "            product_id,\n",
    "            section,\n",
    "            product_id || '-' || section AS \"id\",\n",
    "            'COMP'::varchar AS \"status\",\n",
    "            NULL::varchar AS \"locks\",\n",
    "            'Comp'::varchar AS \"allocations\",\n",
    "            sum(gross_revenue) AS \"gross_revenue\"\n",
    "        FROM\n",
    "            custom.cth_v_ticket_status_2425_playoffs\n",
    "        WHERE\n",
    "            (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "            AND status = 'SOLD'\n",
    "        GROUP BY\n",
    "            product_id,\n",
    "            section\n",
    "        HAVING\n",
    "            sum(gross_revenue) = 0\n",
    "    )\n",
    "\n",
    "    -- sold suites\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'SOLD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Sold'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'SOLD'\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "    HAVING\n",
    "        sum(gross_revenue) > 0\n",
    "    UNION ALL\n",
    "\n",
    "    -- killed suites\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'SOLD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Sold'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (\n",
    "            pc_one IN ('U', 'V', 'W')\n",
    "            OR section = 'House'\n",
    "        )\n",
    "        AND (\n",
    "            allocations ilike '%kill%'\n",
    "            OR locks ilike '%kill%'\n",
    "            OR allocations ilike '%panthers players%'\n",
    "            OR allocations ilike '%owner%'\n",
    "            OR allocations ilike '%hockey operations%'\n",
    "            OR allocations ilike '%visiting team%'\n",
    "        )\n",
    "        AND \"id\" NOT IN (SELECT ct.id FROM comp_temp ct)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "    UNION ALL\n",
    "\n",
    "    -- comp suites\n",
    "    SELECT * FROM comp_temp\n",
    "),\n",
    "held_suites AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'HELD'::varchar AS \"status\",\n",
    "        NULL::varchar AS \"locks\",\n",
    "        'Held'::varchar AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'HELD'\n",
    "        AND \"id\" NOT IN (SELECT s.id FROM sold_suites s)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "),\n",
    "-- SELECT * FROM held_suites;\n",
    "available_suites AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        section,\n",
    "        product_id || '-' || section AS \"id\",\n",
    "        'AVAIL'::varchar AS \"status\",\n",
    "        LISTAGG(DISTINCT locks, ', ') AS \"locks\",\n",
    "        LISTAGG(DISTINCT allocations, ', ') WITHIN GROUP (ORDER BY allocations) AS \"allocations\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_status_2425_playoffs\n",
    "    WHERE\n",
    "        (pc_one IN ('U', 'V', 'W') OR section = 'House')\n",
    "        AND status = 'AVAIL'\n",
    "        AND \"id\" NOT IN (SELECT s.id FROM sold_suites s)\n",
    "        AND \"id\" NOT IN (SELECT h.id FROM held_suites h)\n",
    "        AND (allocations <> '[\"Standing Room Only\"]' OR allocations IS NULL)\n",
    "    GROUP BY\n",
    "        product_id,\n",
    "        section\n",
    "),\n",
    "temp AS (\n",
    "    SELECT * FROM sold_suites\n",
    "    UNION ALL\n",
    "    SELECT * FROM held_suites\n",
    "    UNION ALL\n",
    "    SELECT * FROM available_suites\n",
    ")\n",
    "SELECT\n",
    "    split_part(products.product_description, ' - ', 1) AS \"event_name\",\n",
    "    CASE\n",
    "        WHEN RIGHT(LEFT(product_description,6),2) = 'R4' THEN 'SC'\n",
    "        ELSE RIGHT(LEFT(product_description,6),2)\n",
    "    END AS tier,\n",
    "    event_date,\n",
    "    temp.*\n",
    "FROM\n",
    "    temp\n",
    "LEFT JOIN\n",
    "    custom.seatgeek_v_products products ON temp.product_id = products.product_id\n",
    "ORDER BY\n",
    "    \"event_name\",\n",
    "    event_date,\n",
    "    section\n",
    "\"\"\"\n",
    "\n",
    "current_nightly_suites = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0db30174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "event_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AVAIL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "COMP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SOLD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_out_from_event",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_sold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cumulative_avg_sold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_going_to_sellout",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "45f546eb-ae80-488d-b3a0-106afb26bba3",
       "rows": [
        [
         "0",
         "2024-25 Playoff Inventory Management",
         "2025-06-30 00:00:00",
         "-2",
         "17.0",
         "58.0",
         "4.0",
         "30",
         null,
         null,
         "False"
        ],
        [
         "1",
         "25POR1G1",
         "2025-04-26 13:00:00",
         "R1",
         null,
         "15.0",
         "64.0",
         "-34",
         null,
         null,
         "False"
        ],
        [
         "2",
         "25POR1G2",
         "2025-04-28 19:00:00",
         "R1",
         null,
         "11.0",
         "68.0",
         "-32",
         null,
         null,
         "False"
        ],
        [
         "3",
         "25POR1G3",
         "2025-05-02 00:00:00",
         "R1",
         "72.0",
         null,
         "7.0",
         "-29",
         null,
         null,
         "False"
        ],
        [
         "4",
         "25POR1G4",
         "2025-05-04 00:00:00",
         "R1",
         "72.0",
         null,
         "7.0",
         "-27",
         null,
         null,
         "False"
        ],
        [
         "5",
         "25POR2G1",
         "2025-05-09 19:00:00",
         "R2",
         null,
         "9.0",
         "70.0",
         "-21",
         null,
         null,
         "False"
        ],
        [
         "6",
         "25POR2G2",
         "2025-05-11 19:30:00",
         "R2",
         null,
         "10.0",
         "69.0",
         "-19",
         null,
         null,
         "False"
        ],
        [
         "7",
         "25POR2G3",
         "2025-05-16 20:00:00",
         "R2",
         null,
         "15.0",
         "64.0",
         "-14",
         null,
         null,
         "False"
        ],
        [
         "8",
         "25POR2G4",
         "2025-05-18 00:00:00",
         "R2",
         "73.0",
         null,
         "6.0",
         "-13",
         null,
         null,
         "False"
        ],
        [
         "9",
         "25POR3G1",
         "2025-05-24 20:00:00",
         "R3",
         null,
         "13.0",
         "68.0",
         "-6",
         null,
         null,
         "False"
        ],
        [
         "10",
         "25POR3G2",
         "2025-05-26 20:00:00",
         "R3",
         null,
         "10.0",
         "69.0",
         "-4",
         null,
         null,
         "False"
        ],
        [
         "11",
         "25POR3G3",
         "2025-05-30 20:00:00",
         "R3",
         "74.0",
         null,
         "5.0",
         "0",
         "7.4",
         "7.4",
         "False"
        ],
        [
         "12",
         "25POR3G4",
         "2025-06-01 20:00:00",
         "R3",
         "73.0",
         null,
         "6.0",
         "2",
         "2.6",
         "16.8",
         "False"
        ],
        [
         "13",
         "25POR4G1",
         "2025-06-09 20:00:00",
         "SC",
         "13.0",
         "7.0",
         "59.0",
         "10",
         "0.833333333333333",
         "57.8333333333333",
         "True"
        ],
        [
         "14",
         "25POR4G2",
         "2025-06-12 20:00:00",
         "SC",
         "12.0",
         "7.0",
         "60.0",
         "13",
         "0.333333333333333",
         "59.0",
         "True"
        ],
        [
         "15",
         "25POR4G3",
         "2025-06-17 20:00:00",
         "SC",
         "12.0",
         "7.0",
         "60.0",
         "18",
         "6.16666666666667",
         "81.8333333333333",
         "True"
        ],
        [
         "16",
         "25POR4G4",
         "2025-07-16 00:00:00",
         "SC",
         "73.0",
         null,
         "6.0",
         "46",
         "0.0",
         "91.5",
         "True"
        ],
        [
         "17",
         "25WPR4G1",
         "2025-06-04 20:00:00",
         "SC",
         "65.0",
         null,
         "14.0",
         "5",
         "3.33333333333333",
         "33.5",
         "False"
        ],
        [
         "18",
         "25WPR4G2",
         "2025-06-06 20:00:00",
         "SC",
         "65.0",
         null,
         "14.0",
         "7",
         "2.33333333333333",
         "45.5",
         "False"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_date</th>\n",
       "      <th>tier</th>\n",
       "      <th>AVAIL</th>\n",
       "      <th>COMP</th>\n",
       "      <th>SOLD</th>\n",
       "      <th>days_out_from_event</th>\n",
       "      <th>avg_sold</th>\n",
       "      <th>cumulative_avg_sold</th>\n",
       "      <th>is_going_to_sellout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-25 Playoff Inventory Management</td>\n",
       "      <td>2025-06-30 00:00:00</td>\n",
       "      <td>-2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25POR1G1</td>\n",
       "      <td>2025-04-26 13:00:00</td>\n",
       "      <td>R1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25POR1G2</td>\n",
       "      <td>2025-04-28 19:00:00</td>\n",
       "      <td>R1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25POR1G3</td>\n",
       "      <td>2025-05-02 00:00:00</td>\n",
       "      <td>R1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25POR1G4</td>\n",
       "      <td>2025-05-04 00:00:00</td>\n",
       "      <td>R1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25POR2G1</td>\n",
       "      <td>2025-05-09 19:00:00</td>\n",
       "      <td>R2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25POR2G2</td>\n",
       "      <td>2025-05-11 19:30:00</td>\n",
       "      <td>R2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25POR2G3</td>\n",
       "      <td>2025-05-16 20:00:00</td>\n",
       "      <td>R2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25POR2G4</td>\n",
       "      <td>2025-05-18 00:00:00</td>\n",
       "      <td>R2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25POR3G1</td>\n",
       "      <td>2025-05-24 20:00:00</td>\n",
       "      <td>R3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25POR3G2</td>\n",
       "      <td>2025-05-26 20:00:00</td>\n",
       "      <td>R3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25POR3G3</td>\n",
       "      <td>2025-05-30 20:00:00</td>\n",
       "      <td>R3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25POR3G4</td>\n",
       "      <td>2025-06-01 20:00:00</td>\n",
       "      <td>R3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25POR4G1</td>\n",
       "      <td>2025-06-09 20:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>57.833333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25POR4G2</td>\n",
       "      <td>2025-06-12 20:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25POR4G3</td>\n",
       "      <td>2025-06-17 20:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>81.833333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25POR4G4</td>\n",
       "      <td>2025-07-16 00:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25WPR4G1</td>\n",
       "      <td>2025-06-04 20:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25WPR4G2</td>\n",
       "      <td>2025-06-06 20:00:00</td>\n",
       "      <td>SC</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              event_name          event_date tier  AVAIL  \\\n",
       "0   2024-25 Playoff Inventory Management 2025-06-30 00:00:00   -2   17.0   \n",
       "1                               25POR1G1 2025-04-26 13:00:00   R1    NaN   \n",
       "2                               25POR1G2 2025-04-28 19:00:00   R1    NaN   \n",
       "3                               25POR1G3 2025-05-02 00:00:00   R1   72.0   \n",
       "4                               25POR1G4 2025-05-04 00:00:00   R1   72.0   \n",
       "5                               25POR2G1 2025-05-09 19:00:00   R2    NaN   \n",
       "6                               25POR2G2 2025-05-11 19:30:00   R2    NaN   \n",
       "7                               25POR2G3 2025-05-16 20:00:00   R2    NaN   \n",
       "8                               25POR2G4 2025-05-18 00:00:00   R2   73.0   \n",
       "9                               25POR3G1 2025-05-24 20:00:00   R3    NaN   \n",
       "10                              25POR3G2 2025-05-26 20:00:00   R3    NaN   \n",
       "11                              25POR3G3 2025-05-30 20:00:00   R3   74.0   \n",
       "12                              25POR3G4 2025-06-01 20:00:00   R3   73.0   \n",
       "13                              25POR4G1 2025-06-09 20:00:00   SC   13.0   \n",
       "14                              25POR4G2 2025-06-12 20:00:00   SC   12.0   \n",
       "15                              25POR4G3 2025-06-17 20:00:00   SC   12.0   \n",
       "16                              25POR4G4 2025-07-16 00:00:00   SC   73.0   \n",
       "17                              25WPR4G1 2025-06-04 20:00:00   SC   65.0   \n",
       "18                              25WPR4G2 2025-06-06 20:00:00   SC   65.0   \n",
       "\n",
       "    COMP  SOLD  days_out_from_event  avg_sold  cumulative_avg_sold  \\\n",
       "0   58.0   4.0                   30       NaN                  NaN   \n",
       "1   15.0  64.0                  -34       NaN                  NaN   \n",
       "2   11.0  68.0                  -32       NaN                  NaN   \n",
       "3    NaN   7.0                  -29       NaN                  NaN   \n",
       "4    NaN   7.0                  -27       NaN                  NaN   \n",
       "5    9.0  70.0                  -21       NaN                  NaN   \n",
       "6   10.0  69.0                  -19       NaN                  NaN   \n",
       "7   15.0  64.0                  -14       NaN                  NaN   \n",
       "8    NaN   6.0                  -13       NaN                  NaN   \n",
       "9   13.0  68.0                   -6       NaN                  NaN   \n",
       "10  10.0  69.0                   -4       NaN                  NaN   \n",
       "11   NaN   5.0                    0  7.400000             7.400000   \n",
       "12   NaN   6.0                    2  2.600000            16.800000   \n",
       "13   7.0  59.0                   10  0.833333            57.833333   \n",
       "14   7.0  60.0                   13  0.333333            59.000000   \n",
       "15   7.0  60.0                   18  6.166667            81.833333   \n",
       "16   NaN   6.0                   46  0.000000            91.500000   \n",
       "17   NaN  14.0                    5  3.333333            33.500000   \n",
       "18   NaN  14.0                    7  2.333333            45.500000   \n",
       "\n",
       "    is_going_to_sellout  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "5                 False  \n",
       "6                 False  \n",
       "7                 False  \n",
       "8                 False  \n",
       "9                 False  \n",
       "10                False  \n",
       "11                False  \n",
       "12                False  \n",
       "13                 True  \n",
       "14                 True  \n",
       "15                 True  \n",
       "16                 True  \n",
       "17                False  \n",
       "18                False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_nightly_suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c4db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites.groupby(by = ['event_name','event_date','status'])[['section']].count().reset_index()\n",
    "\n",
    "current_nightly_suites = current_nightly_suites.pivot_table(index=['event_name','event_date', 'tier'], columns='status', \n",
    "             values='section', aggfunc='count').reset_index()\n",
    "\n",
    "current_nightly_suites['event_date'] = pd.to_datetime(current_nightly_suites['event_date'])\n",
    "\n",
    "current_nightly_suites['days_out_from_event'] = (current_nightly_suites['event_date'] - datetime.now()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676d6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    custom.forecasting_hockey_nightly_suites_playoffs\n",
    "\"\"\"\n",
    "\n",
    "forecasting_nightly_suites = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f88575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites = current_nightly_suites.merge(forecasting_nightly_suites, how = 'left', on = ['tier', 'days_out_from_event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64ecfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_nightly_suites['is_going_to_sellout'] = current_nightly_suites['cumulative_avg_sold'] > current_nightly_suites['AVAIL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e10d4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['HELD'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m current_nightly_suites \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_nightly_suites\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdays_out_from_event\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAVAIL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOMP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHELD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSOLD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumulative_avg_sold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_going_to_sellout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['HELD'] not in index\""
     ]
    }
   ],
   "source": [
    "current_nightly_suites = current_nightly_suites[['event_name','event_date','days_out_from_event','tier','AVAIL','COMP','HELD','SOLD','cumulative_avg_sold','is_going_to_sellout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7cb8bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merch, F&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH attendance AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        COUNT(*) AS attendance\n",
    "    FROM\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    GROUP BY\n",
    "        event_datetime\n",
    ")\n",
    "SELECT\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    gross_revenue,\n",
    "    num_orders,\n",
    "    quantity_sold\n",
    "FROM\n",
    "    custom.cheq_v_hockey_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON DATE(cheq_v_hockey_summary.event_date) = DATE(cth_game_descriptions.event_date)\n",
    "LEFT JOIN\n",
    "    attendance \n",
    "    ON DATE(attendance.event_datetime) = DATE(cheq_v_hockey_summary.event_date)\n",
    "WHERE\n",
    "    tier IN ('R1', 'R2', 'R3', 'SC')\n",
    "\"\"\"\n",
    "\n",
    "historical_f_and_b = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_columns(df):\n",
    "\n",
    "    day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "    df['weekend'] = df.apply(\n",
    "        lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "    start_time_map = {\n",
    "        '12:30 PM': 1,\n",
    "        '12:45 PM': 1,\n",
    "        '1:00 PM': 1,\n",
    "        '3:00 PM': 1,\n",
    "        '3:30 PM': 1,\n",
    "        '4:00 PM': 2,\n",
    "        '5:00 PM': 2,\n",
    "        '6:00 PM': 2\n",
    "    }\n",
    "\n",
    "    df['start_time_num'] = df.apply(\n",
    "        lambda row: start_time_map.get(row['start_time'], 0),\n",
    "        axis=1)\n",
    "\n",
    "    tier_mapping = {\n",
    "        'SC': 4,\n",
    "        'R3': 3,\n",
    "        'R2': 2,\n",
    "        'R1': 1\n",
    "    }\n",
    "\n",
    "    df['tier_num'] = df.apply(\n",
    "        lambda row: tier_mapping.get(row['tier'], 0),\n",
    "        axis=1) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c22eb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_f_and_b = get_model_columns(historical_f_and_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ea073",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "WITH attendance AS\n",
    "    (SELECT\n",
    "        event_datetime,\n",
    "        COUNT(*) AS attendance\n",
    "    FROM\n",
    "        custom.cth_v_attendance_2324_playoffs\n",
    "    GROUP BY\n",
    "        event_datetime)\n",
    "SELECT\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance,\n",
    "    SUM(gross_revenue) AS gross_revenue,\n",
    "    SUM(qty) AS quantity,\n",
    "    COUNT(distinct invoice_id) AS num_orders\n",
    "FROM\n",
    "    custom.retailpro_v_invoice_items\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions ON retailpro_v_invoice_items.event_date = cth_game_descriptions.event_date\n",
    "LEFT JOIN\n",
    "    attendance ON retailpro_v_invoice_items.event_date = date(attendance.event_datetime)\n",
    "WHERE\n",
    "    season IN ('2023-24','2024-25')\n",
    "    AND tier IN ('R1','R2','R3','SC')\n",
    "GROUP BY\n",
    "    cth_game_descriptions.season,\n",
    "    cth_game_descriptions.event_date,\n",
    "    tier,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    attendance\n",
    "\"\"\"\n",
    "\n",
    "historical_merch = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39eb8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_merch = get_model_columns(historical_merch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "    season,\n",
    "    date(event_date) AS event_date,\n",
    "    day_of_week,\n",
    "    tier,\n",
    "    start_time\n",
    "FROM\n",
    "    custom.cth_game_descriptions\n",
    "WHERE\n",
    "    event_date >= current_date\n",
    "\"\"\"\n",
    "\n",
    "future_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "future_game_info = future_game_info.merge(final_tickets_and_attendance, how = 'left', on = ['event_date', 'tier'])\n",
    "\n",
    "future_game_info = get_model_columns(future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3df84fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_f_and_b_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['total_attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcbadb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_f_and_b_gross_rev'] = run_f_and_b_model(historical_f_and_b, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "721fe792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_merch_model(df, df_future):\n",
    "\n",
    "    x_train = df[['attendance','weekend','start_time_num','tier_num']]\n",
    "    y_train = df[['gross_revenue']]\n",
    "\n",
    "    x_test = df_future[['total_attendance','weekend','start_time_num','tier_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "631c7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_game_info['predicted_merch_gross_rev'] = run_merch_model(historical_merch, future_game_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7dd67d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_and_f_and_b_rev = future_game_info[['event_date','event_name','total_attendance','predicted_f_and_b_gross_rev', 'predicted_merch_gross_rev']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2b3f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rates by tier and lot\n",
    "\n",
    "q = \"\"\"\n",
    "WITH prepaid AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2324\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2425\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "),\n",
    "prepaid_agg AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        COUNT(*) AS prepaid_passes\n",
    "    FROM\n",
    "        prepaid\n",
    "    GROUP BY\n",
    "        event_datetime, \n",
    "        location_group\n",
    "),\n",
    "scans AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        cth_game_descriptions.event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        CASE\n",
    "            WHEN paid_amount = 0 THEN 1\n",
    "            ELSE 0 \n",
    "        END AS num_scans\n",
    "    FROM\n",
    "        custom.parkhub_v_transactions\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions \n",
    "        ON parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    WHERE\n",
    "        cth_game_descriptions.event_datetime IS NOT NULL\n",
    "        AND season IN ('2023-24', '2024-25')\n",
    "),\n",
    "scans_agg AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group,\n",
    "        SUM(num_scans) AS num_scans\n",
    "    FROM\n",
    "        scans\n",
    "    GROUP BY\n",
    "        season,\n",
    "        event_datetime,\n",
    "        tier,\n",
    "        location_group\n",
    ")\n",
    "SELECT\n",
    "    season,\n",
    "    prepaid_agg.event_datetime,\n",
    "    tier,\n",
    "    prepaid_agg.location_group,\n",
    "    prepaid_passes,\n",
    "    num_scans,\n",
    "    num_scans * 1.0 / prepaid_passes::FLOAT AS show_rate\n",
    "FROM\n",
    "    scans_agg\n",
    "LEFT JOIN\n",
    "    prepaid_agg \n",
    "    ON scans_agg.event_datetime = prepaid_agg.event_datetime\n",
    "    AND scans_agg.location_group = prepaid_agg.location_group\n",
    "WHERE\n",
    "    prepaid_agg.event_datetime IS NOT NULL\n",
    "    AND tier IN ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "show_rate_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56aa7e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3821290929.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# weigh this past season more heavily\n",
    "\n",
    "weights = {'2023-24':1.25,'2024-25':2.75}\n",
    "\n",
    "show_rate_df['weights'] = show_rate_df['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate_df.groupby(by = ['tier','location_group']).apply(weighted_paid_average).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e77dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical prepaid parking data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH prepaid AS (\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        DATE(transaction_date) AS transaction_date\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2324\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        event_datetime,\n",
    "        location_group,\n",
    "        DATE(transaction_date) AS transaction_date\n",
    "    FROM\n",
    "        custom.ctp_v_ticket_2425\n",
    "    WHERE\n",
    "        event_type ILIKE '%panthers%'\n",
    "        AND event_datetime < CURRENT_DATE\n",
    ")\n",
    "SELECT\n",
    "    DATE(prepaid.event_datetime) AS event_date,\n",
    "    location_group,\n",
    "    'prepaid' AS parking_type,\n",
    "    DATEDIFF('days', transaction_date, prepaid.event_datetime) AS days_out,\n",
    "    CASE\n",
    "        WHEN DATEDIFF('days', transaction_date, prepaid.event_datetime) >= 150 THEN 0\n",
    "        ELSE COUNT(*)\n",
    "    END AS num_passes\n",
    "FROM\n",
    "    prepaid\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON prepaid.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    DATEDIFF('days', transaction_date, prepaid.event_datetime) >= 0\n",
    "    AND tier IN ('R1', 'R2', 'R3', 'SC')\n",
    "GROUP BY\n",
    "    prepaid.event_datetime,\n",
    "    location_group,\n",
    "    transaction_date\n",
    "ORDER BY\n",
    "    prepaid.event_datetime,\n",
    "    location_group,\n",
    "    transaction_date DESC\n",
    "\"\"\"\n",
    "\n",
    "historical_prepaid_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "location_map = {\n",
    "    'Club': 4,\n",
    "    'Garage': 3,\n",
    "    'General': 2,\n",
    "    'Valet': 1\n",
    "}\n",
    "\n",
    "historical_prepaid_parking_info['location_num'] = historical_prepaid_parking_info.apply(\n",
    "    lambda row: location_map.get(row['location_group'], 0), axis=1)\n",
    "\n",
    "historical_prepaid_parking_info['cumulative_num_passes']  = historical_prepaid_parking_info.groupby(['event_date', 'location_group'])['num_passes'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "528d7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather historical game data (ie tier, dow, and start time)\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    date(cth_game_descriptions.event_date) AS event_date,\n",
    "    tier,\n",
    "    day_of_week,\n",
    "    start_time,\n",
    "    total_tickets\n",
    "FROM\n",
    "    custom.cth_v_historical_attendance_summary\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions ON cth_v_historical_attendance_summary.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    tier IN ('R1','R2','R3','SC')\n",
    "\"\"\"\n",
    "\n",
    "all_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "day_map = {\n",
    "    'Fri': 1,\n",
    "    'Sat': 1,\n",
    "    'Sun': 1,\n",
    "    'Mon': 0,\n",
    "    'Tue': 0,\n",
    "    'Wed': 0,\n",
    "    'Thu': 0\n",
    "}\n",
    "\n",
    "all_game_info['weekend'] = all_game_info.apply(\n",
    "    lambda row: day_map.get(row['day_of_week'], 0), axis=1)\n",
    "\n",
    "start_time_map = {\n",
    "    '12:30 PM': 1,\n",
    "    '12:45 PM': 1,\n",
    "    '1:00 PM': 1,\n",
    "    '3:00 PM': 1,\n",
    "    '3:30 PM': 1,\n",
    "    '4:00 PM': 2,\n",
    "    '5:00 PM': 2,\n",
    "    '6:00 PM': 2\n",
    "}\n",
    "\n",
    "all_game_info['start_time_num'] = all_game_info.apply(\n",
    "    lambda row: start_time_map.get(row['start_time'], 0),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "046cb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming game data including current prepaid totals by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    DATE(cth_game_descriptions.event_datetime) AS event_date,\n",
    "    DATEDIFF('day', CURRENT_DATE, cth_game_descriptions.event_datetime) AS days_out,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity::INT,\n",
    "    SUM(paid_seats) + SUM(comp_seats) AS prepaid_cars,\n",
    "    SUM(gross_revenue) AS current_gross_revenue,\n",
    "    capacity::INT - (SUM(paid_seats) + SUM(comp_seats)) AS cap_remaining\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN\n",
    "    custom.ctp_parking_capacities \n",
    "    ON ctp_v_ticket_2425.location_group = ctp_parking_capacities.location_group\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions \n",
    "    ON ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    cth_game_descriptions.event_datetime IS NOT NULL \n",
    "    AND cth_game_descriptions.event_datetime >= CURRENT_DATE\n",
    "GROUP BY\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group,\n",
    "    capacity\n",
    "ORDER BY\n",
    "    cth_game_descriptions.event_datetime,\n",
    "    ctp_v_ticket_2425.location_group\n",
    "\"\"\"\n",
    "\n",
    "upcoming_game_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24488c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather upcoming pricing data by game and lot\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT\n",
    "    tier,\n",
    "    location_group,\n",
    "    max(transaction_date) AS \"transaction_date\",\n",
    "    max(adjusted_price) AS \"highest_price\"\n",
    "FROM\n",
    "    custom.ctp_v_ticket_2425\n",
    "LEFT JOIN             \n",
    "    custom.cth_game_descriptions on ctp_v_ticket_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "WHERE\n",
    "    is_comp = FALSE\n",
    "    AND price_type ILIKE 'IA%'\n",
    "GROUP BY\n",
    "    tier, \n",
    "    location_group\n",
    "\"\"\"\n",
    "\n",
    "pricing_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2729752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict remaining prepaid cars\n",
    "\n",
    "def run_prepaid_model(df, df_future, lot):\n",
    "\n",
    "    total_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = total_table[['days_out','weekend','start_time_num']]\n",
    "    y_train = total_table[['cumulative_num_passes']]\n",
    "\n",
    "    total_future_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = total_future_table[['days_out','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daa7cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_table = historical_prepaid_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_table = total_table[total_table['tier'].isin(['R1','R2','R3','SC'])]\n",
    "\n",
    "# merge upcoming parking data with hisorical game data for testing model\n",
    "\n",
    "total_future_table = upcoming_game_info.merge(future_game_info, how = 'left', on = 'event_date')\n",
    "total_future_table = total_future_table[total_future_table['tier'].isin(['R1','R2','R3','SC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7351843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\484755223.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general and garage not  club, valet or executive\n",
    "\n",
    "lots = ['General','Garage']\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = total_future_table[total_future_table['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_parking'] = run_prepaid_model(total_table, total_future_table, lot)\n",
    "\n",
    "    final_df = pd.concat([final_df,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d5ddaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\1184624018.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  club_totals['predicted_parking'] = 0\n"
     ]
    }
   ],
   "source": [
    "# concat club totals for onsite model next\n",
    "\n",
    "club_totals = total_future_table[total_future_table['location_group'] == 'Club']\n",
    "club_totals['predicted_parking'] = 0\n",
    "\n",
    "final_df = pd.concat([final_df, club_totals], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cad384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no negative predictions are made\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['predicted_parking'] < 0, 0, final_df['predicted_parking'])\n",
    "\n",
    "# get total prepaid tickets (current + predicted additional)\n",
    "\n",
    "final_df['total_predicted_prepaid_cars'] = final_df['prepaid_cars'] + final_df['predicted_parking']\n",
    "\n",
    "# get number of parked cars using historical show rates\n",
    "\n",
    "final_df = final_df.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "final_df['prepaid_cars_parked'] = (final_df['total_predicted_prepaid_cars'] * final_df['weighted_average']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6360b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the capacity remaining \n",
    "\n",
    "final_df['cap_remaining'] = final_df['capacity'] - final_df['prepaid_cars_parked']\n",
    "\n",
    "# if predicted cars over capacity subtract overflow out\n",
    "\n",
    "final_df['predicted_prepaid_additional_parking'] = np.where(final_df['cap_remaining'] < 0, final_df['predicted_prepaid_additional_parking']+final_df['cap_remaining'], final_df['predicted_prepaid_additional_parking'])\n",
    "final_df['prepaid_cars_parked'] = np.where(final_df['cap_remaining'] < 0, final_df['prepaid_cars_parked']+final_df['cap_remaining'], final_df['prepaid_cars_parked'])\n",
    "final_df['cap_remaining'] = np.where(final_df['cap_remaining'] < 0, 0, final_df['prepaid_cars_parked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af0a2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[['event_date','days_out','tier', 'start_time_num','weekend',\n",
    "                     'location_group','capacity','prepaid_cars','current_gross_revenue', \n",
    "                     'predicted_prepaid_additional_parking', 'total_predicted_prepaid_cars',\n",
    "                     'prepaid_cars_parked','cap_remaining']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1c556e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hisotrical onsite parking data\n",
    "\n",
    "q = \"\"\"\n",
    "with onsite as\n",
    "    (select\n",
    "        date(cth_game_descriptions.event_datetime) as event_date,\n",
    "        location_group,\n",
    "        0 as days_out,\n",
    "        case\n",
    "            when paid_amount > 0 then 1\n",
    "        else 0\n",
    "        end as num_onsite_cars,\n",
    "        case\n",
    "            when paid_amount = 0 then 1\n",
    "        else 0\n",
    "        end as num_prepaid_cars\n",
    "    from\n",
    "        custom.parkhub_v_transactions\n",
    "    left join\n",
    "        custom.cth_game_descriptions on parkhub_v_transactions.event_datetime = cth_game_descriptions.event_datetime\n",
    "    where\n",
    "        season in ('2023-24','2024-25'))\n",
    "select\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    'onsite' as parking_type,\n",
    "    days_out,\n",
    "    sum(num_onsite_cars) as num_cars,\n",
    "    capacity - sum(num_prepaid_cars) as cap_remaining\n",
    "from\n",
    "    onsite\n",
    "left join\n",
    "    custom.ctp_parking_capacities on onsite.location_group = ctp_parking_capacities.location_group\n",
    "where\n",
    "    days_out >= 0\n",
    "group by\n",
    "    onsite.event_date,\n",
    "    onsite.location_group,\n",
    "    parking_type,\n",
    "    days_out,\n",
    "    capacity\n",
    "\"\"\"\n",
    "\n",
    "historical_onsite_parking_info = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d00413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge hisotrical prepaid parking data with hisorical game data for training model\n",
    "\n",
    "total_onsite_table = historical_onsite_parking_info.merge(all_game_info, how = 'left', on = 'event_date')\n",
    "total_onsite_table = total_onsite_table[total_onsite_table['tier'].isin(['R1','R2','R3','SC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ce33fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict onsite cars\n",
    "\n",
    "def run_onsite_model(df, df_future, lot):\n",
    "\n",
    "    x_train_table = df[df['location_group'] == lot]\n",
    "\n",
    "    x_train = x_train_table[['cap_remaining','weekend','start_time_num']]\n",
    "    y_train = x_train_table[['num_cars']]\n",
    "\n",
    "    x_test_table = df_future[df_future['location_group'] == lot]\n",
    "\n",
    "    x_test = x_test_table[['cap_remaining','weekend','start_time_num']]\n",
    "\n",
    "    #scalar = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #poly_features = scalar.fit_transform(x_train)\n",
    "    scalar = StandardScaler()\n",
    "    poly_features = scalar.fit_transform(x_train)\n",
    "\n",
    "    polynomial = LinearRegression().fit(poly_features, np.array(y_train).ravel())\n",
    "    #predicted_train = polynomial.predict(poly_features)\n",
    "\n",
    "    poly_features2 = scalar.fit_transform(x_test)\n",
    "\n",
    "    #predicted_test = polynomial.predict(poly_features2)\n",
    "\n",
    "    return polynomial.predict(poly_features2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58fc0429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\769201683.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n"
     ]
    }
   ],
   "source": [
    "# only predicting for general, garage, and club not valet or executive\n",
    "\n",
    "lots = ['General','Garage','Club']\n",
    "\n",
    "final_df_onsite = pd.DataFrame()\n",
    "\n",
    "for lot in lots:\n",
    "\n",
    "    temp = final_df[final_df['location_group'] == lot]\n",
    "\n",
    "    temp['predicted_onsite_parking'] = run_onsite_model(total_onsite_table, final_df, lot)\n",
    "\n",
    "    final_df_onsite = pd.concat([final_df_onsite,temp], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eee0a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3926685836.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27320\\3926685836.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n"
     ]
    }
   ],
   "source": [
    "# add back executive and valet parking and match fields from final_df\n",
    "\n",
    "exec_and_valet = total_future_table[total_future_table['location_group'].isin(['Executive','Valet'])]\n",
    "\n",
    "exec_and_valet['predicted_prepaid_additional_parking'] = 0\n",
    "exec_and_valet['total_predicted_prepaid_cars'] = exec_and_valet['prepaid_cars']\n",
    "\n",
    "exec_and_valet = exec_and_valet.merge(paid_tiers, how =  'left', on = ['tier', 'location_group'])\n",
    "exec_and_valet['weighted_average'] = exec_and_valet['weighted_average'].fillna(1)\n",
    "\n",
    "exec_and_valet['prepaid_cars_parked'] = (exec_and_valet['total_predicted_prepaid_cars'] * exec_and_valet['weighted_average']).astype(int)\n",
    "exec_and_valet['predicted_onsite_parking'] = 0\n",
    "exec_and_valet['total_parking'] = exec_and_valet['prepaid_cars_parked'] \n",
    "\n",
    "exec_and_valet = exec_and_valet[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked',\n",
    "                                       'predicted_onsite_parking','total_parking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8b53053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if predicted total over capacity subtract overflow out\n",
    "\n",
    "final_df_onsite['predicted_onsite_parking'] = [pred_onsite if pred_onsite <= cap_remaining else cap_remaining for pred_onsite, cap_remaining in zip(final_df_onsite['predicted_onsite_parking'], final_df_onsite['cap_remaining'])]\n",
    "\n",
    "final_df_onsite['total_parking'] = final_df_onsite['prepaid_cars_parked'] + final_df_onsite['predicted_onsite_parking']\n",
    "\n",
    "final_parking_model = final_df_onsite[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking','total_predicted_prepaid_cars',\n",
    "                                       'prepaid_cars_parked','predicted_onsite_parking','total_parking']]\n",
    "\n",
    "# merge with executive and valet parking info\n",
    "\n",
    "final_parking_model_df = pd.concat([final_parking_model, exec_and_valet], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f37d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parking_model_df = final_parking_model_df.merge(pricing_info, how = 'left', on = ['tier', 'location_group'])\n",
    "\n",
    "final_parking_model_df['predicted_prepaid_additional_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_onsite_parking_gross_revenue'] = (final_parking_model_df['predicted_prepaid_additional_parking'] * final_parking_model_df['highest_price']*1.25).fillna(0)\n",
    "\n",
    "final_parking_model_df['predicted_gross_revenue'] = final_parking_model_df['predicted_prepaid_additional_gross_revenue'] + final_parking_model_df['predicted_onsite_parking_gross_revenue'] + final_parking_model_df['current_gross_revenue']\n",
    "\n",
    "final_parking_model_df = final_parking_model_df[['event_date', 'days_out','tier','location_group','capacity','prepaid_cars',\n",
    "                                       'current_gross_revenue', 'predicted_prepaid_additional_parking', 'predicted_prepaid_additional_gross_revenue',\n",
    "                                       'total_predicted_prepaid_cars', 'prepaid_cars_parked', 'predicted_onsite_parking',\n",
    "                                       'predicted_onsite_parking_gross_revenue','total_parking', 'predicted_gross_revenue']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

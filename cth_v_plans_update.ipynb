{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from sqlalchemy import null\n",
    "from datetime import datetime\n",
    "\n",
    "from prefect.blocks.system import Secret\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'seat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'seat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mselect \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    *\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m    or plan_event_name like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%F\u001b[39;00m\u001b[38;5;124mSP\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    or plan_event_name like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%F\u001b[39;00m\u001b[38;5;124mSC\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m initial_df \u001b[38;5;241m=\u001b[39m FLA_Redshift(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrs_creds)\u001b[38;5;241m.\u001b[39mquery_warehouse(sql_string \u001b[38;5;241m=\u001b[39m q)\n\u001b[1;32m---> 16\u001b[0m \u001b[43minitial_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'seat'"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    *\n",
    "from \n",
    "    custom.arch_final_v_plans\n",
    "where\n",
    "    season_name like '%Panthers Hockey%'\n",
    "    and plan_event_name like '%FSF%'\n",
    "    or plan_event_name like '%FSA%'\n",
    "    or plan_event_name like '%FSB%'\n",
    "    or plan_event_name like '%FSP%'\n",
    "    or plan_event_name like '%FSC%'\"\"\"\n",
    "\n",
    "initial_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "initial_df['seat_nunm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create season\n",
    "\n",
    "initial_df['season'] = [text.split(' ')[0] for text in initial_df['season_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 47\u001b[0m\n\u001b[0;32m     43\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morig_bpp_seat\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_block_purchase_price\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 47\u001b[0m initial_df \u001b[38;5;241m=\u001b[39m \u001b[43mexplode_block_seating\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mexplode_block_seating\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Required Fields\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m        - seat_num  - last_seat\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m        - paid amount\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## num seats\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# df['seat_list'] = df.apply(lambda row: list(range(row['seat_num'], row['last_seat'] + 1)), axis = 1)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseat_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseat_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseat_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_seats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## break out monies\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock_purchase_price\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mexplode_block_seating.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Required Fields\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m        - seat_num  - last_seat\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m        - paid amount\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## num seats\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# df['seat_list'] = df.apply(lambda row: list(range(row['seat_num'], row['last_seat'] + 1)), axis = 1)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseat_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseat_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseat_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_seats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## break out monies\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock_purchase_price\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "def explode_block_seating(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        Required Fields\n",
    "            - seat_num  - last_seat\n",
    "\n",
    "            - block_purchase_price\n",
    "            - paid amount\n",
    "    \"\"\"\n",
    "\n",
    "    ## num seats\n",
    "    # df['seat_list'] = df.apply(lambda row: list(range(row['seat_num'], row['last_seat'] + 1)), axis = 1)\n",
    "    df['seat_list'] = df.apply(lambda row: list(range(row['seat_num'], row['seat_num'] + row['num_seats'])), axis = 1)\n",
    "\n",
    "    ## break out monies\n",
    "    if \"block_purchase_price\" in df.columns:\n",
    "        df['gross_rev_seat'] = df.apply(lambda row: row['block_purchase_price'] / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    if \"paid_amount\" in df.columns:\n",
    "        df['paid_amt_seat'] = df.apply(lambda row: (row['paid_amount'] / row['total_events']) / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    if \"original_block_purchase_price\" in df.columns:\n",
    "        df['orig_bpp_seat'] = df.apply(lambda row: row['original_block_purchase_price'] / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    ## explode\n",
    "    df = df.explode('seat_list')\n",
    "\n",
    "    ## rename\n",
    "    df = df.drop(['seat_num', 'last_seat'], axis = 1).rename(\n",
    "        columns = {'seat_list' : 'seat'}\n",
    "        ).reset_index(drop = True)\n",
    "\n",
    "    if \"block_purchase_price\" in df.columns: \n",
    "        df = df.drop(['block_purchase_price'], axis = 1)\n",
    "        df = df.rename(columns = {'gross_rev_seat' : 'block_purchase_price'})\n",
    "\n",
    "    if \"paid_amount\" in df.columns: \n",
    "        df = df.drop(['paid_amount'], axis = 1)\n",
    "        df = df.rename(columns = {'paid_amt_seat' : 'paid_amount'})\n",
    "    \n",
    "    if \"original_block_purchase_price\" in df.columns: \n",
    "        df = df.drop(['original_block_purchase_price'], axis = 1)\n",
    "        df = df.rename(columns = {'orig_bpp_seat' : 'original_block_purchase_price'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "initial_df = explode_block_seating(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pc fields\n",
    "\n",
    "def break_out_price_code(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['pc_one'] = df['price_code'].str[0]\n",
    "    df['pc_two'] = df['price_code'].str[1]\n",
    "    df['pc_three'] = df['price_code'].str[2]\n",
    "    df['pc_four'] = df['price_code'].str[3]\n",
    "\n",
    "    df['pc_one_two'] = df['price_code'].str[:2]\n",
    "    df['pc_two_three'] = df['price_code'].str[1:3]\n",
    "    df['pc_three_four'] = df['price_code'].str[2:4]\n",
    "    df['pc_two_three_four'] = df['price_code'].str[1:4]\n",
    "\n",
    "    my_cols = ['pc_one', 'pc_two', 'pc_three', 'pc_four', 'pc_one_two', 'pc_two_three', 'pc_three_four', 'pc_two_three_four']\n",
    "\n",
    "    for col in my_cols:\n",
    "        df[col] = df[col].fillna(\"\")\n",
    "\n",
    "    ## Add \"I\" to pc_two if price code is a single character\n",
    "    ## Check for asterisks!\n",
    "    \n",
    "    #df['pc_two'] = df.apply(lambda row: \"I\" if len(row['price_code']) == 1 or row['pc_two'] == \"*\" else row['pc_two'], axis = 1)\n",
    "\n",
    "    return df \n",
    "\n",
    "initial_df = break_out_price_code(initial_df)\n",
    "\n",
    "# Create location_general\n",
    "\n",
    "def create_location_general(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    my_loc_dict = {\n",
    "        \"General\" : [\n",
    "            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "            '1', '2', '3', '4', '5', '6', '7', '8'\n",
    "            ],\n",
    "        \"Suites\" : ['U', 'V', 'W'],\n",
    "        \"Amerant Vault\" : ['X'],\n",
    "        \"Loft\" : ['Y'],\n",
    "        \"Corona\" : ['Z'],\n",
    "        \"Parking\" : ['9']\n",
    "    }\n",
    "\n",
    "    df['location_general'] = \"Other\"\n",
    "\n",
    "    if 'pc_one' in df.columns:\n",
    "        for key, value in my_loc_dict.items():\n",
    "            df.loc[df['pc_one'].isin(value), 'location_general'] = key\n",
    "    else:\n",
    "        print(\"pc_one does not exist!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_location_general(initial_df)\n",
    "\n",
    "# create location specific\n",
    "\n",
    "def create_location_specific(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    my_loc_dict = {\n",
    "        \"Lowers\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
    "        \"Clubs\" : ['K', 'L', 'M'],\n",
    "        \"Uppers\" : ['N', 'O', 'P', 'Q', 'R', 'S', 'T'],\n",
    "        \"Suites\" : ['U', 'V', 'W'],\n",
    "        \"Lounge 954\" : ['X'],\n",
    "        \"Loft\" : ['Y'],\n",
    "        \"Corona\" : ['Z']\n",
    "    }\n",
    "\n",
    "    df['location_specific'] = \"Other\"\n",
    "\n",
    "    if 'pc_one' in df.columns:\n",
    "        for key, value in my_loc_dict.items():\n",
    "            df.loc[df['pc_one'].isin(value), 'location_specific'] = key\n",
    "    else:\n",
    "        print(\"pc_one does not exist!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_location_specific(initial_df)\n",
    "\n",
    "# create arena level\n",
    "\n",
    "def create_arena_level(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    my_level_dict = {\n",
    "        \"Lowers\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
    "        \"Clubs\" : ['X', 'Z'],\n",
    "        \"Uppers\" : ['N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y'],\n",
    "        \"Suites\" : ['U', 'V', 'W'],\n",
    "    }\n",
    "\n",
    "    df['arena_level'] = \"Other\"\n",
    "\n",
    "    if 'pc_one' in df.columns:\n",
    "        for key, value in my_level_dict.items():\n",
    "            df.loc[(df['pc_one'].isin(value)), 'arena_level'] = key\n",
    "    else:\n",
    "        print(\"pc_one does not exist!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_arena_level(initial_df)\n",
    "\n",
    "# create is premium\n",
    "\n",
    "def create_is_premium(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['is_premium'] = False\n",
    "    df.loc[(df['pc_one'].isin(['U', 'V', 'W', 'X', 'Z', '1', '2'])), 'is_premium'] = True\n",
    "\n",
    "    df['is_premium_text'] = [\"Premium\" if x is True else \"General\" for x in df['is_premium']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_premium(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acct_type_desc does not exist!\n"
     ]
    }
   ],
   "source": [
    "# Create plan_type\n",
    "\n",
    "def create_plan_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "    '''\n",
    "        this_df['plan_type'] = \"Unknown\"\n",
    "        this_df.loc[(this_df['pc_two'] == \"F\"), 'plan_type'] = \"Full\"\n",
    "        this_df.loc[(this_df['pc_two'] == \"C\"), 'plan_type'] = \"Premier\"\n",
    "        this_df.loc[(this_df['pc_two'].isin([\"A\", \"B\", \"H\"])), 'plan_type'] = \"Half\"\n",
    "        this_df.loc[(this_df['pc_two'].isin([\"A\", \"B\", \"H\"])) & ((this_df['pc_three'] == \"F\") | (this_df['pc_four'] == \"F\")), 'plan_type'] = \"Full\"\n",
    "        this_df.loc[(this_df['pc_two'].isin([\"I\", \"*\"])), 'plan_type'] = \"Singles\"\n",
    "        this_df.loc[(this_df['pc_two_three'] == \"IX\"), 'plan_type'] = \"Flex\"\n",
    "        this_df.loc[(this_df['pc_two'] == \"G\"), 'plan_type'] = \"Groups\"\n",
    "        this_df.loc[(this_df['pc_two'] == \"C\") & (this_df['pc_three'].isin([\"I\", \"E\"])), 'plan_type'] = \"Singles\"\n",
    "        this_df.loc[(this_df['pc_one'].isin([\"U\", \"V\", \"W\"])) & (this_df['pc_two'].isin([\"Y\", \"R\", \"E\", \"N\"])), 'plan_type'] = \"Full\"\n",
    "    '''\n",
    "\n",
    "    df['plan_type'] = \"Unknown\"\n",
    "    df.loc[(df['pc_two'] == \"F\"), 'plan_type'] = \"Full\"\n",
    "    df.loc[(df['pc_two'] == \"P\"), 'plan_type'] = \"Premier\"\n",
    "    df.loc[(df['pc_two'].isin([\"I\", \"*\", \"\"])), 'plan_type'] = \"Singles\"\n",
    "    df.loc[(df['pc_two'] == \"X\"), 'plan_type'] = \"Flex\"\n",
    "    df.loc[(df['pc_two'] == \"G\"), 'plan_type'] = \"Groups\"\n",
    "\n",
    "        ## SAVED ##\n",
    "        # my_dict = {\n",
    "        #     \"22FSF\" : \"Full\",\n",
    "        #     \"22FSP\" : \"Premier\",\n",
    "        # }\n",
    "\n",
    "        # df['plan_type'] = \"Unknown\"\n",
    "\n",
    "        # for key, value in my_dict.items():\n",
    "        #     df.loc[df['event_name'] == key, 'plan_type'] = value\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_plan_type(initial_df)\n",
    "\n",
    "# create is logitix\n",
    "\n",
    "def create_is_logitix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['is_logitix'] = False\n",
    "    df.loc[(df['pc_two_three'].isin([\"FD\", \"GD\"])) & (~df['pc_one'].isin([\"U\", \"V\", \"W\"])), 'is_logitix'] = True \n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_logitix(initial_df)\n",
    "\n",
    "# create is sponsor\n",
    "\n",
    "def create_is_sponsor(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # df['is_sponsor'] = df.apply(lambda row: True if row['acct_type_desc'] == \"Sponsor\" else False, axis = 1)\n",
    "        \n",
    "    #df['is_sponsor'] = df.apply(lambda row: True if row['rep_full_name'] == \"Sponsor\" else False, axis = 1)\n",
    "\n",
    "    df['is_sponsor'] = [True if x == \"Sponsor\" else False for x in df['acct_rep_full_name']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_sponsor(initial_df)\n",
    "\n",
    "# create is trade\n",
    "\n",
    "def create_is_trade(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # trade_vals = [\"Trade\", \"Marketing Trade\", \"Media Trade\", \"Sponsor Trade\", \"Trade-Marketing\", \"Trade-Sponsor\"]\n",
    "    # df['is_trade'] = df.apply(lambda row: True if row['acct_type_desc'] in trade_vals else False, axis = 1)\n",
    "\n",
    "    #df['is_trade'] = df.apply(lambda row: True if row['rep_full_name'].find(\"Trade\") > -1 else False, axis = 1)\n",
    "\n",
    "    df['is_trade'] = [True if str(x).find(\"Trade\") > -1 else False for x in df['acct_rep_full_name']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_trade(initial_df)\n",
    "\n",
    "# create account type\n",
    "\n",
    "def create_account_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['account_type'] = \"Standard\"\n",
    "\n",
    "    df.loc[df['is_logitix'] == True, 'account_type'] = \"Broker\"\n",
    "    df.loc[df['is_sponsor'] == True, 'account_type'] = \"Sponsor\"\n",
    "    df.loc[df['is_trade'] == True, 'account_type'] = \"Sponsor\"\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_account_type(initial_df)\n",
    "\n",
    "# create account type description group\n",
    "\n",
    "def create_acct_type_desc_group(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    corporate_values = [\"Sponsor\", \"Business\", \"Broker\", \"Community\", \"Suite\", \"Marketing\", \"PR\", \"Trade\", \"Box Office\"]\n",
    "\n",
    "    if 'acct_type_desc' in df.columns:\n",
    "\n",
    "        df['acct_type_desc_group'] = \"Personal\"\n",
    "        \n",
    "        for val in corporate_values:\n",
    "            df.loc[(df['acct_type_desc'].str.find(val)) >= 0, 'acct_type_desc_group'] = \"Corporate\"\n",
    "    else:\n",
    "        print(\"acct_type_desc does not exist!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_acct_type_desc_group(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ticket_type\n",
    "\n",
    "def create_ticket_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['ticket_type'] = \"Unknown\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'] == \"Full\") & (df['account_type'] == \"Standard\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Full\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'] == \"Flex\") & (df['account_type'] == \"Standard\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Flex\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'] == \"Premier\") & (df['account_type'] == \"Standard\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Premier\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'].isin([\"Full\", \"Premier\"])) & (df['location_general'] == \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Annual Suites\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'].isin([\"Full\", \"Flex\", \"Premier\"])) & (df['account_type'] == \"Sponsor\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Sponsor\"\n",
    "\n",
    "    df.loc[(df['is_trade'] == True), 'ticket_type'] = \"Trade\"\n",
    "\n",
    "        ## Double check with Ty\n",
    "        # suite_price_codes_full = [\"VFRW\", \"VFRX\", \"WFRW\", \"WFRX\", \"VFRY\", \"VFRZ\", \"WFRY\", \"WFRZ\", \"VFN\", \"VFNF\", \"WFN\", \"WFNF\", \"WFNX\"]\n",
    "        # suite_price_codes_half = [\"VAN1\", \"WAN1\", \"VBN1\", \"WBN1\"]\n",
    "\n",
    "        # df.loc[df['price_code'].isin(suite_price_codes_full), 'ticket_type'] = \"Full\"\n",
    "        # df.loc[df['price_code'].isin(suite_price_codes_half), 'ticket_type'] = \"Half\"\n",
    "        #######################\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'] == \"Groups\") & (df['account_type'] != \"Broker\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Groups\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'] == \"Singles\") & (df['account_type'] != \"Broker\") & (df['location_general'] != \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Singles\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['plan_type'].isin([\"Singles\", \"Groups\", \"Flex\"])) & (df['account_type'] != \"Broker\") & (df['location_general'] == \"Suites\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Nightly Suites\"\n",
    "            \n",
    "    df.loc[\n",
    "        (df['plan_type'].isin([\"Singles\", \"Groups\", \"Flex\"])) & (df['account_type'] != \"Broker\") & (df['pc_one_two'] == \"YI\") & (df['is_trade'] == False)\n",
    "        , 'ticket_type'\n",
    "        ] = \"Nightly Suites\"\n",
    "\n",
    "    df.loc[\n",
    "        (df['is_trade'] == False) & (df['account_type'] == \"Broker\")\n",
    "        , 'ticket_type'\n",
    "        ] = \"Secondary\"\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_ticket_type(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create is_renewal\n",
    "\n",
    "def create_is_renewal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['is_renewal'] = False\n",
    "    # df.loc[((df['pc_three'] == \"R\") & (df['pc_two_three'] != \"GR\")) & (~df['pc_one'].isin([\"U\", \"V\", \"W\"])), 'is_renewal'] = True\n",
    "    df.loc[((df['pc_three'] == \"R\") & (df['pc_two_three'] != \"GR\")), 'is_renewal'] = True\n",
    "\n",
    "    df['is_renewal_text'] = [\"Renewal\" if x is True else \"New Business\" for x in df['is_renewal']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_renewal(initial_df)\n",
    "\n",
    "# create is upgrade\n",
    "\n",
    "def create_is_upgrade(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['is_upgrade'] = False\n",
    "    df.loc[((df['pc_three_four'] == \"RU\") & (df['location_general'] != \"Suites\")), 'is_upgrade'] = True\n",
    "\n",
    "    df['is_renewal_and_upgrade_text'] = df['is_renewal_text'] \n",
    "    df.loc[(df['is_upgrade'] == True), 'is_renewal_and_upgrade_text'] = \"Upgrade\"\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_upgrade(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comp seats\n",
    "\n",
    "def create_is_comp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "    #df['is_comp'] = df.apply(lambda row: True if row['block_purchase_price'] == 0 else False, axis = 1)\n",
    "\n",
    "    df['is_comp'] = [True if x == 0 else False for x in df['block_purchase_price']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_is_comp(initial_df)\n",
    "\n",
    "# create comp/paid seats\n",
    "\n",
    "def create_paid_comp_seats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        - seats must be exploded\n",
    "    \"\"\"\n",
    "\n",
    "    #df['paid_seats'] = df.apply(lambda row: 1 if row['is_comp'] is False else 0, axis = 1)\n",
    "    df['paid_seats'] = [1 if x is False else 0 for x in df['is_comp']]\n",
    "    #df['comp_seats'] = df.apply(lambda row: 1 if row['is_comp'] is True else 0, axis = 1)\n",
    "    df['comp_seats'] = [1 if x is True else 0 for x in df['is_comp']]\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_paid_comp_seats(initial_df)\n",
    "\n",
    "# create total seats\n",
    "\n",
    "initial_df['total_seats'] = initial_df['paid_seats']+initial_df['comp_seats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_comp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is_comp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_comp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 21\u001b[0m initial_df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_food_fee\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_gross_without_food\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_food_fee\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mcreate_food_fee\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     12\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc_one\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc_one\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n\u001b[1;32m---> 15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfood_fee\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_comp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36mcreate_food_fee.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     12\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc_one\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc_one\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m     15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood_fee\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_comp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is_comp'"
     ]
    }
   ],
   "source": [
    "# create gross/net revenue\n",
    "\n",
    "def create_food_fee(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    '''\n",
    "        - seats must be exploded\n",
    "    '''\n",
    "\n",
    "    df['food_fee'] = 0\n",
    "\n",
    "    df.loc[df['pc_one'] == \"Z\", 'food_fee'] = 25\n",
    "    df.loc[df['pc_one'] == \"Y\", 'food_fee'] = 15\n",
    "    df.loc[df['pc_one'] == \"X\", 'food_fee'] = 35\n",
    "\n",
    "    df['food_fee'] = df.apply(\n",
    "        lambda row: row['food_fee'] if row['is_comp'] is False else 0, axis = 1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_food_fee(initial_df)\n",
    "\n",
    "def create_gross_without_food(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    if 'event_food_fee' in df.columns:\n",
    "        df['gross_without_food'] = df['block_purchase_price'] - df['event_food_fee']\n",
    "    else:\n",
    "        df['gross_without_food'] = df['block_purchase_price'] - df['food_fee']\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_gross_without_food(initial_df)\n",
    "\n",
    "def create_net_revenue_internal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    '''\n",
    "         - needs seats exploded\n",
    "    '''\n",
    "\n",
    "    #df['net_revenue'] = 0\n",
    "    #df.loc[(df['is_host'] == True), 'net_revenue'] = df['gross_without_food'] / 1.07\n",
    "    #df.loc[(df['is_host'] == False), 'net_revenue'] = (df['pc_ticket'] + df['pc_licfee'] + df['surchg_amount']) / 1.07\n",
    "\n",
    "    # df['net_revenue'] = df.apply(\n",
    "    #     lambda row: (row['gross_without_food'] / 1.07) if rowc['is_host'] == True\n",
    "    #         else ((row['pc_ticket'] + row['pc_licfee'] + row['surchg_amount']) / 1.07), axis = 1\n",
    "    # )\n",
    "\n",
    "    df['net_revenue'] = df['gross_without_food'] / 1.07\n",
    "\n",
    "    return df\n",
    "\n",
    "initial_df = create_net_revenue_internal(initial_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Season - DONE\n",
    "### Is Logitix - DONE\n",
    "### Is Sponsor - DONE\n",
    "### Is Trade - DONE\n",
    "### Account Type - DONE\n",
    "### Account Type Description Group - DONE\n",
    "### Ticket Type - DONE\n",
    "### Is Renewal - DONE\n",
    "### Is Comp - DONE\n",
    "### Paid Comp Seats - DONE\n",
    "### Paid Seats - DONE\n",
    "### Comp Seats - DONE\n",
    "### Total Seats - DONE\n",
    "### Gross Revenue - DONE\n",
    "### Net Revenue - DONE\n",
    "### Location General - DONE\n",
    "### Location Specific - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\catnip\\fla_redshift.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['processed_date'] = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "# FLA_Redshift(**rs_creds).write_to_warehouse(df = final_df, table_name= \"cth_v_plans_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    df['last_seat'] = [x + (y-1) for (x,y) in zip(df['seat_num'], df['num_seats'])]\n",
    "\n",
    "    df = break_out_price_code(df)\n",
    "    df = explode_block_seating(df)\n",
    "\n",
    "    df['paid_amount'] = df['block_purchase_price'] * df['percent_paid']\n",
    "    df['owed_amount'] = df['block_purchase_price'] * (1 - df['percent_paid'])\n",
    "\n",
    "    df = Account_Fields().create_is_logitix_2223(df); print(\"5\"); print(datetime.now() - start_time)\n",
    "    df = Account_Fields().create_is_sponsor(df); print(\"6\"); print(datetime.now() - start_time)\n",
    "    df = Account_Fields().create_is_trade(df); print(\"7\"); print(datetime.now() - start_time)\n",
    "    df = Account_Fields().create_account_type(df); print(\"8\"); print(datetime.now() - start_time)\n",
    "    df = Account_Fields().create_acct_type_desc_group(df); print(\"9\"); print(datetime.now() - start_time)\n",
    "    \n",
    "    df = Financial_Fields().create_is_comp(df); print(\"10\"); print(datetime.now() - start_time)\n",
    "    df = Financial_Fields().create_paid_comp_seats(df); print(\"11\"); print(datetime.now() - start_time)\n",
    "\n",
    "    df = Location_Fields().create_location_general(df); print(\"12\"); print(datetime.now() - start_time)\n",
    "    df = Location_Fields().create_location_specific(df); print(\"13\"); print(datetime.now() - start_time)\n",
    "    df = Location_Fields().create_arena_level(df); print(\"14\"); print(datetime.now() - start_time)\n",
    "    df = Location_Fields().create_is_premium(df); print(\"15\"); print(datetime.now() - start_time)\n",
    "\n",
    "    df = Ticket_Type_Fields().create_is_renewal_2223(df); print(\"16\"); print(datetime.now() - start_time)\n",
    "    df = Ticket_Type_Fields().create_is_upgrade_2223(df); print(\"17\"); print(datetime.now() - start_time)\n",
    "    df = Ticket_Type_Fields().create_plan_type_2223(df); print(\"18\"); print(datetime.now() - start_time)\n",
    "    df = Ticket_Type_Fields().create_ticket_type_2223(df); print(\"19\"); print(datetime.now() - start_time)\n",
    "\n",
    "    df['fse_calc'] = 0\n",
    "    df.loc[(df['plan_event_name'].str.contains('FS')) & (df['is_comp'] == False), 'fse_calc'] = 1/42 * df['total_events']\n",
    "\n",
    "    ## seat ids\n",
    "    df['seat_id'] = [f\"{x}-{y}-{z}\" for (x,y,z) in zip(df['section_name'], df['row_name'], df['seat'])]\n",
    "    df['seat_event_id'] = [f\"{_a}-{x}-{y}-{z}\" for (x,y,z,_a) in zip(df['section_name'], df['row_name'], df['seat'], df['plan_event_name'])]\n",
    "\n",
    "\n",
    "    df = df[[c for c in df if c != 'processed_date'] + ['processed_date']]\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticket_Type_Fields():\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_upgrade_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['is_upgrade'] = False\n",
    "        df.loc[((df['pc_three_four'] == \"RU\") & (df['location_general'] != \"Suites\")), 'is_upgrade'] = True\n",
    "\n",
    "        df['is_renewal_and_upgrade_text'] = df['is_renewal_text'] \n",
    "        df.loc[(df['is_upgrade'] == True), 'is_renewal_and_upgrade_text'] = \"Upgrade\"\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_renewal_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        '''\n",
    "            - check with Ty on parameters\n",
    "        '''\n",
    "\n",
    "        df['is_renewal'] = False\n",
    "        df.loc[((df['pc_three'] == \"R\") & (df['pc_two_three'] != \"GR\")), 'is_renewal'] = True\n",
    "        # df.loc[(df['pc_two'] == \"F\") & (df['pc_three'].isin([str(i) for i in range(0, 10)])), 'is_renewal'] = True\n",
    "        # df.loc[(df['pc_two_three'] == \"HF\"), 'is_renewal'] = True\n",
    "        # df.loc[(df['pc_one'].isin([\"U\", \"V\", \"W\"])) & (df['pc_two'] == \"R\"), 'is_renewal'] = True\n",
    "\n",
    "        # df['is_renewal_text'] = df.apply(lambda row: \"Renewal\" if row['is_renewal'] is True else \"New Business\", axis = 1)\n",
    "        df['is_renewal_text'] = [\"Renewal\" if x is True else \"New Business\" for x in df['is_renewal']]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_is_host(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        #df['is_host'] = df.apply(lambda row: True if len(row['price_code']) == 1 or row['pc_two'] == '*' else False, axis = 1)\n",
    "\n",
    "        df['is_host'] = [True if x == '*' else False for x in df['pc_two']]\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_all_inclusive_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['is_all_inclusive'] = df.apply(\n",
    "            lambda row: True if (str(row['price_code_desc']).lower().find(\"inclusive\") >= 0) or (str(row['price_code_group']) == \"AI\") else False, axis = 1\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_ticket_type_playoffs_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['ticket_type_playoffs'] = \"Unknown\"\n",
    "\n",
    "        df.loc[\n",
    "            (df['plan_type'] == \"Full\") & (df['is_renewal'] == True) & (df['pc_four'] != \"A\")\n",
    "            , 'ticket_type_playoffs'\n",
    "            ] = \"Renewal Strips\"\n",
    "\n",
    "        df.loc[\n",
    "            (df['plan_type'] == \"Full\") & (df['is_renewal'] == True) & (df['pc_four'] == \"A\")\n",
    "            , 'ticket_type_playoffs'\n",
    "            ] = \"Add-on Strips\"\n",
    "\n",
    "        df.loc[\n",
    "            (df['plan_type'] == \"Full\") & (df['is_renewal'] == False)\n",
    "            , 'ticket_type_playoffs'\n",
    "            ] = \"New Business Strips\"\n",
    "\n",
    "        df.loc[\n",
    "            (df['account_type'] == \"Broker\")\n",
    "            , 'ticket_type_playoffs'\n",
    "            ] = \"Secondary\"\n",
    "        \n",
    "        df.loc[\n",
    "            (df['pc_two'].isin([\"*\", \"I\"]))\n",
    "            , 'ticket_type_playoffs'\n",
    "            ] = \"Singles\"\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_hrr_plan_type_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        if \"plan_type\" not in df.columns:\n",
    "            df = Ticket_Type_Fields().create_plan_type_2223(df)\n",
    "\n",
    "        df['hrr_plan_type'] = \"Plans\"\n",
    "        df.loc[(df['is_all_inclusive'] == True), 'hrr_plan_type'] = \"All-Inclusive\"\n",
    "        df.loc[(df['plan_type'] == \"Groups\"), 'hrr_plan_type'] = \"Groups\"\n",
    "        df.loc[(df['plan_type'] == \"Singles\"), 'hrr_plan_type'] = \"Singles\"\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_fse(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['fse_calc'] = 0\n",
    "        df.loc[(~df['ticket_type'].isin(['Singles', 'Nightly Suites', 'Groups', 'Flex'])) & (df['pc_two_three'] != \"GD\") & (df['is_comp'] == False), 'fse_calc'] = 1/42\n",
    "\n",
    "        return df \n",
    "\n",
    "    @staticmethod\n",
    "    def create_fse_2324(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        # df['fse_calc'] = 0\n",
    "        # df.loc[(df['ticket_type'].isin([\"Full\", \"Annual Suites\"])) & (df['is_comp'] == False), 'fse_calc'] = 1\n",
    "        # df.loc[(df['ticket_type'] == \"Premier\") & (df['is_comp'] == False), 'fse_calc'] = 25/42\n",
    "\n",
    "        df['fse_calc'] = 0\n",
    "        df.loc[(df['plan_event_name'] == \"23FSF\") & (df['is_comp'] == False), 'fse_calc'] = 1\n",
    "        df.loc[(df['plan_event_name'] == \"23FSP\") & (df['is_comp'] == False), 'fse_calc'] = 25/42\n",
    "\n",
    "        return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location_Fields():\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_sro(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        matches = [\"GA\", \"SRO\"]\n",
    "\n",
    "        if 'row_name' in df.columns:\n",
    "            df['is_sro'] = df.apply(lambda row: True if any(x in row['row_name'] for x in matches) else False, axis = 1)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_location_specific(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        my_loc_dict = {\n",
    "            \"Lowers\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
    "            \"Clubs\" : ['K', 'L', 'M'],\n",
    "            \"Uppers\" : ['N', 'O', 'P', 'Q', 'R', 'S', 'T'],\n",
    "            \"Suites\" : ['U', 'V', 'W'],\n",
    "            \"Lounge 954\" : ['X'],\n",
    "            \"Loft\" : ['Y'],\n",
    "            \"Corona\" : ['Z']\n",
    "        }\n",
    "\n",
    "        df['location_specific'] = \"Other\"\n",
    "\n",
    "        if 'pc_one' in df.columns:\n",
    "            for key, value in my_loc_dict.items():\n",
    "                df.loc[df['pc_one'].isin(value), 'location_specific'] = key\n",
    "        else:\n",
    "            print(\"pc_one does not exist!\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_location_events(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        my_loc_dict = {\n",
    "            \"ENN's\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'],\n",
    "            \"Loge Box\" : ['U'],\n",
    "            \"Club Suites\" : ['V'],\n",
    "            \"Suites\" : ['W'],\n",
    "            \"Lounge 954\" : ['X'],\n",
    "            \"Loft\" : ['Y'],\n",
    "            \"Corona\" : ['Z']\n",
    "        }\n",
    "\n",
    "        df['location_events'] = \"Other\"\n",
    "\n",
    "        if 'pc_one' in df.columns:\n",
    "            for key, value in my_loc_dict.items():\n",
    "                df.loc[df['pc_one'].isin(value), 'location_events'] = key\n",
    "        else:\n",
    "            print(\"pc_one does not exist!\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_location_events_general(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        my_loc_dict = {\n",
    "            \"ENN's\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T'],\n",
    "            \"Suites\": ['U', 'V', 'W'],\n",
    "            \"Clubs\": ['X', 'Y', 'Z']\n",
    "        }\n",
    "\n",
    "        df['location_events_general'] = \"Other\"\n",
    "\n",
    "        if 'pc_one' in df.columns:\n",
    "            for key, value in my_loc_dict.items():\n",
    "                df.loc[df['pc_one'].isin(value), 'location_events_general'] = key\n",
    "        else:\n",
    "            print(\"pc_one does not exist!\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_location_hrr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        if \"location_general\" not in df.columns:\n",
    "            df = Location_Fields().create_location_general(df)\n",
    "        \n",
    "        df['location_general'] = df['location_general'].replace(\"General\", \"Bowl\")\n",
    "        df = df.rename(columns = {'location_general' : 'hrr_location'})\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def create_arena_level(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        my_level_dict = {\n",
    "            \"Lowers\" : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
    "            \"Clubs\" : ['X', 'Z'],\n",
    "            \"Uppers\" : ['N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y'],\n",
    "            \"Suites\" : ['U', 'V', 'W'],\n",
    "        }\n",
    "\n",
    "        df['arena_level'] = \"Other\"\n",
    "\n",
    "        if 'pc_one' in df.columns:\n",
    "            for key, value in my_level_dict.items():\n",
    "                df.loc[(df['pc_one'].isin(value)), 'arena_level'] = key\n",
    "        else:\n",
    "            print(\"pc_one does not exist!\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_arena_level_internal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        my_level_dict = {\n",
    "            \"Lowers\": ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
    "            \"Clubs\": ['K', 'L', 'M'],\n",
    "            \"Uppers\": ['N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y'],\n",
    "            \"Suites\": ['U', 'V', 'W'],\n",
    "            \"Premium\": ['X', 'Z']\n",
    "        }\n",
    "\n",
    "        df['arena_level_internal'] = \"Other\"\n",
    "\n",
    "        if 'pc_one' in df.columns:\n",
    "            for key, value in my_level_dict.items():\n",
    "                df.loc[(df['pc_one'].isin(value)), 'arena_level_internal'] = key\n",
    "        else:\n",
    "            print(\"pc_one does not exist!\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def add_xy_coordinates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        seat_loc_df = FLA_Redshift().query_warehouse(\"SELECT * FROM custom.cth_xy_coordinates\")\n",
    "\n",
    "        if 'seat_id' in df.columns:\n",
    "            df = pd.merge(seat_loc_df, df, how = \"left\", on = \"seat_id\")\n",
    "        else:\n",
    "            print(\"seat_id does not exist\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_premium(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['is_premium'] = False\n",
    "        df.loc[(df['pc_one'].isin(['U', 'V', 'W', 'X', 'Z', '1', '2'])), 'is_premium'] = True\n",
    "\n",
    "        df['is_premium_text'] = [\"Premium\" if x is True else \"General\" for x in df['is_premium']]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Account_Fields():\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_logitix_playoffs_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['is_logitix'] = False\n",
    "        df.loc[(df['pc_four'] == \"L\"), 'is_logitix'] = True \n",
    "        df.loc[(df['pc_two_three'] == \"GL\"), 'is_logitix'] = True \n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_hrr_account_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['hrr_account_type'] = \"Standard\"\n",
    "        df.loc[df['acct_type_desc'] == \"Sponsor\", 'hrr_account_type'] = \"Sponsor\"\n",
    "        df.loc[df['acct_type_desc'].isin([\"Sponsor Trade\", \"Trade-Sponsor\"]), 'hrr_account_type'] = \"Sponsor Trade\"\n",
    "        df.loc[df['acct_type_desc'].isin([\"Marketing Trade\", \"Trade-Marketing\"]), 'hrr_account_type'] = \"Marketing Trade\"\n",
    "        df.loc[df['acct_type_desc'] == \"Trade\", 'hrr_account_type'] = \"Trade\"\n",
    "        \n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_acct_type_desc_group(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        corporate_values = [\"Sponsor\", \"Business\", \"Broker\", \"Community\", \"Suite\", \"Marketing\", \"PR\", \"Trade\", \"Box Office\"]\n",
    "\n",
    "        if 'acct_type_desc' in df.columns:\n",
    "\n",
    "            df['acct_type_desc_group'] = \"Personal\"\n",
    "            \n",
    "            for val in corporate_values:\n",
    "                df.loc[(df['acct_type_desc'].str.find(val)) >= 0, 'acct_type_desc_group'] = \"Corporate\"\n",
    "        else:\n",
    "            print(\"acct_type_desc does not exist!\")\n",
    "\n",
    "        return df \n",
    "\n",
    "\n",
    "def explode_block_seating(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "        Required Fields\n",
    "            - seat_num  - last_seat\n",
    "\n",
    "            - block_purchase_price\n",
    "            - paid amount\n",
    "    \"\"\"\n",
    "\n",
    "    ## num seats\n",
    "    df['seat_list'] = df.apply(lambda row: list(range(row['seat_num'], row['last_seat'] + 1)), axis = 1)\n",
    "\n",
    "    ## break out monies\n",
    "    if \"block_purchase_price\" in df.columns:\n",
    "        df['gross_rev_seat'] = df.apply(lambda row: row['block_purchase_price'] / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    if \"paid_amount\" in df.columns:\n",
    "        df['paid_amt_seat'] = df.apply(lambda row: (row['paid_amount'] / row['total_events']) / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    if \"original_block_purchase_price\" in df.columns:\n",
    "        df['orig_bpp_seat'] = df.apply(lambda row: row['original_block_purchase_price'] / len(row['seat_list']), axis = 1)\n",
    "\n",
    "    ## explode\n",
    "    df = df.explode('seat_list')\n",
    "\n",
    "    ## rename\n",
    "    df = df.drop(['seat_num', 'last_seat'], axis = 1).rename(\n",
    "        columns = {'seat_list' : 'seat'}\n",
    "        ).reset_index(drop = True)\n",
    "\n",
    "    if \"block_purchase_price\" in df.columns: \n",
    "        df = df.drop(['block_purchase_price'], axis = 1)\n",
    "        df = df.rename(columns = {'gross_rev_seat' : 'block_purchase_price'})\n",
    "\n",
    "    if \"paid_amount\" in df.columns: \n",
    "        df = df.drop(['paid_amount'], axis = 1)\n",
    "        df = df.rename(columns = {'paid_amt_seat' : 'paid_amount'})\n",
    "    \n",
    "    if \"original_block_purchase_price\" in df.columns: \n",
    "        df = df.drop(['original_block_purchase_price'], axis = 1)\n",
    "        df = df.rename(columns = {'orig_bpp_seat' : 'original_block_purchase_price'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_seat_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    #df['seat_id'] = df.apply(lambda row: f\"{row['section_name']}-{row['row_name']}-{row['seat']}\", axis = 1)\n",
    "    df['seat_id'] = [f\"{x}-{y}-{z}\" for (x,y,z) in zip(df['section_name'], df['row_name'], df['seat'])]\n",
    "\n",
    "    #df['seat_event_id'] = df.apply(lambda row: f\"{str(row['event_name'])}-{row['seat_id']}\", axis = 1)\n",
    "    df['seat_event_id'] = [f\"{_a}-{x}-{y}-{z}\" for (x,y,z,_a) in zip(df['section_name'], df['row_name'], df['seat'], df['event_name'])]\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def gameday_check() -> bool:\n",
    "\n",
    "    q = \"\"\"\n",
    "        SELECT \n",
    "            SUM( \n",
    "                CASE \n",
    "                    WHEN event_date = CAST(GETDATE() AS DATE) THEN 1\n",
    "                    ELSE 0\n",
    "                END \n",
    "            ) AS \"gameday_check\"\n",
    "        FROM \n",
    "            custom.cth_game_descriptions cgd \n",
    "    \"\"\"\n",
    "\n",
    "    return bool(FLA_Redshift().query_warehouse(sql_string = q).iloc[0,0])\n",
    "\n",
    "\n",
    "def create_is_game_over(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # df['is_game_over'] = df.apply(\n",
    "    #     lambda row: True if datetime.strptime(row['event_date'], \"%Y-%m-%d\").date() < date.today() else False, axis = 1\n",
    "    # )\n",
    "\n",
    "    df['is_game_over'] = [True if datetime.strptime(x, \"%Y-%m-%d\").date() < (datetime.now() - timedelta(hours = 1)).date() else False for x in df['event_date']]\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "def create_tier_from_event_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['tier'] = df['event_name'].str[-1]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_days_out_from_event(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['days_out_from_event'] = [FLA_Helpers().get_days_between(datetime.strftime(x, '%Y-%m-%d'), y) for (x,y) in zip(df['add_datetime'], df['event_date'])]\n",
    "\n",
    "    return df \n",
    "\n",
    "def create_days_out_bucket(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df['days_out_bucket'] = \"Unknown\"\n",
    "    df.loc[df['days_out_from_event'] <= 0, 'days_out_bucket'] = \"A: Day Of\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(1, 4, 1)]), 'days_out_bucket'] = \"B: 1-3 Days Out\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(4, 8, 1)]), 'days_out_bucket'] = \"C: 4-7 Days Out\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(8, 15, 1)]), 'days_out_bucket'] = \"D: 1-2 Weeks Out\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(15, 31, 1)]), 'days_out_bucket'] = \"E: 2-4 Weeks Out\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(31, 61, 1)]), 'days_out_bucket'] = \"F: 1-2 Months Out\"\n",
    "    df.loc[df['days_out_from_event'].isin([*range(61, 91, 1)]), 'days_out_bucket'] = \"G: 2-3 Months Out\"\n",
    "    df.loc[df['days_out_from_event'] >= 91, 'days_out_bucket'] = \"H: 3+ Months Out\"\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Financial_Fields():\n",
    "\n",
    "    @staticmethod\n",
    "    def create_is_comp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        #df['is_comp'] = df.apply(lambda row: True if row['block_purchase_price'] == 0 else False, axis = 1)\n",
    "\n",
    "        df['is_comp'] = [True if x == 0 else False for x in df['block_purchase_price']]\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_paid_comp_seats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        \"\"\"\n",
    "            - seats must be exploded\n",
    "        \"\"\"\n",
    "\n",
    "        #df['paid_seats'] = df.apply(lambda row: 1 if row['is_comp'] is False else 0, axis = 1)\n",
    "        df['paid_seats'] = [1 if x is False else 0 for x in df['is_comp']]\n",
    "        #df['comp_seats'] = df.apply(lambda row: 1 if row['is_comp'] is True else 0, axis = 1)\n",
    "        df['comp_seats'] = [1 if x is True else 0 for x in df['is_comp']]\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_food_fee_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        '''\n",
    "            - seats must be exploded\n",
    "        '''\n",
    "\n",
    "        df['food_fee'] = 0\n",
    "\n",
    "        df.loc[df['pc_one'] == \"Z\", 'food_fee'] = 25\n",
    "        df.loc[df['pc_one'] == \"Y\", 'food_fee'] = 15\n",
    "        df.loc[df['pc_one'] == \"X\", 'food_fee'] = 35\n",
    "\n",
    "        df['food_fee'] = df.apply(\n",
    "            lambda row: row['food_fee'] if row['is_comp'] is False else 0, axis = 1\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_food_fee_2223_events(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        ## - seats must be exploded\n",
    "\n",
    "        df['food_fee'] = 0\n",
    "\n",
    "        df.loc[(df['pc_one'] == \"Z\") & (df['pc_three'] != \"N\"), 'food_fee'] = 25\n",
    "        df.loc[(df['pc_one'] == \"X\") & (df['pc_three'] != \"N\"), 'food_fee'] = 35\n",
    "\n",
    "        df.loc[df['is_comp'] == True, 'food_fee'] = 0\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_gross_without_food(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        if 'event_food_fee' in df.columns:\n",
    "            df['gross_without_food'] = df['block_purchase_price'] - df['event_food_fee']\n",
    "        else:\n",
    "            df['gross_without_food'] = df['block_purchase_price'] - df['food_fee']\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_net_revenue_internal_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        '''\n",
    "            - needs seats exploded\n",
    "        '''\n",
    "\n",
    "        df['net_revenue'] = 0\n",
    "        df.loc[(df['is_host'] == True), 'net_revenue'] = df['gross_without_food'] / 1.07\n",
    "        df.loc[(df['is_host'] == False), 'net_revenue'] = (df['pc_ticket'] + df['pc_licfee'] + df['surchg_amount']) / 1.07\n",
    "\n",
    "        # df['net_revenue'] = df.apply(\n",
    "        #     lambda row: (row['gross_without_food'] / 1.07) if row['is_host'] == True\n",
    "        #         else ((row['pc_ticket'] + row['pc_licfee'] + row['surchg_amount']) / 1.07), axis = 1\n",
    "        # )\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_net_revenue_internal_2324(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        '''\n",
    "            - needs seats exploded\n",
    "        '''\n",
    "\n",
    "        df['net_revenue'] = 0\n",
    "        df.loc[(df['is_host'] == True), 'net_revenue'] = df['gross_without_food'] / 1.07\n",
    "        df.loc[(df['is_host'] == False), 'net_revenue'] = df['pc_ticket'] + df['pc_licfee'] + df['surchg_amount']\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_net_revenue_logitix_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        '''\n",
    "            - Need to attach pc_one to dynasty sales in order to get food fee\n",
    "        '''\n",
    "\n",
    "        # df['net_revenue'] = df.apply(\n",
    "        #     lambda row: (((row['block_purchase_price'] * 0.93) - row['food_fee']) / 1.07), axis = 1\n",
    "        # )\n",
    "\n",
    "        df['net_revenue'] = ((df['block_purchase_price'] * 0.93) - df['food_fee']) / 1.07\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_jl_parking_refund_field(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['net_revenue'] = df.apply(\n",
    "            lambda row: (row['net_revenue'] + (row['num_seats'] * 5)) if row['retail_ticket_type'].isin(['J-TYPE', 'L-TYPE']) else row['net_revenue']\n",
    "            , axis = 1\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_events_commission_rate_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        df['commission_type'] = \"Unknown\"\n",
    "        df['commission_rate'] = 0.0\n",
    "\n",
    "        mask = (df['pc_two'] == \"G\")\n",
    "        df.loc[mask, 'commission_type'] = \"Single Event Groups\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.04\n",
    "\n",
    "        mask = ((df['pc_two'] == \"G\") & (df['rep_department'] == \"Events\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Single Event Groups\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.08\n",
    "\n",
    "        mask = (df['location_events_general'].isin([\"ENN's\", \"Clubs\"]))\n",
    "        df.loc[mask, 'commission_type'] = \"Single Event Clubs and ENN\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.04\n",
    "\n",
    "        mask = (df['location_events_general'] == \"Suites\")\n",
    "        df.loc[mask, 'commission_type'] = \"Single Event Suites\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.08\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_hockey_commission_rate_2223(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['commission_type'] = \"Unknown\"\n",
    "        df['commission_rate'] = 0.0\n",
    "\n",
    "\n",
    "        ## New Business ##\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Full\") & (df['is_renewal'] == False) & (df['location_general'] != \"Lounge 954\") & (df['location_general'] != \"Suites\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Premier\") & (df['is_renewal'] == False) & (df['location_general'] != \"Lounge 954\") & (df['location_general'] != \"Suites\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Full\") & (df['is_renewal'] == False) & (df['location_general'] == \"Lounge 954\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Lounge 954 Premier Plus New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Premier\") & (df['is_renewal'] == False) & (df['location_general'] == \"Lounge 954\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Lounge 954 Premier New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Full\") & (df['is_renewal'] == False) & \n",
    "            ((df['location_general'].isin([\"Lounge 954\", \"Corona\"])) | (df['pc_one'].isin([\"1\", \"2\"]))) &\n",
    "            (df['rep_department'] == \"Premium\") & (df['rep_sales_service'] == \"Sales\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Premium Sales Premier Plus New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.12\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Premier\") & (df['is_renewal'] == False) & \n",
    "            ((df['location_general'].isin([\"Lounge 954\", \"Corona\"])) | (df['pc_one'].isin([\"1\", \"2\"]))) &\n",
    "            (df['rep_department'] == \"Premium\") & (df['rep_sales_service'] == \"Sales\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Premium Sales Premier New\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.12\n",
    "\n",
    "\n",
    "        ## Renewals ##\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Full\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_department'] == \"Membership\") & (df['rep_sales_service'] == \"Service\") & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.014\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Premier\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_department'] == \"Membership\") & (df['rep_sales_service'] == \"Service\")  & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.014\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Full\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_department'] == \"Premium\") & (df['rep_sales_service'] == \"Service\") & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.01\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Premier\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_department'] == \"Premium\") & (df['rep_sales_service'] == \"Service\") & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.01\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Full\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_sales_service'] == \"Sales\") & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = (\n",
    "            (df['ticket_type'] == \"Premier\") & (df['is_renewal'] == True) & (df['location_general'] != \"Lounge 954\") &\n",
    "            (df['rep_sales_service'] == \"Sales\") & (df['location_general'] != \"Suites\")\n",
    "        )\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Full\") & (df['is_renewal'] == True) & (df['location_general'] == \"Lounge 954\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Lounge 954 Premier Plus Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.01\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Premier\") & (df['is_renewal'] == True) & (df['location_general'] == \"Lounge 954\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Lounge 954 Premier Renewal\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.01\n",
    "\n",
    "\n",
    "        ## Upgrade ##\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Full\") & (df['is_upgrade'] == True) & (df['rep_sales_service'] == \"Service\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus Upgrade\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.05\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Full\") & (df['is_upgrade'] == True) & (df['rep_department'].isin([\"New Business\", \"Groups\"])))\n",
    "        df.loc[mask, 'commission_type'] = \"Bowl Premier Plus Upgrade\"\n",
    "        df.loc[mask, 'commission_rate'] = 0.1\n",
    "\n",
    "        ## Groups ##\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['tier'].isin([\"D\", \"E\"])))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey D, E Tier Group\"\n",
    "        df.loc[mask,'commission_rate'] = 0.10\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['tier'].isin([\"B\", \"C\"])))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey B, C Tier Group\"\n",
    "        df.loc[mask,'commission_rate'] = 0.06\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['tier'].isin([\"B\", \"C\"])) & (df['rep_department'] == \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey B, C Tier Group - Premium\"\n",
    "        df.loc[mask,'commission_rate'] = 0.04\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['tier'] == \"A\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey A Tier Group\"\n",
    "        df.loc[mask,'commission_rate'] = 0.04\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['pc_one'].isin([\"1\", \"2\", \"X\", \"Z\"])) & (df['rep_department'] == \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey Premium Group\"\n",
    "        df.loc[mask,'commission_rate'] = 0.1\n",
    "\n",
    "        ## Flex ##\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Flex\") & (df['location_general'] != \"Suites\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Flex\"\n",
    "        df.loc[mask,'commission_rate'] = 0.04\n",
    "\n",
    "        ## Nightly Suites ##\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Nightly Suites\") & (df['rep_department'] == \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey Nightly Suites - Premium\"\n",
    "        df.loc[mask,'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Nightly Suites\") & (df['rep_department'] != \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey Nightly Suites\"\n",
    "        df.loc[mask,'commission_rate'] = 0.05\n",
    "\n",
    "        ## Stable ##\n",
    "\n",
    "        mask = ((df['price_code'] == \"YI\") & (df['rep_department'] == \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey Nightly Stable - Premium\"\n",
    "        df.loc[mask,'commission_rate'] = 0.1\n",
    "\n",
    "        mask = ((df['price_code'] == \"YI\") & (df['rep_department'] != \"Premium\"))\n",
    "        df.loc[mask, 'commission_type'] = \"Hockey Nightly Stable\"\n",
    "        df.loc[mask,'commission_rate'] = 0.05\n",
    "\n",
    "        ## Double Commmission - Groups ##\n",
    "        '''\n",
    "            Group sales\n",
    "                - add_date between 10/3 - 10/14\n",
    "                - event_date in (10/6, 10/19, 10/23)\n",
    "        '''\n",
    "\n",
    "        mask = ((df['ticket_type'] == \"Groups\") & (df['add_datetime'] >= datetime(2022, 10, 3)) \n",
    "                & (df['add_datetime'] <= datetime(2022, 10, 14)) & (df['event_name'].isin([\"22H1006E\", \"22H1019C\", \"22H1023D\"])))\n",
    "        df.loc[mask,'commission_rate'] = df.loc[mask,'commission_rate'] * 2\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def create_commissionable_amount(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        # df['commissionable_amount'] = df.apply(\n",
    "        #     lambda row: (((row['block_purchase_price'] - row['food_fee']) / 1.07) * row['percent_paid']), axis = 1\n",
    "        # )\n",
    "\n",
    "        # df['commissionable_amount'] = df.apply(\n",
    "        #     lambda row: (((row['gross_without_food']) / 1.07) * row['percent_paid']), axis = 1\n",
    "        # )\n",
    "\n",
    "        df['commissionable_amount'] = (df['gross_without_food'] / 1.07) * df['percent_paid']\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_total_commissions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        # df['rep_commissions'] = df.apply(lambda row: (row['commissionable_amount'] * row['commission_rate']), axis = 1)\n",
    "\n",
    "        df['rep_commissions'] = df['commissionable_amount'] * df['commission_rate']\n",
    "\n",
    "        return df \n",
    "\n",
    "    @staticmethod\n",
    "    def create_total_tax_field(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df['total_tax'] = (df['net_revenue'] * 1.07) - df['net_revenue']\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

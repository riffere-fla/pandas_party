{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get game info data\n",
    "\n",
    "q = \"\"\"\n",
    "select \n",
    "    date(event_date) as event_date,\n",
    "    tier,\n",
    "    is_premier, \n",
    "    cast(original_six_plus_extra*100 as int) as original_six_plus_extra\n",
    "from  \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "tier_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "pl_tier_df = pl.from_pandas(tier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 24/25 ticket data\n",
    "\n",
    "#df_2324 = pl.read_csv(\"C:\\\\Users\\\\riffere\\\\Florida Panthers\\\\SP-BS - Documents\\\\Data Science\\\\Resources\\\\Files\\\\emily_ticket_sales_model_data_final.csv\")  \n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "         event_date,\n",
    "        CASE\n",
    "            WHEN pc_one IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN pc_one IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN pc_one IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN pc_one IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN pc_one IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        case\n",
    "            when allocations like '%Kill%' or locks like '%Kill%' then 0\n",
    "            else 1\n",
    "        end as capacity\n",
    "    from\n",
    "        custom.cth_v_ticket_status_2324),\n",
    "arena_level_agg as\n",
    "    (select\n",
    "         event_date, \n",
    "         arena_level_internal,\n",
    "         sum(capacity) as capacity\n",
    "    from\n",
    "        arena_levels\n",
    "    group by\n",
    "        event_date,\n",
    "        arena_level_internal),\n",
    "ticket_info as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        datediff('days',date(transaction_date), date(event_datetime)) as days_out,\n",
    "        arena_level_internal,\n",
    "        sum(paid_seats) as paid_seats,\n",
    "        sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2324\n",
    "    where\n",
    "        ticket_type in ('Singles', 'Nightly Suites', 'Secondary', 'Groups')\n",
    "    group by\n",
    "        event_datetime,\n",
    "        date(transaction_date),\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(arena_level_agg.event_date) as event_date,\n",
    "    ticket_info.days_out,\n",
    "    arena_level_agg.arena_level_internal,\n",
    "    capacity,\n",
    "    case \n",
    "        when arena_level_agg.arena_level_internal = 'Lowers' AND days_out > 80 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Uppers' AND days_out > 100 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Clubs' AND days_out > 50 THEN 0\n",
    "        when arena_level_agg.arena_level_internal = 'Premium' AND days_out > 30 THEN 0\n",
    "        else paid_seats\n",
    "        end as paid_seats\n",
    "from\n",
    "    arena_level_agg\n",
    "left join\n",
    "    ticket_info on date(arena_level_agg.event_date) = date(ticket_info.event_datetime)\n",
    "    and arena_level_agg.arena_level_internal = ticket_info.arena_level_internal\n",
    "order by\n",
    "    event_date,\n",
    "    arena_level_internal,\n",
    "    days_out\n",
    "\"\"\"\n",
    "\n",
    "df_2324 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "df_2324 = pl.from_pandas(df_2324)\n",
    "\n",
    "### coalesce(gross_revenue::int,0) as gross_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tickets left to sell by days out descending\n",
    "\n",
    "#df_2324['cumulative_tickets']  = df_2324.groupby(['event_date', 'arena_level_internal'])['paid_seats'].cumsum()\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col(\"paid_seats\").cum_sum().over([\"event_date\", \"arena_level_internal\"]).cast(pl.Int16).alias(\"cumulative_tickets\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join game info data on 24/25 ticket data\n",
    "\n",
    "#df_2324 = df_2324.merge(tier_df, on = 'event_date', how = 'left')\n",
    "df_2324 = df_2324.join(pl_tier_df, on=\"event_date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2324.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\3196607192.py:34: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\3196607192.py:47: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  .replace(arena_level_mapping, default=0)\n"
     ]
    }
   ],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('event_date').cast(pl.Date)\n",
    "# ])\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('gross_revenue').cast(pl.Int16)\n",
    "# ])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
    ")\n",
    "\n",
    "arena_level_mapping = {\n",
    "    'Clubs': 5,\n",
    "    'Lowers': 4,\n",
    "    'Uppers': 3,\n",
    "    'Suites': 2,\n",
    "    'Premium': 1\n",
    "}\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('arena_level_internal')\n",
    "      .replace(arena_level_mapping, default=0)\n",
    "      .cast(pl.Int16)\n",
    "      .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining')\n",
    ")\n",
    "\n",
    "df_2324 = df_2324.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) &\n",
    "    (pl.col(\"days_out\") >= 0) &\n",
    "    (pl.col('arena_level_internal').is_in(['Clubs','Lowers','Uppers','Suites','Premium']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2324['dow'] = [datetime.weekday(x) for x in df_2324['event_date']]\n",
    "# df_2324['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2324['tier']]\n",
    "# #df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# # pcs = sorted(df_2324['pc_one'].unique())\n",
    "# # pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# # df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "\n",
    "\n",
    "# df_2324['arena_level_num'] = [6 if arena_level_internal == 'Premium' else (5 if arena_level_internal == 'Clubs' else (4 if arena_level_internal == 'Lowers' else \n",
    "#                             (3 if arena_level_internal == 'Uppers' else (2 if arena_level_internal == 'Suites' else 1)))) for arena_level_internal in df_2324['arena_level_internal']]\n",
    "\n",
    "# #df_2324 = df_2324.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2324 = df_2324.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model(df_train, df_test):\n",
    "\n",
    "#     #df_train_subset = df_train[df_train['date_diff'] == days_out]\n",
    "\n",
    "#     X_train = df_train[['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra','days_out', 'cap_remaining']]\n",
    "#     y_train = df_train[['cumulative_tickets']]\n",
    "\n",
    "#     #df_test_subset = df_test[(df_test['days_out'] == days_out) & (df_test['ticket_type_final'] == 'Not Sold')]\n",
    "\n",
    "#     X_test = df_test[['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra', 'days_out', 'cap_remaining']]\n",
    "#     #y_test = df_test[['is_sold']]\n",
    " \n",
    "#     if len(X_test) > 0:\n",
    "#         ss = StandardScaler()\n",
    "#         x_train_scaled = ss.fit_transform(X_train)\n",
    "#         x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "#         clf = RandomForestClassifier(random_state = 1993)\n",
    "#         clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "#         predicted_df = pd.DataFrame(data = clf.predict(x_test_scaled), columns = ['cumulative_tickets_predicted'])\n",
    "#         predicted_df = pl.from_pandas(predicted_df)\n",
    "#         final_df = pl.concat([df_test, predicted_df], how = 'horizontal')\n",
    "\n",
    "#         return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 24/25 ticket data\n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "         event_date,\n",
    "        CASE\n",
    "            WHEN pc_one IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN pc_one IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN pc_one IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN pc_one IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN pc_one IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        case\n",
    "            when allocations like '%Kill%' or locks like '%Kill%' then 0\n",
    "            else 1\n",
    "        end as capacity\n",
    "    from\n",
    "        custom.cth_v_ticket_status_2425),\n",
    "arena_level_agg as\n",
    "    (select\n",
    "         event_date,\n",
    "         arena_level_internal,\n",
    "         sum(capacity) as capacity\n",
    "    from\n",
    "        arena_levels\n",
    "    group by\n",
    "        event_date,\n",
    "        arena_level_internal),\n",
    "current_info as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         arena_level_internal,\n",
    "         sum(paid_seats) as paid_seats,\n",
    "         sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2425\n",
    "    group by\n",
    "        event_datetime,\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(arena_level_agg.event_date) as event_date,\n",
    "    arena_level_agg.arena_level_internal,\n",
    "    datediff('days', current_date, cth_game_descriptions.event_datetime) as days_out,\n",
    "    tier,\n",
    "    cast(original_six_plus_extra*100 as int) as original_six_plus_extra,\n",
    "    is_premier,\n",
    "    capacity,\n",
    "    paid_seats,\n",
    "    capacity-paid_seats as cap_remaining\n",
    "from\n",
    "    arena_level_agg\n",
    "left join\n",
    "    current_info on arena_level_agg.arena_level_internal = current_info.arena_level_internal\n",
    "    and arena_level_agg.event_date = date(current_info.event_datetime)\n",
    "left join\n",
    "    custom.cth_game_descriptions on arena_level_agg.event_date = date(cth_game_descriptions.event_datetime)\n",
    " \"\"\"\n",
    "\n",
    "df_2425 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "# df_2425['days_out'] = df_2425['days_out'].astype(np.int64)\n",
    "# df_2425['original_six_plus_extra'] = df_2425['original_six_plus_extra'].astype(np.float32)\n",
    "# df_2425['days_out']\n",
    "# for col in df_2425.columns:\n",
    "#     print(df_2425[col].dtype)\n",
    "df_2425 = pl.from_pandas(df_2425)\n",
    "\n",
    "### gross_revenue,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\1435635451.py:41: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\1435635451.py:54: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  .replace(arena_level_mapping, default=0)\n"
     ]
    }
   ],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2425['dow'] = [datetime.weekday(x) for x in df_2425['event_datetime']]\n",
    "# df_2425['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2425['tier']]\n",
    "#df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "\n",
    "\n",
    "# df_2425['arena_level_num'] = [6 if arena_level_internal == 'Premium' else (5 if arena_level_internal == 'Clubs' else (4 if arena_level_internal == 'Lowers' else \n",
    "#                             (3 if arena_level_internal == 'Uppers' else (2 if arena_level_internal == 'Suites' else 1)))) for arena_level_internal in df_2425['arena_level_internal']]\n",
    "\n",
    "#df_2425 = df_2425.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2425 = df_2425.reset_index()\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2425['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2425 = df_2425.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "tier_mapping = {\n",
    "    'A': 5,\n",
    "    'B': 4,\n",
    "    'C': 3,\n",
    "    'D': 2,\n",
    "    'E': 1\n",
    "}\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('tier').replace(tier_mapping, default=0).cast(pl.Int16).alias('tier_num')\n",
    "])\n",
    "\n",
    "arena_level_mapping = {\n",
    "    'Clubs': 5,\n",
    "    'Lowers': 4,\n",
    "    'Uppers': 3,\n",
    "    'Suites': 2,\n",
    "    'Premium': 1\n",
    "}\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('arena_level_internal')\n",
    "      .replace(arena_level_mapping, default=0)\n",
    "      .cast(pl.Int16)\n",
    "      .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "# df_2425 = df_2425.with_columns(\n",
    "#     pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining'))\n",
    "\n",
    "df_2425 = df_2425.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) &\n",
    "    (pl.col(\"days_out\") >= 0) &\n",
    "     (pl.col('arena_level_internal').is_in(['Clubs','Lowers','Uppers','Suites','Premium']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2425.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "# def run_model(df, df_future, arena_level):\n",
    "\n",
    "#     x_train_table = df.filter(\n",
    "#         (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "\n",
    "#     X_train = x_train_table.select(['tier_num', 'arena_level_num', 'days_out', 'cap_remaining'])\n",
    "#     y_train = x_train_table.select(['cumulative_tickets'])\n",
    "\n",
    "#     x_test_table = df_future.filter(\n",
    "#         (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "#     X_test = x_test_table.select(['tier_num', 'arena_level_num', 'days_out', 'cap_remaining'])\n",
    "\n",
    "#     ss = StandardScaler()\n",
    "#     x_train_scaled = ss.fit_transform(X_train)\n",
    "#     x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "#     polynomial = LinearRegression().fit(x_train_scaled, np.array(y_train).ravel())\n",
    "\n",
    "#     return polynomial.predict(x_test_scaled)\n",
    "\n",
    "def run_model(df, df_future, arena_level):\n",
    "\n",
    "    x_train_table = df.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "\n",
    "    X_train = x_train_table.select(['tier_num', 'arena_level_num', 'days_out', 'is_premier'])\n",
    "    y_train = x_train_table.select(['cumulative_tickets'])\n",
    "\n",
    "    x_test_table = df_future.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    X_test = x_test_table.select(['tier_num', 'arena_level_num', 'days_out', 'is_premier'])\n",
    "\n",
    "    # poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "    # x_train_poly = poly.fit_transform(X_train)\n",
    "    # x_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    x_train_poly = ss.fit_transform(X_train)\n",
    "    x_test_poly = ss.fit_transform(X_test)\n",
    "\n",
    "    # x_train_poly = np.array(X_train)\n",
    "    # x_test_poly = np.array(X_test)\n",
    "\n",
    "    #polynomial = sm.OLS(np.array(y_train).ravel(), x_train_poly).fit()\n",
    "\n",
    "    y_log = np.nan_to_num(np.log(np.array(y_train).ravel()), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    polynomial = LinearRegression().fit(x_train_poly, y_log)\n",
    "\n",
    "    #print(polynomial.aic)\n",
    "\n",
    "    return polynomial.predict(x_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowers\n",
      "Premium\n",
      "Uppers\n",
      "Clubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\3230911877.py:52: RuntimeWarning: divide by zero encountered in log\n",
      "  y_log = np.nan_to_num(np.log(np.array(y_train).ravel()), nan=0.0, posinf=0.0, neginf=0.0)\n"
     ]
    }
   ],
   "source": [
    "# run by arena_level NOT SUITES!\n",
    "\n",
    "arena_levels = ['Lowers','Premium','Uppers','Clubs']\n",
    "\n",
    "final_df = pl.DataFrame(\n",
    "    schema= {\n",
    "        'event_date': pl.Date,\n",
    "        'arena_level_internal': pl.String,\n",
    "        'days_out': pl.Int16,\n",
    "        'tier': pl.String,\n",
    "        'original_six_plus_extra': pl.Int16,\n",
    "        'is_premier': pl.Boolean,\n",
    "        'capacity': pl.Int16,\n",
    "        'paid_seats': pl.Int16,\n",
    "        'cap_remaining': pl.Int16,\n",
    "        'dow': pl.Int16,\n",
    "        'tier_num': pl.Int16,\n",
    "        'arena_level_num': pl.Int16,\n",
    "        'literal' : pl.Float64\n",
    "    }\n",
    ")\n",
    "\n",
    "for arena_level in arena_levels:\n",
    "\n",
    "    temp = df_2425.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    result = run_model(df_2324, df_2425, arena_level)\n",
    "\n",
    "    temp = temp.with_columns([result])\n",
    "\n",
    "    final_df = pl.concat([final_df,temp], how = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\2110826848.py:2: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  suite_df = suite_df.with_columns(pl.zeros(pl.count()).alias('literal'))\n"
     ]
    }
   ],
   "source": [
    "suite_df = df_2425.filter((pl.col(\"arena_level_internal\").is_in(['Suites'])))\n",
    "suite_df = suite_df.with_columns(pl.zeros(pl.count()).alias('literal'))\n",
    "\n",
    "final_df = pl.concat([final_df,suite_df], how = 'vertical')\n",
    "final_df = final_df.rename({'literal':'cumulative_tickets_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total tickets prediction\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('cumulative_tickets_predicted')).exp()\n",
    "    .alias('cumulative_tickets_predicted'))\n",
    "])\n",
    "\n",
    "# create cumulative_tickets_predicted column so its greater than 0 and less than cap_remianing\n",
    "\n",
    "final_df = final_df.with_columns(\n",
    "        pl.when(pl.col(\"cumulative_tickets_predicted\") < 0)\n",
    "        .then(0)\n",
    "        .when(pl.col(\"cap_remaining\") < pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .then(pl.col(\"cap_remaining\"))\n",
    "        .otherwise(pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .alias(\"cumulative_tickets_predicted\")\n",
    ")\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('paid_seats') + pl.col('cumulative_tickets_predicted'))\n",
    "    .alias('total_predicted_tickets'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rate data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "    \n",
    "        game_desc.season,\n",
    "        game_desc.tier,\n",
    "        arena_level_internal,\n",
    "        ticket.event_date::date,\n",
    "        ticket.comp_seats::float,\n",
    "        ticket.paid_seats::float,\n",
    "        CASE\n",
    "            WHEN ticket.is_comp = TRUE AND ticket.did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"comp_seats_attended\",\n",
    "        CASE\n",
    "            WHEN is_comp = FALSE AND did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"paid_seats_attended\"\n",
    "    FROM\n",
    "        custom.cth_v_historical_ticket ticket\n",
    "    INNER JOIN\n",
    "        custom.cth_game_descriptions game_desc\n",
    "            ON ticket.event_datetime::date = game_desc.event_datetime::date\n",
    "            AND game_desc.season IN ('2021-22', '2022-23', '2023-24', '2024-25')\n",
    "            AND game_desc.event_datetime < current_date\n",
    "),\n",
    "tier_show_rate AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        tier,\n",
    "        arena_level_internal,\n",
    "        sum(historical.comp_seats_attended)::float / nullif(sum(historical.comp_seats),0) AS \"comp_show_rate\",\n",
    "        sum(historical.paid_seats_attended)::float / nullif(sum(historical.paid_seats),0) AS \"paid_show_rate\"\n",
    "    FROM\n",
    "        historical\n",
    "    GROUP BY\n",
    "        season, tier, arena_level_internal\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tier_show_rate\n",
    "where \n",
    "    tier != 'F'\n",
    "\"\"\"\n",
    "\n",
    "show_rate = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\532970369.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_paid_average).reset_index()\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_4500\\532970369.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comp_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_comp_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# get weighted show_rate avergaes over last 4 seasons\n",
    "\n",
    "weights = {'2021-22':0.5, '2022-23': .75, '2023-24':1.25,'2024-25':1.5}\n",
    "\n",
    "show_rate['weights'] = show_rate['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['paid_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_paid_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_paid_average).reset_index()\n",
    "\n",
    "def weighted_comp_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['comp_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_comp_average': wavg\n",
    "    })\n",
    "\n",
    "comp_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_comp_average).reset_index()\n",
    "\n",
    "tiers = pd.merge(paid_tiers, comp_tiers, on = ['tier', 'arena_level_internal'], how = 'left')\n",
    "tiers = pl.from_pandas(tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto 24/25 data and predict attendance\n",
    "\n",
    "final_df = final_df.join(tiers, on = ['tier','arena_level_internal'])\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('total_predicted_tickets') * pl.col('weighted_paid_average'))\n",
    "    .alias('total_attendance'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.write_csv('C:\\\\Users\\\\riffere\\\\Desktop\\\\output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

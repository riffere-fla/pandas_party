{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = \"\"\"\n",
    "# with seats as\n",
    "#     (select\n",
    "#         distinct seat_id, pc_one\n",
    "#     from\n",
    "#         custom.cth_manifest_2223),\n",
    "# event_dates as\n",
    "#     (select\n",
    "#         event_date, tier, is_premier, original_six_plus_extra, abbreviation\n",
    "#     from\n",
    "#         custom.cth_game_descriptionsv  \n",
    "#     where\n",
    "#         season = '2023-24' and game_type = 1 and event_date = '2023-10-19'),\n",
    "# transaction_dates as\n",
    "#     (select\n",
    "#          transaction_date\n",
    "#      from\n",
    "#          custom.cth_v_ticket_2324\n",
    "#      where\n",
    "#         date(event_datetime) >= date(transaction_date)),\n",
    "# other as\n",
    "#     (select\n",
    "#         event_datetime, section, row, seat, transaction_date,\n",
    "#         cast(section as varchar)+'-'+cast(row as varchar)+'-'+cast(seat as varchar) as seat_id, gross_revenue, ticket_type\n",
    "#     from\n",
    "#         custom.cth_v_ticket_2324),\n",
    "# base as\n",
    "#     (select\n",
    "#         *\n",
    "#     from\n",
    "#         event_dates\n",
    "#     cross join\n",
    "#         seats\n",
    "#     cross join\n",
    "#         transaction_dates)\n",
    "# select\n",
    "#     base.event_date, base.transaction_date, tier, is_premier::int, datediff(day, date(other.transaction_date), date(base.event_date)) as days_out,\n",
    "#     original_six_plus_extra, base.seat_id, abbreviation, pc_one,\n",
    "#         CASE\n",
    "#             WHEN pc_one in ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8')\n",
    "#             THEN 'Lowers'\n",
    "#             WHEN pc_one in ('K', 'L', 'M') THEN 'Clubs'\n",
    "#             WHEN pc_one in ('N', 'O', 'P', 'Q', 'R', 'S', 'T') THEN 'Uppers'\n",
    "#             WHEN pc_one in ('U', 'V', 'W') THEN 'Suites'\n",
    "#             WHEN pc_one in ('X') THEN 'Amerant'\n",
    "#             WHEN pc_one in ('Y') THEN 'Loft'\n",
    "#             WHEN pc_one in ('Z') THEN 'Corona'\n",
    "#             ELSE 'unknown'\n",
    "#             END AS location,\n",
    "#     CASE\n",
    "#         when gross_revenue > 0 then gross_revenue\n",
    "#         else 0\n",
    "#     end as block_purchase_price,\n",
    "#     CASE\n",
    "#         when ticket_type IS NOT NULL then ticket_type\n",
    "#         else 'Not Sold'\n",
    "#     end as ticket_type_final,\n",
    "#     CASE\n",
    "#         when ticket_type_final in ('Full', 'Annual Suites', 'Premier', 'Flex', 'Quarter', 'Sponsor', 'Trade') then 'Plans'\n",
    "#         when ticket_type_final in ('Not Sold') then 'Not Sold'\n",
    "#         else 'Nightly'\n",
    "#     end as ticket_type_group\n",
    "# from\n",
    "#     base\n",
    "# left join\n",
    "#     other on date(base.event_date) = date(other.event_datetime) and base.seat_id = other.seat_id\n",
    "# order by\n",
    "#     base.event_date, base.seat_id\n",
    "# \"\"\"\n",
    "# df_2324 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    event_date, tier, is_premier, original_six_plus_extra::int\n",
    "from  \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "tier_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "pl_tier_df = pl.from_pandas(tier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2324 = pl.read_csv(\"C:\\\\Users\\\\riffere\\\\Florida Panthers\\\\SP-BS - Documents\\\\Data Science\\\\Resources\\\\Files\\\\emily_ticket_sales_model_data_final.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2324 = df_2324.sample(n = 1500000, seed = 1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2324 = df_2324.merge(tier_df, on = 'event_date', how = 'left')\n",
    "df_2324 = df_2324.join(pl_tier_df, on=\"event_date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('event_date').cast(pl.Date)\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('gross_revenue').cast(pl.Int16)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_16060\\3798392910.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_2324 = df_2324.with_columns([\n"
     ]
    }
   ],
   "source": [
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "pcs = sorted(df_2324['pc_one'].unique())\n",
    "pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('pc_one').map_elements(\n",
    "        lambda x: pc_dict.get(x, None)\n",
    "    ).cast(pl.Int16)\n",
    "    .alias('pc_number')\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.when(pl.col('tier') == 'A').then(5)\n",
    "    .when(pl.col('tier') == 'B').then(4)\n",
    "    .when(pl.col('tier') == 'C').then(3)\n",
    "    .when(pl.col('tier') == 'D').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('tier_num')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2324['dow'] = [datetime.weekday(datetime.strptime(x, \"%Y-%m-%d\")) for x in df_2324['event_date']]\n",
    "# df_2324['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2324['tier']]\n",
    "# #df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "# df_2324 = df_2324.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2324 = df_2324.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(df_train, df_test):\n",
    "\n",
    "    #df_train_subset = df_train[df_train['date_diff'] == days_out]\n",
    "\n",
    "    X_train = df_train[['dow', 'tier_num', 'pc_number', 'is_premier', 'original_six_plus_extra','days_out']]\n",
    "    y_train = df_train[['is_sold']]\n",
    "\n",
    "    #df_test_subset = df_test[(df_test['days_out'] == days_out) & (df_test['ticket_type_final'] == 'Not Sold')]\n",
    "\n",
    "    X_test = df_test[['dow', 'tier_num', 'pc_number', 'is_premier', 'original_six_plus_extra','days_out']]\n",
    "    #y_test = df_test[['is_sold']]\n",
    " \n",
    "    if len(X_test) > 0:\n",
    "        ss = StandardScaler()\n",
    "        x_train_scaled = ss.fit_transform(X_train)\n",
    "        x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "        clf = RandomForestClassifier(random_state = 1993)\n",
    "        clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "        predicted_df = pd.DataFrame(data = clf.predict(x_test_scaled), columns = ['is_sold_predicted'])\n",
    "        predicted_df = pl.from_pandas(predicted_df)\n",
    "        final_df = pl.concat([df_test, predicted_df], how = 'horizontal')\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model(df_test, df_train):\n",
    "\n",
    "#     #df_test_subset = df_test[(df_test['days_out'] == days_out) & (df_test['ticket_type_final'] == 'Not Sold')]\n",
    "\n",
    "#     X_test = df_test[['dow', 'tier_num', 'pc_num', 'is_premier', 'original_six_plus_extra','days_out']]\n",
    "#     y_test = df_test[['ticket_type_group']]\n",
    "\n",
    "#     #df_train_subset = df_train[df_train['date_diff'] == days_out]\n",
    "\n",
    "#     X_train = df_train[['dow', 'tier_num', 'pc_num', 'is_premier', 'original_six_plus_extra','days_out']]\n",
    "#     y_train = df_train[['ticket_type_group']]\n",
    "\n",
    "#     if len(X_test) > 0:\n",
    "#         ss = StandardScaler()\n",
    "#         x_train_scaled = ss.fit_transform(X_train)\n",
    "#         x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "#         clf = RandomForestClassifier(random_state = 1993)\n",
    "#         clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "#         predicted_df = pd.DataFrame(data = clf.predict_proba(x_test_scaled), columns = ['Nightly', 'Not Sold', 'Plans'])\n",
    "#         final_df = pd.concat([df_test.reset_index(), predicted_df], axis = 1)\n",
    "\n",
    "#         return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "with seat_ids as\n",
    "    (select\n",
    "        date(cth_game_descriptions.event_datetime) as event_date,\n",
    "        seat_id,\n",
    "        tier,\n",
    "        is_premier,\n",
    "        original_six_plus_extra,\n",
    "        price_level as pc_one,\n",
    "        datediff('days', current_date, cth_game_descriptions.event_datetime) as days_out\n",
    "    from\n",
    "        custom.cth_v_manifest_2425\n",
    "    left join\n",
    "        custom.cth_game_descriptions on cth_v_manifest_2425.event_datetime = cth_game_descriptions.event_datetime\n",
    "    group by\n",
    "        cth_game_descriptions.event_datetime,\n",
    "        seat_id,\n",
    "        tier,\n",
    "        is_premier,\n",
    "        original_six_plus_extra,\n",
    "        price_level),\n",
    "    event_dates as\n",
    "    (select\n",
    "        date(cth_v_ticket_2425.event_datetime) as event_date,\n",
    "        seat_id\n",
    "    from\n",
    "        custom.cth_v_ticket_2425)\n",
    "select\n",
    "    seat_ids.event_date as event_date,\n",
    "    seat_ids.seat_id,\n",
    "    tier,\n",
    "    pc_one,\n",
    "    is_premier,\n",
    "    original_six_plus_extra,\n",
    "    days_out,\n",
    "    case\n",
    "        when event_dates.seat_id is not null then True\n",
    "        else False\n",
    "    end as is_sold\n",
    "from\n",
    "    seat_ids\n",
    "left join\n",
    "    event_dates on seat_ids.seat_id = event_dates.seat_id\n",
    "    and seat_ids.event_date = event_dates.event_date\"\"\"\n",
    "\n",
    "df_2425 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "# df_2425['days_out'] = df_2425['days_out'].astype(np.int64)\n",
    "# df_2425['original_six_plus_extra'] = df_2425['original_six_plus_extra'].astype(np.float32)\n",
    "# df_2425['days_out']\n",
    "# for col in df_2425.columns:\n",
    "#     print(df_2425[col].dtype)\n",
    "df_2425 = pl.from_pandas(df_2425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_16060\\1335230582.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_2425 = df_2425.with_columns([\n"
     ]
    }
   ],
   "source": [
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "pcs = sorted(df_2425['pc_one'].unique())\n",
    "pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('pc_one').map_elements(\n",
    "        lambda x: pc_dict.get(x, None)\n",
    "    ).cast(pl.Int16)\n",
    "    .alias('pc_number')\n",
    "])\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.when(pl.col('tier') == 'A').then(5)\n",
    "    .when(pl.col('tier') == 'B').then(4)\n",
    "    .when(pl.col('tier') == 'C').then(3)\n",
    "    .when(pl.col('tier') == 'D').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('tier_num')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2425_model = df_2425.filter(pl.col('is_sold') == False)\n",
    "df_2425_model = df_2425_model.filter(pl.col('days_out') >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_825, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_date</th><th>seat_id</th><th>tier</th><th>pc_one</th><th>is_premier</th><th>original_six_plus_extra</th><th>days_out</th><th>is_sold</th><th>dow</th><th>pc_number</th><th>tier_num</th></tr><tr><td>date</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>f64</td><td>i64</td><td>bool</td><td>i16</td><td>i16</td><td>i16</td></tr></thead><tbody><tr><td>2025-02-02</td><td>&quot;310-15-9&quot;</td><td>&quot;D&quot;</td><td>&quot;T&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>27</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;SL33-SRO-9&quot;</td><td>&quot;D&quot;</td><td>&quot;W&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>30</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;312-15-4&quot;</td><td>&quot;D&quot;</td><td>&quot;T&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>27</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;CL30-3-10&quot;</td><td>&quot;D&quot;</td><td>&quot;M&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>20</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;333-15-10&quot;</td><td>&quot;D&quot;</td><td>&quot;P&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>23</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2025-02-02</td><td>&quot;334-12-12&quot;</td><td>&quot;D&quot;</td><td>&quot;P&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>23</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;CL07-4-1&quot;</td><td>&quot;D&quot;</td><td>&quot;Z&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>33</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;311-13-16&quot;</td><td>&quot;D&quot;</td><td>&quot;T&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>27</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;311-13-19&quot;</td><td>&quot;D&quot;</td><td>&quot;T&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>27</td><td>2</td></tr><tr><td>2025-02-02</td><td>&quot;311-13-18&quot;</td><td>&quot;D&quot;</td><td>&quot;T&quot;</td><td>true</td><td>0.0</td><td>97</td><td>false</td><td>7</td><td>27</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_825, 11)\n",
       "┌────────────┬────────────┬──────┬────────┬───┬─────────┬─────┬───────────┬──────────┐\n",
       "│ event_date ┆ seat_id    ┆ tier ┆ pc_one ┆ … ┆ is_sold ┆ dow ┆ pc_number ┆ tier_num │\n",
       "│ ---        ┆ ---        ┆ ---  ┆ ---    ┆   ┆ ---     ┆ --- ┆ ---       ┆ ---      │\n",
       "│ date       ┆ str        ┆ str  ┆ str    ┆   ┆ bool    ┆ i16 ┆ i16       ┆ i16      │\n",
       "╞════════════╪════════════╪══════╪════════╪═══╪═════════╪═════╪═══════════╪══════════╡\n",
       "│ 2025-02-02 ┆ 310-15-9   ┆ D    ┆ T      ┆ … ┆ false   ┆ 7   ┆ 27        ┆ 2        │\n",
       "│ 2025-02-02 ┆ SL33-SRO-9 ┆ D    ┆ W      ┆ … ┆ false   ┆ 7   ┆ 30        ┆ 2        │\n",
       "│ 2025-02-02 ┆ 312-15-4   ┆ D    ┆ T      ┆ … ┆ false   ┆ 7   ┆ 27        ┆ 2        │\n",
       "│ 2025-02-02 ┆ CL30-3-10  ┆ D    ┆ M      ┆ … ┆ false   ┆ 7   ┆ 20        ┆ 2        │\n",
       "│ 2025-02-02 ┆ 333-15-10  ┆ D    ┆ P      ┆ … ┆ false   ┆ 7   ┆ 23        ┆ 2        │\n",
       "│ …          ┆ …          ┆ …    ┆ …      ┆ … ┆ …       ┆ …   ┆ …         ┆ …        │\n",
       "│ 2025-02-02 ┆ 334-12-12  ┆ D    ┆ P      ┆ … ┆ false   ┆ 7   ┆ 23        ┆ 2        │\n",
       "│ 2025-02-02 ┆ CL07-4-1   ┆ D    ┆ Z      ┆ … ┆ false   ┆ 7   ┆ 33        ┆ 2        │\n",
       "│ 2025-02-02 ┆ 311-13-16  ┆ D    ┆ T      ┆ … ┆ false   ┆ 7   ┆ 27        ┆ 2        │\n",
       "│ 2025-02-02 ┆ 311-13-19  ┆ D    ┆ T      ┆ … ┆ false   ┆ 7   ┆ 27        ┆ 2        │\n",
       "│ 2025-02-02 ┆ 311-13-18  ┆ D    ┆ T      ┆ … ┆ false   ┆ 7   ┆ 27        ┆ 2        │\n",
       "└────────────┴────────────┴──────┴────────┴───┴─────────┴─────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2425_model.filter(pl.col('event_date') == datetime.strptime('2025-02-02', '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "final_df = run_model(df_2324, df_2425_model)\n",
    "\n",
    "# cm = confusion_matrix(final_df['is_sold'], final_df['is_sold_predicted'])\n",
    "# print(accuracy_score(final_df['is_sold'],final_df['is_sold_predicted']))\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Sold','Not Sold'])\n",
    "# disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataframe(df, percent_chunk):\n",
    "#     total_rows = len(df)\n",
    "#     chunk_size = int(total_rows * percent_chunk / 100)\n",
    "    \n",
    "#     for i in range(0, total_rows, chunk_size):\n",
    "#         end = min(i + chunk_size, total_rows)\n",
    "#         yield df.slice(i, end - i)\n",
    "\n",
    "# def process_partition(partition, model_func):\n",
    "#     # Apply the model to the current partition\n",
    "#     result = model_func(partition)\n",
    "    \n",
    "#     # Process the result as needed\n",
    "#     processed_result = result\n",
    "    \n",
    "#     return processed_result\n",
    "\n",
    "# for partition in split_dataframe(df_2324, 1):\n",
    "#     processed_partition = run_model(partition, partition)\n",
    "#     print('go')\n",
    "# processed_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_dates = df_2324['event_date'].unique()\n",
    "# today = str(date.today())\n",
    "# final_df2 = pd.DataFrame()\n",
    "# for event_date in unique_dates:\n",
    "#     days_out = (datetime.strptime(today, '%Y-%m-%d').date() - event_date).days\n",
    "#     for i in range(1,days_out):\n",
    "#        df = run_model(df_2324, df_2324)\n",
    "#        final_df2 = pd.concat([final_df2,df])\n",
    "#     #df = run_model(df_2324, df_2324, 42)\n",
    "#     #final_df = pd.concat([final_df,df])\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.group_by(by = 'event_date').agg(pl.col('is_sold_predicted').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (37, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>by</th><th>is_sold_predicted</th></tr><tr><td>date</td><td>u32</td></tr></thead><tbody><tr><td>2025-01-16</td><td>166</td></tr><tr><td>2024-11-27</td><td>1528</td></tr><tr><td>2024-12-20</td><td>330</td></tr><tr><td>2025-03-03</td><td>0</td></tr><tr><td>2025-04-12</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2025-02-02</td><td>0</td></tr><tr><td>2024-11-09</td><td>594</td></tr><tr><td>2025-02-27</td><td>24</td></tr><tr><td>2025-04-08</td><td>2</td></tr><tr><td>2024-11-07</td><td>1612</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (37, 2)\n",
       "┌────────────┬───────────────────┐\n",
       "│ by         ┆ is_sold_predicted │\n",
       "│ ---        ┆ ---               │\n",
       "│ date       ┆ u32               │\n",
       "╞════════════╪═══════════════════╡\n",
       "│ 2025-01-16 ┆ 166               │\n",
       "│ 2024-11-27 ┆ 1528              │\n",
       "│ 2024-12-20 ┆ 330               │\n",
       "│ 2025-03-03 ┆ 0                 │\n",
       "│ 2025-04-12 ┆ 0                 │\n",
       "│ …          ┆ …                 │\n",
       "│ 2025-02-02 ┆ 0                 │\n",
       "│ 2024-11-09 ┆ 594               │\n",
       "│ 2025-02-27 ┆ 24                │\n",
       "│ 2025-04-08 ┆ 2                 │\n",
       "│ 2024-11-07 ┆ 1612              │\n",
       "└────────────┴───────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_csv(\"C:\\\\Users\\\\riffere\\\\Desktop\\\\output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import polars as pl\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get game info data\n",
    "\n",
    "q = \"\"\"\n",
    "select \n",
    "    date(event_date) as event_date,\n",
    "    tier,\n",
    "    is_premier, \n",
    "    cast(original_six_plus_extra*100 as int) as original_six_plus_extra\n",
    "from  \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "tier_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "pl_tier_df = pl.from_pandas(tier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 24/25 ticket data\n",
    "\n",
    "#df_2324 = pl.read_csv(\"C:\\\\Users\\\\riffere\\\\Florida Panthers\\\\SP-BS - Documents\\\\Data Science\\\\Resources\\\\Files\\\\emily_ticket_sales_model_data_final.csv\")  \n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "        CASE\n",
    "            WHEN price_level IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN price_level IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN price_level IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN price_level IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN price_level IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        count(distinct seat_id) as capacity\n",
    "    from\n",
    "        custom.cth_v_manifest_2324\n",
    "    group by\n",
    "        arena_level_internal),\n",
    "event_dates as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        date(transaction_date) as transaction_date,\n",
    "        datediff('days', date(transaction_date), date(event_datetime)) as days_out\n",
    "    from\n",
    "        custom.cth_v_ticket_2324\n",
    "    group by\n",
    "        event_datetime,\n",
    "        date(transaction_date)),\n",
    "cross_join as\n",
    "    (select\n",
    "        *\n",
    "    from\n",
    "        arena_levels\n",
    "    cross join\n",
    "        event_dates),\n",
    "ticket_info as\n",
    "    (select\n",
    "        event_datetime,\n",
    "        datediff('days',date(transaction_date), date(event_datetime)) as days_out,\n",
    "        arena_level_internal,\n",
    "        sum(paid_seats) as paid_seats,\n",
    "        sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2324\n",
    "    group by\n",
    "        event_datetime,\n",
    "        date(transaction_date),\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(cross_join.event_datetime) as event_date,\n",
    "    cross_join.days_out,\n",
    "    cross_join.arena_level_internal,\n",
    "    capacity,\n",
    "    coalesce(paid_seats,0) as paid_seats\n",
    "from\n",
    "    cross_join\n",
    "left join\n",
    "    ticket_info on cross_join.event_datetime = ticket_info.event_datetime\n",
    "    and cross_join.arena_level_internal = ticket_info.arena_level_internal\n",
    "    and cross_join.days_out = ticket_info.days_out\n",
    "order by\n",
    "    event_date,\n",
    "    arena_level_internal,\n",
    "    days_out\n",
    "\"\"\"\n",
    "\n",
    "df_2324 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "df_2324 = pl.from_pandas(df_2324)\n",
    "\n",
    "### coalesce(gross_revenue::int,0) as gross_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tickets left to sell by days out descending\n",
    "\n",
    "#df_2324['cumulative_tickets']  = df_2324.groupby(['event_date', 'arena_level_internal'])['paid_seats'].cumsum()\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col(\"paid_seats\").cum_sum().over([\"event_date\", \"arena_level_internal\"]).alias(\"cumulative_tickets\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join game info data on 24/25 ticket data\n",
    "\n",
    "#df_2324 = df_2324.merge(tier_df, on = 'event_date', how = 'left')\n",
    "df_2324 = df_2324.join(pl_tier_df, on=\"event_date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2324.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('event_date').cast(pl.Date)\n",
    "# ])\n",
    "\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('gross_revenue').cast(pl.Int16)\n",
    "# ])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324 = df_2324.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.when(pl.col('tier') == 'A').then(5)\n",
    "    .when(pl.col('tier') == 'B').then(4)\n",
    "    .when(pl.col('tier') == 'C').then(3)\n",
    "    .when(pl.col('tier') == 'D').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('tier_num')\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns([\n",
    "    pl.when(pl.col('arena_level_internal') == 'Clubs').then(6)\n",
    "    .when(pl.col('arena_level_internal') == 'Lowers').then(5)\n",
    "    .when(pl.col('arena_level_internal') == 'Uppers').then(4)\n",
    "    .when(pl.col('arena_level_internal') == 'Suites').then(3)\n",
    "    .when(pl.col('arena_level_internal') == 'Premium').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "df_2324 = df_2324.with_columns(\n",
    "    pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining'))\n",
    "\n",
    "df_2324 = df_2324.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) & (pl.col(\"days_out\") >= 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2324['dow'] = [datetime.weekday(x) for x in df_2324['event_date']]\n",
    "# df_2324['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2324['tier']]\n",
    "# #df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# # pcs = sorted(df_2324['pc_one'].unique())\n",
    "# # pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# # df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "\n",
    "\n",
    "# df_2324['arena_level_num'] = [6 if arena_level_internal == 'Premium' else (5 if arena_level_internal == 'Clubs' else (4 if arena_level_internal == 'Lowers' else \n",
    "#                             (3 if arena_level_internal == 'Uppers' else (2 if arena_level_internal == 'Suites' else 1)))) for arena_level_internal in df_2324['arena_level_internal']]\n",
    "\n",
    "# #df_2324 = df_2324.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2324 = df_2324.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_model(df_train, df_test):\n",
    "\n",
    "#     #df_train_subset = df_train[df_train['date_diff'] == days_out]\n",
    "\n",
    "#     X_train = df_train[['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra','days_out', 'cap_remaining']]\n",
    "#     y_train = df_train[['cumulative_tickets']]\n",
    "\n",
    "#     #df_test_subset = df_test[(df_test['days_out'] == days_out) & (df_test['ticket_type_final'] == 'Not Sold')]\n",
    "\n",
    "#     X_test = df_test[['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra', 'days_out', 'cap_remaining']]\n",
    "#     #y_test = df_test[['is_sold']]\n",
    " \n",
    "#     if len(X_test) > 0:\n",
    "#         ss = StandardScaler()\n",
    "#         x_train_scaled = ss.fit_transform(X_train)\n",
    "#         x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "#         clf = RandomForestClassifier(random_state = 1993)\n",
    "#         clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "#         predicted_df = pd.DataFrame(data = clf.predict(x_test_scaled), columns = ['cumulative_tickets_predicted'])\n",
    "#         predicted_df = pl.from_pandas(predicted_df)\n",
    "#         final_df = pl.concat([df_test, predicted_df], how = 'horizontal')\n",
    "\n",
    "#         return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 24/25 ticket data\n",
    "\n",
    "q = \"\"\"\n",
    "with arena_levels as\n",
    "    (select\n",
    "        CASE\n",
    "            WHEN price_level IN ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') THEN 'Lowers'\n",
    "            WHEN price_level IN ('K', 'L', 'M') THEN 'Clubs'\n",
    "            WHEN price_level IN ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') THEN 'Uppers'\n",
    "            WHEN price_level IN ('U', 'V', 'W') THEN 'Suites'\n",
    "            WHEN price_level IN ('X', 'Z') THEN 'Premium'\n",
    "            ELSE 'Unknown'\n",
    "        END AS arena_level_internal,\n",
    "        count(distinct seat_id) as capacity\n",
    "    from\n",
    "        custom.cth_v_manifest_2425\n",
    "    group by\n",
    "        arena_level_internal),\n",
    "event_dates as\n",
    "    (select\n",
    "        distinct event_datetime\n",
    "    from\n",
    "        custom.cth_v_ticket_2425),\n",
    "cross_join as\n",
    "    (select\n",
    "        *\n",
    "    from\n",
    "        arena_levels\n",
    "    cross join\n",
    "        event_dates),\n",
    "current_info as\n",
    "    (select\n",
    "         event_datetime,\n",
    "         arena_level_internal,\n",
    "         sum(paid_seats) as paid_seats,\n",
    "         sum(gross_revenue) as gross_revenue\n",
    "    from\n",
    "        custom.cth_v_ticket_2425\n",
    "    group by\n",
    "        event_datetime,\n",
    "        arena_level_internal)\n",
    "select\n",
    "    date(cross_join.event_datetime) as event_date,\n",
    "    cross_join.arena_level_internal,\n",
    "    datediff('days', current_date, cth_game_descriptions.event_datetime) as days_out,\n",
    "    tier,\n",
    "    cast(original_six_plus_extra*100 as int) as original_six_plus_extra,\n",
    "    is_premier,\n",
    "    capacity,\n",
    "    paid_seats,\n",
    "    capacity-paid_seats as cap_remaining\n",
    "from\n",
    "    cross_join\n",
    "left join\n",
    "    current_info on cross_join.arena_level_internal = current_info.arena_level_internal\n",
    "    and cross_join.event_datetime = current_info.event_datetime\n",
    "left join\n",
    "    custom.cth_game_descriptions on cross_join.event_datetime = cth_game_descriptions.event_datetime\n",
    " \"\"\"\n",
    "\n",
    "df_2425 = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "# df_2425['days_out'] = df_2425['days_out'].astype(np.int64)\n",
    "# df_2425['original_six_plus_extra'] = df_2425['original_six_plus_extra'].astype(np.float32)\n",
    "# df_2425['days_out']\n",
    "# for col in df_2425.columns:\n",
    "#     print(df_2425[col].dtype)\n",
    "df_2425 = pl.from_pandas(df_2425)\n",
    "\n",
    "### gross_revenue,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model columns: dow, tier_num, arena_level_num, cap_remaining and filter out non-regular season games\n",
    "\n",
    "\n",
    "# df_2425['dow'] = [datetime.weekday(x) for x in df_2425['event_datetime']]\n",
    "# df_2425['tier_num'] = [5 if tier == 'A' else (4 if tier == 'B' else (3 if tier == 'C' else (2 if tier == 'D' else 1))) for tier in df_2425['tier']]\n",
    "#df_2324['random'] = [x for x in (np.random.rand(len(df_2324),1)/2)]\n",
    "\n",
    "# pcs = sorted(df_2324['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2324['pc_num'] = df_2324.apply(lambda row: pc_dict[row['pc_one']], axis = 1)\n",
    "\n",
    "\n",
    "# df_2425['arena_level_num'] = [6 if arena_level_internal == 'Premium' else (5 if arena_level_internal == 'Clubs' else (4 if arena_level_internal == 'Lowers' else \n",
    "#                             (3 if arena_level_internal == 'Uppers' else (2 if arena_level_internal == 'Suites' else 1)))) for arena_level_internal in df_2425['arena_level_internal']]\n",
    "\n",
    "#df_2425 = df_2425.sample(n=len(df_2324), random_state=1993)\n",
    "# df_2425 = df_2425.reset_index()\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col('event_date').dt.weekday().cast(pl.Int16).alias('dow')\n",
    "    ])\n",
    "\n",
    "# pcs = sorted(df_2425['pc_one'].unique())\n",
    "# pc_dict = dict((value,count) for count, value in enumerate(pcs))\n",
    "# df_2425 = df_2425.with_columns([\n",
    "#     pl.col('pc_one').map_elements(\n",
    "#         lambda x: pc_dict.get(x, None)\n",
    "#     ).cast(pl.Int16)\n",
    "#     .alias('pc_number')\n",
    "# ])\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.when(pl.col('tier') == 'A').then(5)\n",
    "    .when(pl.col('tier') == 'B').then(4)\n",
    "    .when(pl.col('tier') == 'C').then(3)\n",
    "    .when(pl.col('tier') == 'D').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('tier_num')\n",
    "])\n",
    "\n",
    "\n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.when(pl.col('arena_level_internal') == 'Clubs').then(6)\n",
    "    .when(pl.col('arena_level_internal') == 'Lowers').then(5)\n",
    "    .when(pl.col('arena_level_internal') == 'Uppers').then(4)\n",
    "    .when(pl.col('arena_level_internal') == 'Suites').then(3)\n",
    "    .when(pl.col('arena_level_internal') == 'Premium').then(2)\n",
    "    .otherwise(1)\n",
    "    .cast(pl.Int16)\n",
    "    .alias('arena_level_num')\n",
    "])\n",
    "\n",
    "# df_2425 = df_2425.with_columns(\n",
    "#     pl.col('capacity').sub(pl.col('cumulative_tickets')).alias('cap_remaining'))\n",
    "\n",
    "df_2425 = df_2425.filter(\n",
    "    (pl.col(\"tier\").is_in(['A','B','C','D','E'])) & (pl.col(\"days_out\") >= 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all int64 to int16 columns to make it run faster\n",
    "\n",
    "int64_columns = df_2425.select(pl.col(pl.Int64)).columns\n",
    "    \n",
    "df_2425 = df_2425.with_columns([\n",
    "    pl.col(col).cast(pl.Int16) for col in int64_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "def run_model(df, df_future, arena_level):\n",
    "\n",
    "    x_train_table = df.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "\n",
    "    X_train = x_train_table.select(['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra','days_out', 'cap_remaining'])\n",
    "    y_train = x_train_table.select(['cumulative_tickets'])\n",
    "\n",
    "    x_test_table = df_future.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    X_test = x_test_table.select(['dow', 'tier_num', 'arena_level_num', 'is_premier', 'original_six_plus_extra', 'days_out', 'cap_remaining'])\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    x_train_scaled = ss.fit_transform(X_train)\n",
    "    x_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "    polynomial = LinearRegression().fit(x_train_scaled, np.array(y_train).ravel())\n",
    "\n",
    "    return polynomial.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run by arena_level\n",
    "\n",
    "arena_levels = ['Lowers','Premium','Uppers', 'Suites','Clubs']\n",
    "\n",
    "final_df = pl.DataFrame(\n",
    "    schema= {\n",
    "        'event_date': pl.Date,\n",
    "        'arena_level_internal': pl.String,\n",
    "        'days_out': pl.Int16,\n",
    "        'tier': pl.String,\n",
    "        'original_six_plus_extra': pl.Int16,\n",
    "        'is_premier': pl.Boolean,\n",
    "        'capacity': pl.Int16,\n",
    "        'paid_seats': pl.Int16,\n",
    "        'cap_remaining': pl.Int16,\n",
    "        'dow': pl.Int16,\n",
    "        'tier_num': pl.Int16,\n",
    "        'arena_level_num': pl.Int16,\n",
    "        'literal' : pl.Float64\n",
    "    }\n",
    ")\n",
    "\n",
    "for arena_level in arena_levels:\n",
    "\n",
    "    temp = df_2425.filter(\n",
    "        (pl.col(\"arena_level_internal\").is_in([arena_level])))\n",
    "    \n",
    "    result = run_model(df_2324, df_2425, arena_level)\n",
    "\n",
    "    temp = temp.with_columns([result])\n",
    "\n",
    "    final_df = pl.concat([final_df,temp], how = 'vertical')\n",
    "\n",
    "final_df = final_df.rename({'literal':'cumulative_tickets_predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cumulative_tickets_predicted column so its greater than 0 and less than cap_remianing\n",
    "\n",
    "final_df = final_df.with_columns(\n",
    "        pl.when(pl.col(\"cumulative_tickets_predicted\") < 0)\n",
    "        .then(0)\n",
    "        .when(pl.col(\"cap_remaining\") < pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .then(pl.col(\"cap_remaining\"))\n",
    "        .otherwise(pl.col(\"cumulative_tickets_predicted\"))\n",
    "        .alias(\"cumulative_tickets_predicted\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total tickets prediction\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('paid_seats') + pl.col('cumulative_tickets_predicted'))\n",
    "    .alias('total_predicted_tickets'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical show rate data\n",
    "\n",
    "q = \"\"\"\n",
    "WITH historical AS (\n",
    "    SELECT\n",
    "        game_desc.season,\n",
    "        game_desc.tier,\n",
    "        arena_level_internal,\n",
    "        ticket.event_date::date,\n",
    "        ticket.comp_seats::float,\n",
    "        ticket.paid_seats::float,\n",
    "        CASE\n",
    "            WHEN ticket.is_comp = TRUE AND ticket.did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"comp_seats_attended\",\n",
    "        CASE\n",
    "            WHEN is_comp = FALSE AND did_attended = TRUE THEN 1\n",
    "            ELSE 0\n",
    "        END AS \"paid_seats_attended\"\n",
    "    FROM\n",
    "        custom.cth_v_historical_ticket ticket\n",
    "    INNER JOIN\n",
    "        custom.cth_game_descriptions game_desc\n",
    "            ON ticket.event_datetime::date = game_desc.event_datetime::date\n",
    "            AND game_desc.season IN ('2021-22', '2022-23', '2023-24', '2024-25')\n",
    "            AND game_desc.event_datetime < current_date\n",
    "),\n",
    "tier_show_rate AS (\n",
    "    SELECT\n",
    "        season,\n",
    "        tier,\n",
    "        arena_level_internal,\n",
    "        sum(historical.comp_seats_attended)::float / nullif(sum(historical.comp_seats),0) AS \"comp_show_rate\",\n",
    "        sum(historical.paid_seats_attended)::float / nullif(sum(historical.paid_seats),0) AS \"paid_show_rate\"\n",
    "    FROM\n",
    "        historical\n",
    "    GROUP BY\n",
    "        season, tier, arena_level_internal\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tier_show_rate\n",
    "where \n",
    "    tier != 'F'\n",
    "\"\"\"\n",
    "\n",
    "show_rate = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27220\\1985194415.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  paid_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_paid_average).reset_index()\n",
      "C:\\Users\\riffere\\AppData\\Local\\Temp\\ipykernel_27220\\1985194415.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comp_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_comp_average).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# get weighted show_rate avergaes over last 4 seasons\n",
    "\n",
    "weights = {'2021-22':0.5, '2022-23': .75, '2023-24':1.25,'2024-25':1.5}\n",
    "\n",
    "show_rate['weights'] = show_rate['season'].map(weights)\n",
    "\n",
    "def weighted_paid_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['paid_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_paid_average': wavg\n",
    "    })\n",
    "\n",
    "paid_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_paid_average).reset_index()\n",
    "\n",
    "def weighted_comp_average(group):\n",
    "    # Calculate the weighted sum\n",
    "    weighted_sum = (group['comp_show_rate'] * group['weights']).sum()\n",
    "    \n",
    "    # Calculate the weight sum\n",
    "    weight_sum = group['weights'].sum()\n",
    "    \n",
    "    # Calculate the weighted average\n",
    "    wavg = weighted_sum / weight_sum\n",
    "    \n",
    "    return pd.Series({\n",
    "        'weighted_comp_average': wavg\n",
    "    })\n",
    "\n",
    "comp_tiers = show_rate.groupby(by = ['tier', 'arena_level_internal']).apply(weighted_comp_average).reset_index()\n",
    "\n",
    "tiers = pd.merge(paid_tiers, comp_tiers, on = ['tier', 'arena_level_internal'], how = 'left')\n",
    "tiers = pl.from_pandas(tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto 24/25 data and predict attendance\n",
    "\n",
    "final_df = final_df.join(tiers, on = ['tier','arena_level_internal'])\n",
    "\n",
    "final_df = final_df.with_columns([\n",
    "    ((pl.col('total_predicted_tickets') * pl.col('weighted_paid_average'))\n",
    "    .alias('total_attendance'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write_csv('C:\\\\Users\\\\riffere\\\\Desktop\\\\output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pricing - Dynamic Pricing Model\n",
    "\n",
    "# seperate file (pricing_model_v1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Predicted Budget\n",
    "\n",
    "q = \"\"\"\n",
    "select \n",
    "    date(event_date)::varchar as event_date, sum(budget_goal) as budget_goal\n",
    "from  \n",
    "    custom.cth_budget_summary_2324\n",
    "group by\n",
    "    event_date\n",
    "order by \n",
    "    event_date\n",
    "\"\"\"\n",
    "budget_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predicted Revenue & Tickets\n",
    "\n",
    "q = \"\"\"\n",
    "select\n",
    "    cth_ticket_sales_model_2324.event_date, tier,\n",
    "    sum(paid_seats+expected_additional_paid_seats) as expected_final_paid_seats,\n",
    "    sum(comp_seats+expected_additional_comp_seats) as expected_final_comp_seats,\n",
    "    expected_final_paid_seats+expected_final_comp_seats as expected_final_seats,\n",
    "    sum(gross_revenue+expected_additional_revenue) as expected_final_gross_revenue\n",
    "from\n",
    "    custom.cth_ticket_sales_model_2324\n",
    "left join\n",
    "    custom.cth_game_descriptions on cth_ticket_sales_model_2324.event_date = cth_game_descriptions.event_date\n",
    "group by\n",
    "    cth_ticket_sales_model_2324.event_date, tier, abbreviation, start_time_tableau, day_of_week\n",
    "order by\n",
    "    cth_ticket_sales_model_2324.event_date\n",
    "\"\"\"\n",
    "predicted_df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Predicted Attendance\n",
    "\n",
    "# mulitply projected tickets by historical show rate\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT \n",
    "        h.paid_seats, h.did_attend, h.event_date\n",
    "    FROM \n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE \n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.paid_seats != 0)\n",
    "\n",
    "SELECT \n",
    "    g.tier, sum(a.did_attend)/sum(a.paid_seats) as paid_rate\n",
    "FROM \n",
    "    a\n",
    "LEFT JOIN \n",
    "    custom.cth_game_descriptions g on date(a.event_date) = date(g.event_date)\n",
    "GROUP BY \n",
    "    tier\n",
    "ORDER BY \n",
    "    tier\"\"\"\n",
    "\n",
    "paid_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT\n",
    "        h.comp_seats, h.did_attend, h.event_date\n",
    "    FROM\n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE\n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.comp_seats != 0)\n",
    "\n",
    "SELECT\n",
    "    g.tier, sum(a.did_attend)/sum(a.comp_seats) as comp_rate\n",
    "FROM\n",
    "    a\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions g on date(a.event_date) = date(g.event_date)\n",
    "GROUP BY\n",
    "    tier\n",
    "ORDER BY\n",
    "    tier\"\"\"\n",
    "\n",
    "comp_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "attendance_df = paid_seats.merge(comp_seats, how = 'left', on = 'tier')\n",
    "\n",
    "final_attendance_df = predicted_df.merge(right = attendance_df, how = 'left', on = 'tier')\n",
    "final_attendance_df['predicted_attendance'] = [(w*x)+(y*z) for w,x,y,z, in zip(final_attendance_df['expected_final_paid_seats'],\n",
    "                                                              final_attendance_df['paid_rate'], final_attendance_df['expected_final_comp_seats'], final_attendance_df['comp_rate'])]\n",
    "just_attendance = final_attendance_df[['event_date', 'predicted_attendance', 'expected_final_gross_revenue', 'expected_final_seats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Predicted Parking\n",
    "\n",
    "# polynomial model (built by Pavan), multiply by avg atp to get rev\n",
    "\n",
    "q = \"\"\"\n",
    "WITH attendance as\n",
    "    (SELECT\n",
    "        '2022-23' as season, event_date, sum(entry) as attendance\n",
    "    FROM\n",
    "        custom.cth_attendance_scans_2223\n",
    "    GROUP BY\n",
    "        event_date\n",
    "    ORDER BY\n",
    "        event_date)\n",
    "\n",
    "SELECT\n",
    "    attendance.event_date, tier, coalesce(attendance,0) as ticket_scans,\n",
    "    coalesce(sum(paid_amount),0) as parking_paid_amount, count(*)-1 as num_parking_transactions\n",
    "FROM\n",
    "    attendance\n",
    "LEFT JOIN\n",
    "    custom.Parkhub_v_transactions on attendance.event_date = Parkhub_v_transactions.event_date\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions on attendance.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    attendance.event_date > '2022-10-01'\n",
    "    and tier in ('A','B','C','D','E')\n",
    "    and attendance.event_date != '2022-11-09'\n",
    "GROUP BY\n",
    "    attendance.event_date, tier, ticket_scans\n",
    "ORDER BY\n",
    "    attendance.event_date, tier\n",
    "\"\"\"\n",
    "\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "#Historical Parking Data Clean Up \n",
    "df['weekend'] = df.apply(lambda row: 1 if datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 5 \n",
    "    or datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 6 else 0, axis = 1)\n",
    "df['tier_num'] = df.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else \n",
    "    (2 if row['tier'] == 'D' else (1 if row['tier'] == 'E' else 0)))), axis = 1)\n",
    "\n",
    "#2023-2024 Season Data Clean Up \n",
    "q = \"\"\"\n",
    "select \n",
    "    event_date, tier, day_of_week\n",
    "from \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "\n",
    "games = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "games['weekend'] = games.apply(lambda row: 1 if row['day_of_week'] =='Fri' or row['day_of_week']=='Sat'  or row['day_of_week']=='Sun'  else 0 , axis=1)\n",
    "games['tier_num'] = games.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else \n",
    "    (2 if row['tier'] == 'D' else (1 if row['tier'] == 'E' else 0)))), axis = 1)\n",
    "games = games.merge(right = just_attendance, how = 'left', on = 'event_date')\n",
    "\n",
    "#Training Data \n",
    "xdf = df[['ticket_scans', 'weekend', 'tier_num']]\n",
    "y = df[['num_parking_transactions']]\n",
    "\n",
    "# #Test Data \n",
    "xdf2 = games[['predicted_attendance', 'weekend', 'tier_num']] ## GET PREDICTED ATTENDANCE FROM ABOVE CODE!\n",
    "\n",
    "#Scaling Data\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_features2 = poly.fit_transform(xdf2)\n",
    "poly_features = poly.fit_transform(xdf)\n",
    "\n",
    "polynomial = LinearRegression().fit(poly_features, np.array(y).ravel())\n",
    "predicted = polynomial.predict(poly_features2)\n",
    "\n",
    "games['predicted_parking'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select \n",
    "    cast(date(event_datetime) as varchar) as event_date, count(*) as current_parking, sum(gross_revenue) as current_gross_rev\n",
    "from \n",
    "    custom.ctp_v_ticket\n",
    "where \n",
    "    event_type = '2023-24 Panthers Parking'\n",
    "    and price_type_group not like 'Comp%'\n",
    "group by \n",
    "    event_date\n",
    "\"\"\"\n",
    "\n",
    "current_parking = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "games = games.merge(current_parking, how = 'left', on = 'event_date')\n",
    "games['remaining_parking'] = [x-y for x,y in zip(games['predicted_parking'], games['current_parking'])]\n",
    "games['predicted_parking_revenue'] = [42.8*x+y for x,y in zip(games['remaining_parking'], games['current_gross_rev'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Predicted F&B & Merch\n",
    "\n",
    "# avg F&B & Merch per caps by tier (add DOW for drink deals and stuff, simply regression model)\n",
    "\n",
    "q = \"\"\"\n",
    "with a as\n",
    "    (select bypass_orderitems_2223.event_date, sum(line_item_gross_revenue) as fandb_rev\n",
    "    from custom.bypass_orderitems_2223\n",
    "    where event_type = 'Hockey'\n",
    "    group by bypass_orderitems_2223.event_date\n",
    "    order by bypass_orderitems_2223.event_date),\n",
    "b as\n",
    "    (select event_date, sum(entry) as entry\n",
    "     from custom.cth_attendance_scans_2223\n",
    "     group by event_date\n",
    "     UNION\n",
    "     select event_date, sum(entry) as entry\n",
    "     from custom.cth_attendance_scans_playoffs_2223\n",
    "     group by event_date),\n",
    "c as\n",
    "    (select event_date, sum(line_item_gross_revenue) as merch_rev\n",
    "     from custom.retailpro_invoice_items\n",
    "     group by event_date),\n",
    "\n",
    "temp as\n",
    "    (select a.event_date, tier,\n",
    "        CASE\n",
    "            when date_part('dw', date(a.event_date)) in (5,6,7) then 1\n",
    "            else 0\n",
    "        end as weekend, fandb_rev, entry, merch_rev, fandb_rev/entry as fandb_percap, merch_rev/entry as merch_percap\n",
    "    from a\n",
    "    left join b on a.event_date = b.event_date\n",
    "    left join c on a.event_date = c.event_date\n",
    "    left join custom.cth_game_descriptions on a.event_date = cth_game_descriptions.event_date\n",
    "    where a.event_date not like '2022-11-15')\n",
    "\n",
    "select tier, weekend, avg(fandb_percap) as fandb_percap, avg(merch_percap) as merch_percap\n",
    "from temp\n",
    "where tier in ('A','B','C','D','E')\n",
    "group by tier, weekend\n",
    "order by tier, weekend\n",
    "\"\"\"\n",
    "\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "final = games.merge(right = df, how = 'left', on = ['weekend', 'tier'])\n",
    "final['predicted_fandb'] = [x*y for x,y in zip(final['predicted_attendance'], final['fandb_percap'])]\n",
    "final['predicted_merch'] = [x*y for x,y in zip(final['predicted_attendance'], final['merch_percap'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.merge(budget_df, how = 'left', on = 'event_date')\n",
    "final = final[['event_date', 'tier', 'budget_goal', 'expected_final_gross_revenue', 'expected_final_seats',\n",
    "               'predicted_attendance', 'predicted_parking', 'predicted_parking_revenue','predicted_fandb', 'predicted_merch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955870.679880997"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['predicted_parking_revenue'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

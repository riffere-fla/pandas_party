{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from sqlalchemy import null\n",
    "from datetime import datetime\n",
    "\n",
    "from prefect.blocks.system import Secret\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\riffere\\\\Desktop\\\\shapes (4).csv\")\n",
    "FLA_Redshift(**rs_creds).write_to_warehouse(df = df, table_name= \"cth_xy_coordinates_suites_seatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\riffere\\\\Desktop\\\\nhlpanthers_custom_cordinates_pricelevels.csv\")\n",
    "FLA_Redshift(**rs_creds).write_to_warehouse(df = df, table_name= \"cth_xy_coordinates_pricelevels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nightly\n",
    "\n",
    "def extract_nightly():\n",
    "\n",
    "    q = \"\"\"\n",
    "    WITH temp AS\n",
    "        (SELECT\n",
    "            event_date, paid_seats, comp_seats, gross_revenue,\n",
    "            case\n",
    "                when pc_one in ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') then 'Lowers'\n",
    "                when pc_one in ('K', 'L', 'M') then 'Clubs'\n",
    "                when pc_one in ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') then 'Uppers'\n",
    "                when pc_one in ('U', 'V', 'W') then 'Suites'\n",
    "                when pc_one in ('X', 'Z') then 'Premium'\n",
    "                else Null\n",
    "            end as arena_level_internal\n",
    "        FROM\n",
    "            custom.cth_historical_all_1718_2223\n",
    "        WHERE\n",
    "            ticket_type in ('Singles', 'Nightly Suites', 'Flex')\n",
    "            and season in ('2021-22', '2022-23')\n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            date(event_datetime), paid_seats, comp_seats, gross_revenue,\n",
    "            case\n",
    "                when pc_one in ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') then 'Lowers'\n",
    "                when pc_one in ('K', 'L', 'M') then 'Clubs'\n",
    "                when pc_one in ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') then 'Uppers'\n",
    "                when pc_one in ('U', 'V', 'W') then 'Suites'\n",
    "                when pc_one in ('X', 'Z') then 'Premium'\n",
    "                else Null\n",
    "            end as arena_level_internal\n",
    "        FROM\n",
    "            custom.cth_v_ticket_2324\n",
    "        WHERE\n",
    "            ticket_type in ('Singles', 'Nightly Suites', 'Flex'))\n",
    "\n",
    "    SELECT\n",
    "        season, temp.event_date, arena_level_internal, sum(paid_seats) AS \"paid_seats\", sum(comp_seats) AS \"comp_seats\",\n",
    "        sum(gross_revenue) AS \"gross_revenue\", trimester, original_six_plus_extra, is_dense, is_holiday,\n",
    "        case\n",
    "            when day_of_week = 'Sat' then 2\n",
    "            when day_of_week in ('Fri','Sun') then 1\n",
    "            else 0\n",
    "        end as is_day_of_week\n",
    "    FROM\n",
    "        temp\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions on date(temp.event_date) = date(cth_game_descriptions.event_date)\n",
    "    WHERE\n",
    "        tier in ('A','B','C','D','E')\n",
    "    GROUP BY\n",
    "        season, temp.event_date, arena_level_internal, trimester, original_six_plus_extra, is_dense, is_holiday, is_day_of_week\n",
    "    ORDER BY\n",
    "        season, arena_level_internal, event_date\n",
    "    \"\"\"\n",
    "\n",
    "    # extract historical nightly\n",
    "    df_nightly = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "    return df_nightly\n",
    "\n",
    "def run_model(total_df, loc):\n",
    "\n",
    "    # subset to specific location\n",
    "    total_df = total_df[total_df['arena_level_internal'] == loc]\n",
    "\n",
    "    # x train\n",
    "    xtrain = total_df[total_df['season'].isin(['2021-22', '2022-23'])]\n",
    "    xtrain = xtrain[['is_day_of_week', 'trimester', 'original_six_plus_extra', 'is_dense', 'is_holiday']]\n",
    "\n",
    "    # x test\n",
    "    df2324 = total_df[total_df['season'] == '2023-24']\n",
    "    df2324_predict = df2324[['is_day_of_week', 'trimester', 'original_six_plus_extra', 'is_dense', 'is_holiday']]\n",
    "\n",
    "    # y train\n",
    "    ytrain = total_df[total_df['season'].isin(['2021-22', '2022-23'])]\n",
    "    ytrain = ytrain[['paid_seats']]\n",
    "    ytrain = np.log1p(ytrain)\n",
    "\n",
    "    # run model\n",
    "    svm = SVR(gamma = 'auto').fit(xtrain, np.array(ytrain).ravel())\n",
    "    df2324_predict = svm.predict(df2324_predict)\n",
    "    df2324_predict = [np.expm1(i) for i in df2324_predict]\n",
    "    df2324_predict = pd.DataFrame(df2324_predict).reset_index(drop = True)\n",
    "    df2324_predict['type'] = 'nightly'\n",
    "    df2324_predict['loc'] = loc\n",
    "\n",
    "    return df2324_predict\n",
    "\n",
    "def transform_nightly(df_nightly):\n",
    "\n",
    "    #df_nightly['tier_num'] = df_nightly.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else (2 if row['tier'] == 'D' else 1))), axis = 1)\n",
    "\n",
    "    # run ticket model by location\n",
    "    proj_df = pd.DataFrame()\n",
    "    locations = ['Clubs','Lowers','Premium','Suites','Uppers']\n",
    "    for loc in locations:\n",
    "        proj = run_model(df_nightly, loc)\n",
    "        proj_df = pd.concat([proj_df, proj], ignore_index = True)\n",
    "    proj_df = proj_df.rename(columns = {0:'projected_tickets'})\n",
    "\n",
    "    # subset y test\n",
    "    df2324 = df_nightly[df_nightly['season'] == '2023-24'].reset_index()\n",
    "    df2324 = pd.concat([df2324, proj_df], axis = 1)\n",
    "\n",
    "    df2324_final = df2324.groupby(by = 'event_date')[['projected_tickets']].sum()\n",
    "    df2324_final = pd.DataFrame(df2324_final).reset_index()\n",
    "    df2324_final['type'] = 'nightly'\n",
    "\n",
    "    return df2324_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plans\n",
    "\n",
    "def extract_plans():\n",
    "\n",
    "    v = \"\"\" \n",
    "    SELECT\n",
    "        date(c.event_datetime) as event_date, c.arena_level_internal,\n",
    "        g.tier, count(*) as \"num_seats\", sum(gross_revenue) as \"gross_revenue\", sum(gross_revenue)/count(*) as \"current_ATP\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2324 c\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions g on date(c.event_datetime) = date(g.event_date)\n",
    "    WHERE\n",
    "        c.ticket_type in ('Full', 'Premier', 'Annual Suites', 'Sponsor', 'Trade')\n",
    "        and tier in ('A','B','C','D','E')\n",
    "    GROUP BY\n",
    "        c.event_datetime, c.arena_level_internal, g.tier\n",
    "    ORDER BY\n",
    "        c.event_datetime;\n",
    "    \"\"\"\n",
    "\n",
    "    # extract plans\n",
    "    df_plans = FLA_Redshift(**rs_creds).query_warehouse(sql_string = v)\n",
    "\n",
    "    return df_plans\n",
    "\n",
    "def get_budget_proj():\n",
    "    \n",
    "    l = \"\"\"\n",
    "    SELECT\n",
    "        sum(budget_goal)\n",
    "    FROM\n",
    "        custom.cth_budget_summary_2324\n",
    "    WHERE\n",
    "        ticket_type IN ('Full', 'Half/Premier', 'Annual Suites', 'Sponsor', 'Trade')\n",
    "    \"\"\"\n",
    "\n",
    "    # get plans total expected revenue\n",
    "    budget_proj = FLA_Redshift(**rs_creds).query_warehouse(sql_string = l)\n",
    "\n",
    "    return budget_proj.iloc[0]\n",
    "\n",
    "def transform_plans(df_plans):\n",
    "\n",
    "    # get number of games by tier\n",
    "    num_tier = {'A' : 2, 'B' : 6, 'C' : 14, 'D' : 10, 'E' : 9}\n",
    "    num_tier = pd.DataFrame(data = [num_tier]).T\n",
    "    num_tier.columns = ['num_per_tier']\n",
    "    num_tier['tier'] = num_tier.index\n",
    "\n",
    "    # get percent revenue by tier\n",
    "    count_per = {'A' : 0.07, 'B' : 0.16, 'C' : 0.3, 'D' : 0.25, 'E' : 0.22}\n",
    "    count_df = pd.DataFrame(data = [count_per]).T\n",
    "    count_df.columns = ['count_per_tier']\n",
    "    count_df['tier'] = count_df.index\n",
    "    left = get_budget_proj() - df_plans['gross_revenue'].sum()\n",
    "\n",
    "    # get percent revenue by game by location\n",
    "    loc_per = {'Suites' : 0.1821, 'Clubs' : 0.0851, 'Uppers' : 0.0571, 'Premium' : 0.2509, 'Lowers' : 0.4247}\n",
    "    loc_per = pd.DataFrame(data = [loc_per]).T\n",
    "    loc_per.columns = ['count_per_loc']\n",
    "    loc_per['arena_level_internal'] = loc_per.index\n",
    "\n",
    "    # merge on plan info\n",
    "    df_final = df_plans.merge(num_tier, how = 'left', on = 'tier')\n",
    "    df_final_2 = df_final.merge(count_df, how = 'left', on = 'tier')\n",
    "    df_final_3 = df_final_2.merge(loc_per, how = 'left', on = 'arena_level_internal')\n",
    "    df_final_3.rename(columns = {'gross_revenue' : 'current_plans', 'location_specific': 'loc'}, inplace = True)\n",
    "\n",
    "    # get projected revenue by game and difference from current\n",
    "    df_final_3['left'] = left.iloc[0]   \n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "        date(event_date) as event_date, tier, datediff(day, getdate(), cast(event_date as date)) AS \"days_out\",\n",
    "        ratio_to_report(\"days_out\") OVER (PARTITION BY tier) AS \"percent_test\"\n",
    "    FROM\n",
    "        custom.cth_game_descriptions\n",
    "    WHERE\n",
    "        season = '2023-24'\n",
    "    ORDER BY\n",
    "        event_date\n",
    "    \"\"\"\n",
    "    percent_test = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "    df_final_3 = df_final_3.merge(percent_test, how = 'left', on = 'event_date')\n",
    "\n",
    "    df_final_3['total_expected_revenue'] = df_final_3.apply(lambda row: row['current_plans'] + (left*row['count_per_tier']*row['percent_test']*row['count_per_loc']), axis = 1)\n",
    "    df_final_3['projected_tickets'] = df_final_3['total_expected_revenue']/df_final_3['current_atp']\n",
    "\n",
    "    # # get daily tickets to hit expected and tickets at specific days out\n",
    "    # df_final_3['proj'] = df_final_3.apply(lambda row: row['total_expected_revenue']/row['current_atp'], axis = 1)\n",
    "    # df_final_3['daily'] = df_final_3.apply(lambda row: (row['proj']-row['num_seats'])/(datetime.strptime(row['event_date'], '%Y-%m-%d').date()\n",
    "    #         -datetime.strptime('2022-09-01', '%Y-%m-%d').date()).days, axis = 1)\n",
    "    # df_final_3['projected_tickets1'] = df_final_3.apply(lambda row: row['num_seats']+(((datetime.strptime(row['event_date'], '%Y-%m-%d').date()-\n",
    "    #         datetime.strptime('2022-09-01', '%Y-%m-%d').date()).days+1-days_out)*row['daily']), axis = 1)\n",
    "    # df_final_3['projected_tickets'] = df_final_3.apply(lambda row: 621 if row['loc'] == 'Lounge 954' and row['projected_tickets1'] > 621 else row['projected_tickets1'], axis = 1)\n",
    "    # df_final_3['type'] = 'plans'\n",
    "\n",
    "    df_final_3 = df_final_3.groupby(by = 'event_date')[['projected_tickets']].sum()\n",
    "    df_final_3 = pd.DataFrame(df_final_3).reset_index()\n",
    "    df_final_3['type'] = 'plans'\n",
    "    df_final_3['event_date'] = pd.to_datetime(df_final_3['event_date']).dt.normalize()\n",
    "\n",
    "    return df_final_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups\n",
    "\n",
    "def extract_groups():\n",
    "\n",
    "    w = \"\"\"\n",
    "    SELECT\n",
    "        '2023-24' as season, date(c.event_datetime) as event_date, tier, c.arena_level_internal, sum(paid_seats) as \"num_seats\",\n",
    "        sum(gross_revenue) as \"gross_revenue\", sum(gross_revenue)/sum(paid_seats) as \"current_ATP\"\n",
    "    FROM\n",
    "        custom.cth_v_ticket_2324 c\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions g on date(c.event_datetime) = date(g.event_date)\n",
    "    WHERE\n",
    "        c.ticket_type in ('Groups')\n",
    "        and tier in ('A','B','C','D','E')\n",
    "    AND\n",
    "        tier != 'PS'\n",
    "    GROUP BY\n",
    "        c.event_datetime, c.arena_level_internal, g.tier\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        g.season, c.event_date, tier, \n",
    "        case\n",
    "            when pc_one in ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') then 'Lowers'\n",
    "            when pc_one in ('K', 'L', 'M') then 'Clubs'\n",
    "            when pc_one in ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') then 'Uppers'\n",
    "            when pc_one in ('U', 'V', 'W') then 'Suites'\n",
    "            when pc_one in ('X', 'Z') then 'Premium'\n",
    "            else Null\n",
    "        end as arena_level_internal, sum(paid_seats) as \"num_seats\", sum(gross_revenue) as \"gross_revenue\", sum(gross_revenue)/sum(paid_seats) as \"current_ATP\"\n",
    "    FROM\n",
    "        custom.cth_historical_all_1718_2223 c\n",
    "    LEFT JOIN\n",
    "        custom.cth_game_descriptions g on date(c.event_date) = date(g.event_date)\n",
    "    WHERE\n",
    "        c.ticket_type in ('Groups')\n",
    "        and tier in ('A','B','C','D','E')\n",
    "        and g.season in ('2021-22','2022-23')\n",
    "    GROUP BY\n",
    "        c.event_date, arena_level_internal, g.tier, g.season\n",
    "    ORDER BY\n",
    "        event_date\n",
    "    \"\"\"\n",
    "\n",
    "    # get groups\n",
    "    df_groups = FLA_Redshift(**rs_creds).query_warehouse(sql_string = w)\n",
    "\n",
    "    return df_groups\n",
    "\n",
    "def transform_groups(df_groups):\n",
    "\n",
    "    # get groups\n",
    "    df_groups_historical = df_groups[df_groups['season'] != '2023-24']\n",
    "    df_groups_historical_agg = df_groups_historical.groupby(by = ['tier', 'arena_level_internal'])[['gross_revenue', 'num_seats']].sum()\n",
    "    df_groups_historical_agg = pd.DataFrame(df_groups_historical_agg).reset_index()\n",
    "    df_groups_historical_agg = df_groups_historical_agg.rename(columns = {'gross_revenue':'gross_revenue_avg', 'num_seats' : 'num_seats_avg'})\n",
    "    df_groups_historical_agg['gross_revenue_avg'] = df_groups_historical_agg['gross_revenue_avg']/41\n",
    "    df_groups_historical_agg['num_seats_avg'] = df_groups_historical_agg['num_seats_avg']/41\n",
    "    df_groups_historical_agg['atp_avg'] = df_groups_historical_agg['gross_revenue_avg']/df_groups_historical_agg['num_seats_avg']\n",
    "\n",
    "    # get percent revenue by game by location\n",
    "    loc_per = {'Suites' : 0.1821, 'Clubs' : 0.0851, 'Uppers' : 0.0571, 'Premium' : 0.2509, 'Lowers' : 0.4247}\n",
    "    loc_per = pd.DataFrame(data = [loc_per]).T\n",
    "    loc_per.columns = ['count_per_loc']\n",
    "    loc_per['arena_level_internal'] = loc_per.index\n",
    "\n",
    "    # get number of games by tier\n",
    "    num_tier = {'A' : 2, 'B' : 6, 'C' : 14, 'D' : 10, 'E' : 9}\n",
    "    num_tier = pd.DataFrame(data = [num_tier]).T\n",
    "    num_tier.columns = ['num_per_tier']\n",
    "    num_tier['tier'] = num_tier.index\n",
    "\n",
    "    df_groups_historical_agg = df_groups_historical_agg.merge(loc_per, how = 'left', on = 'arena_level_internal')\n",
    "    df_groups_historical_agg = df_groups_historical_agg.merge(num_tier, how = 'left', on = 'tier')\n",
    "    df_groups_historical_agg['total_percent_increase'] = .362147\n",
    "\n",
    "    df_groups_historical_agg['percent_increase'] = df_groups_historical_agg.apply(lambda row: (row['total_percent_increase']*row['count_per_loc'])/row['num_per_tier'], axis = 1)\n",
    "    df_groups_historical_agg['final_rev'] = df_groups_historical_agg['gross_revenue_avg'] + (df_groups_historical_agg['gross_revenue_avg']*df_groups_historical_agg['percent_increase'])\n",
    "    df_groups_historical_agg['projected_tickets'] = df_groups_historical_agg['final_rev']/df_groups_historical_agg['atp_avg']\n",
    "    df_groups_historical_agg= df_groups_historical_agg[['tier','arena_level_internal','projected_tickets']]\n",
    "\n",
    "    df_groups_2324 = df_groups[df_groups['season'] == '2023-24']\n",
    "\n",
    "    df_groups_2324 = df_groups_2324.merge(df_groups_historical_agg, how = 'left', on = ['tier', 'arena_level_internal'])\n",
    "\n",
    "    df_groups_2324 = df_groups_2324.groupby(by = 'event_date')[['projected_tickets']].sum()\n",
    "    df_groups_2324 = pd.DataFrame(df_groups_2324).reset_index()\n",
    "    df_groups_2324['type'] = 'groups'\n",
    "\n",
    "    return df_groups_2324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary\n",
    "\n",
    "def extract_secondary():\n",
    "    \n",
    "    t = \"\"\"\n",
    "        SELECT\n",
    "            season, date(c.event_datetime) as event_date, g.abbreviation, c.arena_level_internal,\n",
    "            g.tier, sum(paid_seats) as \"num_seats\", sum(gross_revenue) as \"gross_revenue\"\n",
    "        FROM\n",
    "            custom.cth_v_ticket_2324 c\n",
    "        LEFT JOIN\n",
    "            custom.cth_game_descriptions g ON date(c.event_datetime) = date(g.event_date)\n",
    "        WHERE\n",
    "            c.ticket_type = 'Secondary'\n",
    "            and g.tier in ('A','B','C','D','E')\n",
    "        GROUP BY\n",
    "            c.event_datetime, c.arena_level_internal, g.tier, g.abbreviation, season\n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            c.season, date(c.event_date) as event_date, g.abbreviation,\n",
    "            case\n",
    "                when pc_one in ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', '1', '2', '3', '4', '5', '6', '7', '8') then 'Lowers'\n",
    "                when pc_one in ('K', 'L', 'M') then 'Clubs'\n",
    "                when pc_one in ('N', 'O', 'P', 'Q', 'R', 'S', 'T', 'Y') then 'Uppers'\n",
    "                when pc_one in ('U', 'V', 'W') then 'Suites'\n",
    "                when pc_one in ('X', 'Z') then 'Premium'\n",
    "                else Null\n",
    "            end as arena_level_internal,\n",
    "            g.tier, sum(paid_seats) as \"num_seats\", sum(gross_revenue) as \"gross_revenue\"\n",
    "        FROM\n",
    "            custom.cth_historical_all_1718_2223 c\n",
    "        LEFT JOIN\n",
    "            custom.cth_game_descriptions g ON date(c.event_date) = date(g.event_date)\n",
    "        WHERE\n",
    "            c.ticket_type = 'Secondary'\n",
    "            and g.tier in ('A','B','C','D','E')\n",
    "            and c.season in ('2021-22','2022-23')\n",
    "        GROUP BY\n",
    "            c.event_date, arena_level_internal, g.tier, g.abbreviation, c.season\n",
    "        ORDER BY\n",
    "            event_date\n",
    "    \"\"\"\n",
    "\n",
    "    # extract secondary \n",
    "    df_secondary =FLA_Redshift(**rs_creds).query_warehouse(sql_string = t)\n",
    "    #df_secondary.rename(columns = {'gross_revenue' : 'current_secondary', 'location_specific': 'loc'}, inplace = True)\n",
    "\n",
    "    return df_secondary\n",
    "\n",
    "def transform_secondary(df_secondary):\n",
    "\n",
    "        # get groups\n",
    "    df_secondary_historical = df_secondary[df_secondary['season'] != '2023-24']\n",
    "    df_secondary_historical_agg = df_secondary_historical.groupby(by = ['tier', 'arena_level_internal'])[['gross_revenue', 'num_seats']].sum()\n",
    "    df_secondary_historical_agg = pd.DataFrame(df_secondary_historical_agg).reset_index()\n",
    "    df_secondary_historical_agg = df_secondary_historical_agg.rename(columns = {'gross_revenue':'gross_revenue_avg', 'num_seats' : 'num_seats_avg'})\n",
    "    df_secondary_historical_agg['gross_revenue_avg'] = df_secondary_historical_agg['gross_revenue_avg']/41\n",
    "    df_secondary_historical_agg['num_seats_avg'] = df_secondary_historical_agg['num_seats_avg']/41\n",
    "    df_secondary_historical_agg['atp_avg'] = df_secondary_historical_agg['gross_revenue_avg']/df_secondary_historical_agg['num_seats_avg']\n",
    "\n",
    "    # get percent revenue by game by location\n",
    "    loc_per = {'Suites' : 0.1821, 'Clubs' : 0.0851, 'Uppers' : 0.0571, 'Premium' : 0.2509, 'Lowers' : 0.4247}\n",
    "    loc_per = pd.DataFrame(data = [loc_per]).T\n",
    "    loc_per.columns = ['count_per_loc']\n",
    "    loc_per['arena_level_internal'] = loc_per.index\n",
    "\n",
    "    # get number of games by tier\n",
    "    num_tier = {'A' : 2, 'B' : 6, 'C' : 14, 'D' : 10, 'E' : 9}\n",
    "    num_tier = pd.DataFrame(data = [num_tier]).T\n",
    "    num_tier.columns = ['num_per_tier']\n",
    "    num_tier['tier'] = num_tier.index\n",
    "\n",
    "    df_secondary_historical_agg = df_secondary_historical_agg.merge(loc_per, how = 'left', on = 'arena_level_internal')\n",
    "    df_secondary_historical_agg = df_secondary_historical_agg.merge(num_tier, how = 'left', on = 'tier')\n",
    "    df_secondary_historical_agg['total_percent_increase'] = .15\n",
    "\n",
    "    df_secondary_historical_agg['percent_increase'] = df_secondary_historical_agg.apply(lambda row: (row['total_percent_increase']*row['count_per_loc'])/row['num_per_tier'], axis = 1)\n",
    "    df_secondary_historical_agg['final_rev'] = df_secondary_historical_agg['gross_revenue_avg'] + (df_secondary_historical_agg['gross_revenue_avg']*df_secondary_historical_agg['percent_increase'])\n",
    "    df_secondary_historical_agg['projected_tickets'] = df_secondary_historical_agg['final_rev']/df_secondary_historical_agg['atp_avg']\n",
    "    df_secondary_historical_agg= df_secondary_historical_agg[['tier','arena_level_internal','projected_tickets']]\n",
    "\n",
    "    df_groups_2324 = df_secondary[df_secondary['season'] == '2023-24']\n",
    "\n",
    "    df_groups_2324 = df_groups_2324.merge(df_secondary_historical_agg, how = 'left', on = ['tier', 'arena_level_internal'])\n",
    "\n",
    "    df_groups_2324 = df_groups_2324.groupby(by = 'event_date')[['projected_tickets']].sum()\n",
    "    df_groups_2324 = pd.DataFrame(df_groups_2324).reset_index()\n",
    "    df_groups_2324['type'] = 'secondary'\n",
    "\n",
    "    df_groups_2324['event_date'] = pd.to_datetime(df_groups_2324['event_date']).dt.normalize()\n",
    "    \n",
    "    return df_groups_2324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projected_tickets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-19</th>\n",
       "      <td>12715.559590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-21</th>\n",
       "      <td>12304.824996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-24</th>\n",
       "      <td>6317.049925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-28</th>\n",
       "      <td>12498.195805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>6857.952403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10</th>\n",
       "      <td>12501.244876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-12</th>\n",
       "      <td>13336.959448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-20</th>\n",
       "      <td>10727.057558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-22</th>\n",
       "      <td>13381.883543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>13258.246043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-02</th>\n",
       "      <td>13392.914731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>8274.919468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>13682.458760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>11924.808651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-23</th>\n",
       "      <td>14108.853938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>14743.548613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>13980.638159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>9271.153074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>14026.711960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>13453.418157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>11847.381450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>14125.342335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>9388.446341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-06</th>\n",
       "      <td>12928.011455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-08</th>\n",
       "      <td>14860.728659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-10</th>\n",
       "      <td>14960.360848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-20</th>\n",
       "      <td>11374.696080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-24</th>\n",
       "      <td>15337.553199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>10747.724217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>15601.403352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07</th>\n",
       "      <td>13488.338701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-09</th>\n",
       "      <td>15308.378395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-16</th>\n",
       "      <td>15471.357694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-21</th>\n",
       "      <td>12112.147412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>15828.453641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>13539.513684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-30</th>\n",
       "      <td>15925.201854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09</th>\n",
       "      <td>14159.998042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-11</th>\n",
       "      <td>11895.852995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-13</th>\n",
       "      <td>15613.370286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-16</th>\n",
       "      <td>16731.489141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            projected_tickets\n",
       "event_date                   \n",
       "2023-10-19       12715.559590\n",
       "2023-10-21       12304.824996\n",
       "2023-10-24        6317.049925\n",
       "2023-10-28       12498.195805\n",
       "2023-11-06        6857.952403\n",
       "2023-11-10       12501.244876\n",
       "2023-11-12       13336.959448\n",
       "2023-11-20       10727.057558\n",
       "2023-11-22       13381.883543\n",
       "2023-11-24       13258.246043\n",
       "2023-12-02       13392.914731\n",
       "2023-12-06        8274.919468\n",
       "2023-12-08       13682.458760\n",
       "2023-12-21       11924.808651\n",
       "2023-12-23       14108.853938\n",
       "2023-12-29       14743.548613\n",
       "2023-12-30       13980.638159\n",
       "2024-01-11        9271.153074\n",
       "2024-01-13       14026.711960\n",
       "2024-01-15       13453.418157\n",
       "2024-01-17       11847.381450\n",
       "2024-01-19       14125.342335\n",
       "2024-01-24        9388.446341\n",
       "2024-02-06       12928.011455\n",
       "2024-02-08       14860.728659\n",
       "2024-02-10       14960.360848\n",
       "2024-02-20       11374.696080\n",
       "2024-02-24       15337.553199\n",
       "2024-02-27       10747.724217\n",
       "2024-02-29       15601.403352\n",
       "2024-03-07       13488.338701\n",
       "2024-03-09       15308.378395\n",
       "2024-03-16       15471.357694\n",
       "2024-03-21       12112.147412\n",
       "2024-03-26       15828.453641\n",
       "2024-03-28       13539.513684\n",
       "2024-03-30       15925.201854\n",
       "2024-04-09       14159.998042\n",
       "2024-04-11       11895.852995\n",
       "2024-04-13       15613.370286\n",
       "2024-04-16       16731.489141"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat\n",
    "\n",
    "df_nightly = extract_nightly()\n",
    "df_nightly = transform_nightly(df_nightly)\n",
    "\n",
    "df_plans = extract_plans()\n",
    "df_plans = transform_plans(df_plans)\n",
    "\n",
    "df_groups = extract_groups()\n",
    "df_groups = transform_groups(df_groups)\n",
    "\n",
    "df_secondary = extract_secondary()\n",
    "df_secondary = transform_secondary(df_secondary)\n",
    "\n",
    "df_final = pd.concat([df_nightly, df_plans, df_groups, df_secondary], ignore_index = True, axis = 0)\n",
    "df_final.groupby(by = 'event_date')[['projected_tickets']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "with ticket_info as\n",
    "    (select event_date, sum(paid_seats) as paid_seats, sum(gross_revenue) as gross_revenue\n",
    "     from\n",
    "         custom.cth_historical_all_1718_2223\n",
    "     where\n",
    "         season in ('2021-22', '2022-23')\n",
    "     group by\n",
    "         event_date\n",
    "    UNION ALL\n",
    "    select date(event_datetime) as event_date, sum(paid_seats) as paid_seats, sum(gross_revenue) as gross_revenue\n",
    "     from\n",
    "         custom.cth_v_ticket_2324\n",
    "     group by\n",
    "         event_date)\n",
    "select\n",
    "    season, ticket_info.event_date,\n",
    "       case\n",
    "           when tier = 'A' then 1\n",
    "           when tier = 'B' then 2\n",
    "           when tier = 'C' then 3\n",
    "           when tier = 'D' then 4\n",
    "           else 5\n",
    "       end as tier_num,\n",
    "       case\n",
    "           when day_of_week in ('Fri', 'Sun') then 1\n",
    "           when day_of_week = 'Sat' then 2\n",
    "           else 0\n",
    "       end as day_of_week_num, original_six_plus_extra, trimester, is_holiday, is_dense,\n",
    "       sum(paid_seats) as paid_seats, sum(gross_revenue) as gross_revenue\n",
    "from\n",
    "    ticket_info\n",
    "left join\n",
    "        custom.cth_game_descriptions on date(ticket_info.event_date) = date(cth_game_descriptions.event_date)\n",
    "where\n",
    "    tier in ('A','B','C','D','E')\n",
    "group by\n",
    "    season, ticket_info.event_date, tier_num, day_of_week_num, original_six_plus_extra,\n",
    "    trimester, is_holiday, is_dense\n",
    "\"\"\"\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string = q)\n",
    "\n",
    "xtrain = df[df['season'].isin(['2021-22','2022-23'])]\n",
    "xtrain = xtrain[['tier_num', 'day_of_week_num', 'trimester', 'original_six_plus_extra', 'is_dense','is_holiday']]\n",
    "xtest_df = df[df['season'] == '2023-24'].reset_index(drop = True)\n",
    "xtest = xtest_df[['tier_num', 'day_of_week_num', 'trimester', 'original_six_plus_extra', 'is_dense','is_holiday']]\n",
    "ytrain = df[df['season'].isin(['2021-22','2022-23'])]\n",
    "ytrain = ytrain[['paid_seats']]\n",
    "ytrain = np.log1p(ytrain)\n",
    "\n",
    "svm = SVR(kernel= 'poly').fit(xtrain, np.array(ytrain).ravel())\n",
    "df2324_predicted = svm.predict(xtest)\n",
    "df2324_predicted = [np.expm1(i) for i in df2324_predicted]\n",
    "df2324_predicted = pd.DataFrame(df2324_predicted).reset_index(drop = True)\n",
    "xtest_df['predicted'] = df2324_predicted\n",
    "xtest_df[xtest['tier_num'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Predicted Attendance\n",
    "\n",
    "# mulitply projected tickets by historical show rate\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT \n",
    "        h.paid_seats, h.did_attend, h.event_date\n",
    "    FROM \n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE \n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.paid_seats != 0)\n",
    "\n",
    "SELECT \n",
    "    g.tier, sum(a.did_attend)/sum(a.paid_seats) as paid_rate\n",
    "FROM \n",
    "    a\n",
    "LEFT JOIN \n",
    "    custom.cth_game_descriptions g on date(a.event_date) = date(g.event_date)\n",
    "GROUP BY \n",
    "    tier\n",
    "ORDER BY \n",
    "    tier\"\"\"\n",
    "\n",
    "paid_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT\n",
    "        h.comp_seats, h.did_attend, h.event_date\n",
    "    FROM\n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE\n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.comp_seats != 0)\n",
    "\n",
    "SELECT\n",
    "    g.tier, sum(a.did_attend)/sum(a.comp_seats) as comp_rate\n",
    "FROM\n",
    "    a\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions g on date(a.event_date) = date(g.event_date)\n",
    "GROUP BY\n",
    "    tier\n",
    "ORDER BY\n",
    "    tier\"\"\"\n",
    "\n",
    "comp_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "attendance_df = paid_seats.merge(comp_seats, how = 'left', on = 'tier')\n",
    "\n",
    "final_attendance_df = predicted_df.merge(right = attendance_df, how = 'left', on = 'tier')\n",
    "final_attendance_df['predicted_attendance'] = [(w*x)+(y*z) for w,x,y,z, in zip(final_attendance_df['expected_final_paid_seats'],\n",
    "                                                              final_attendance_df['paid_rate'], final_attendance_df['expected_final_comp_seats'], final_attendance_df['comp_rate'])]\n",
    "just_attendance = final_attendance_df[['event_date', 'predicted_attendance', 'expected_final_gross_revenue', 'expected_final_seats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Predicted Parking\n",
    "\n",
    "# polynomial model (built by Pavan), multiply by avg atp to get rev\n",
    "\n",
    "q = \"\"\"\n",
    "WITH attendance as\n",
    "    (SELECT\n",
    "        '2022-23' as season, event_date, sum(entry) as attendance\n",
    "    FROM\n",
    "        custom.cth_attendance_scans_2223\n",
    "    GROUP BY\n",
    "        event_date\n",
    "    ORDER BY\n",
    "        event_date)\n",
    "\n",
    "SELECT\n",
    "    attendance.event_date, tier, coalesce(attendance,0) as ticket_scans,\n",
    "    coalesce(sum(paid_amount),0) as parking_paid_amount, count(*)-1 as num_parking_transactions\n",
    "FROM\n",
    "    attendance\n",
    "LEFT JOIN\n",
    "    custom.Parkhub_v_transactions on attendance.event_date = Parkhub_v_transactions.event_date\n",
    "LEFT JOIN\n",
    "    custom.cth_game_descriptions on attendance.event_date = cth_game_descriptions.event_date\n",
    "WHERE\n",
    "    attendance.event_date > '2022-10-01'\n",
    "    and tier in ('A','B','C','D','E')\n",
    "    and attendance.event_date != '2022-11-09'\n",
    "GROUP BY\n",
    "    attendance.event_date, tier, ticket_scans\n",
    "ORDER BY\n",
    "    attendance.event_date, tier\n",
    "\"\"\"\n",
    "\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "#Historical Parking Data Clean Up \n",
    "df['weekend'] = df.apply(lambda row: 1 if datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 5 \n",
    "    or datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 6 else 0, axis = 1)\n",
    "df['tier_num'] = df.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else \n",
    "    (2 if row['tier'] == 'D' else (1 if row['tier'] == 'E' else 0)))), axis = 1)\n",
    "\n",
    "#2023-2024 Season Data Clean Up \n",
    "q = \"\"\"\n",
    "select \n",
    "    event_date, tier, day_of_week\n",
    "from \n",
    "    custom.cth_game_descriptions\n",
    "where \n",
    "    season = '2023-24'\n",
    "\"\"\"\n",
    "\n",
    "games = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "games['weekend'] = games.apply(lambda row: 1 if row['day_of_week'] =='Fri' or row['day_of_week']=='Sat'  or row['day_of_week']=='Sun'  else 0 , axis=1)\n",
    "games['tier_num'] = games.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else \n",
    "    (2 if row['tier'] == 'D' else (1 if row['tier'] == 'E' else 0)))), axis = 1)\n",
    "games = games.merge(right = just_attendance, how = 'left', on = 'event_date')\n",
    "\n",
    "#Training Data \n",
    "xdf = df[['ticket_scans', 'weekend', 'tier_num']]\n",
    "y = df[['num_parking_transactions']]\n",
    "\n",
    "# #Test Data \n",
    "xdf2 = games[['predicted_attendance', 'weekend', 'tier_num']] ## GET PREDICTED ATTENDANCE FROM ABOVE CODE!\n",
    "\n",
    "#Scaling Data\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_features2 = poly.fit_transform(xdf2)\n",
    "poly_features = poly.fit_transform(xdf)\n",
    "\n",
    "polynomial = LinearRegression().fit(poly_features, np.array(y).ravel())\n",
    "predicted = polynomial.predict(poly_features2)\n",
    "\n",
    "games['predicted_parking'] = predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

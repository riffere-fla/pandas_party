{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from prefect.blocks.system import Secret\n",
    "from catnip.fla_redshift import FLA_Redshift\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# from fractions import Fraction\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from collections import Counter\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redshift_credentials() -> Dict:\n",
    "\n",
    "    cred_dict = {\n",
    "        \"dbname\": Secret.load(\"stellar-redshift-db-name\").get(),\n",
    "        \"host\": Secret.load(\"stellar-redshift-host\").get(),\n",
    "        \"port\": 5439,\n",
    "        \"user\": Secret.load(\"stellar-redshift-user-name\").get(),\n",
    "        \"password\": Secret.load(\"stellar-redshift-password\").get(),\n",
    "\n",
    "        \"aws_access_key_id\": Secret.load(\"fla-s3-aws-access-key-id-east-1\").get(),\n",
    "        \"aws_secret_access_key\": Secret.load(\"fla-s3-aws-secret-access-key-east-1\").get(),\n",
    "        \"bucket\": Secret.load(\"fla-s3-bucket-name-east-1\").get(),\n",
    "        \"subdirectory\": \"us-east-1\",\n",
    "\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    return cred_dict\n",
    "\n",
    "with ThreadPoolExecutor(1) as pool:\n",
    "    rs_creds = pool.submit(lambda: get_redshift_credentials()).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pricing - Dynamic Pricing Model\n",
    "\n",
    "# seperate file (pricing_model_v1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Predicted Budget\n",
    "\n",
    "# df = pd.read_excel(r\"C:\\\\Users\\\\riffere\\\\Desktop\\\\test_budget_by_ticket_by_game.xlsx\", sheet_name = 'sum_table')\n",
    "# df['key'] = 0\n",
    "\n",
    "# goal = 53000000\n",
    "\n",
    "# ticket_types = pd.DataFrame(\n",
    "#     {'ticket_type' : ['Annual Suites','Full','Premier', 'Flex & Quarter', 'Groups', 'Nightly Suites',\n",
    "#     'Secondary', 'Singles', 'Sponsor', 'Trade'], \n",
    "#     'ticket_percent' : [Fraction(5800000, goal), Fraction(22650000, goal), Fraction(6600000, goal),\n",
    "#     Fraction(1100000, goal), Fraction(3250000, goal), Fraction(2250000, goal), Fraction(5250000, goal),\n",
    "#     Fraction(4250000, goal), Fraction(1350000, goal), Fraction(500000, goal)]})\n",
    "# ticket_types['key'] = 0\n",
    "\n",
    "# df = df.merge(ticket_types, how = 'outer', on = 'key')\n",
    "\n",
    "# tier_percentage = pd.DataFrame({'tier' : ['AP','BP','CP','C','DP','D','E'],\n",
    "#                                 'Full' : [0.075, 0.175, 0.3, 0.05, 0.115, 0.115, 0.17], 'Premier': [0.10, 0.27, 0.46, 0, 0.17, 0, 0],\n",
    "#                                 'Annual Suites' : [0.08, 0.16, 0.291, 0.049, 0.115, 0.115, 0.19], 'Flex & Quarter' : [0.092, 0.22, 0.294, 0.064, 0.107, 0.08, 0.143],\n",
    "#                                 'Groups' : [0.10, 0.127, 0.255, 0.058, 0.10, 0.15, 0.21], 'Nightly Suites' : [0.088, 0.2, 0.284, 0.067, 0.122, 0.1, 0.139],\n",
    "#                                 'Secondary' : [0.09, 0.19, 0.325, 0.055, 0.12, 0.12, 0.10], 'Singles' : [0.083, 0.182, 0.264, 0.063, 0.084, 0.135, 0.189],\n",
    "#                                 'Sponsor' : [0.076, 0.181, 0.31, 0.051, 0.119, 0.114, 0.149], 'Trade' : [0.073, 0.161, 0.3, 0.053, 0.127, 0.116, 0.17]})\n",
    "\n",
    "\n",
    "# melt_tiers = tier_percentage.melt(id_vars = ['tier'], value_vars = ['Full', 'Annual Suites', 'Flex & Quarter', 'Groups', 'Premier',\n",
    "#                                                                     'Nightly Suites', 'Secondary', 'Singles', 'Sponsor', 'Trade'],\n",
    "#                                     var_name = 'ticket_type', value_name = 'tier_percent')\n",
    "\n",
    "# num_games = pd.DataFrame({'tier' : ['AP', 'BP', 'CP', 'C', 'DP', 'D', 'E'], 'num_games' : [2, 6, 12, 2, 5, 5, 10]})\n",
    "\n",
    "# df = df.merge(melt_tiers, how = 'left', on = ['tier','ticket_type'])\n",
    "# df = df.merge(num_games, how = 'left', on = 'tier')\n",
    "# df['goal'] = goal\n",
    "# df[df['event_date'] == '2024-03-07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predicted Revenue & Tickets\n",
    "\n",
    "# classification model for tickets then use avg (loc, ticket type, tier) atp for revenue\n",
    "\n",
    "# revenue pacing based on current ATP and days out based on historical numbers\n",
    "# q = \"\"\"\n",
    "# with a as\n",
    "#     (select \n",
    "#         cth_ticket_expanded_all.event_date, tier, cast(date_diff('day', cast(cth_ticket_expanded_all.event_date as date), getdate()) as int) as days_out, sum(block_purchase_price) as gross_rev,\n",
    "#         sum(paid_seats) as paid_seats,\n",
    "#         CASE\n",
    "#             when sum(paid_seats) = 0 then 0\n",
    "#             else gross_rev/sum(paid_seats)\n",
    "#         end as avg_atp\n",
    "#     from \n",
    "#         custom.cth_ticket_expanded_all\n",
    "#     left join \n",
    "#         custom.cth_game_descriptions \n",
    "#         on cth_ticket_expanded_all.event_date = cth_game_descriptions.event_date\n",
    "#     group by \n",
    "#         cth_ticket_expanded_all.event_date, tier)\n",
    "\n",
    "# select \n",
    "#     *\n",
    "# from \n",
    "#     a\n",
    "# left join \n",
    "#     custom.cth_expected_singles_012723\n",
    "#     on a.tier = cth_expected_singles_012723.tier\n",
    "#     and a.days_out = cth_expected_singles_012723.days_out\n",
    "# order by \n",
    "#     event_date\n",
    "# \"\"\"\n",
    "\n",
    "# df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier</th>\n",
       "      <th>location</th>\n",
       "      <th>paid_seats</th>\n",
       "      <th>did_attend</th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Clubs</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Corona</td>\n",
       "      <td>3</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Lounge 954</td>\n",
       "      <td>15</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Lowers</td>\n",
       "      <td>260</td>\n",
       "      <td>194.200000</td>\n",
       "      <td>0.744632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Suites</td>\n",
       "      <td>149</td>\n",
       "      <td>107.200000</td>\n",
       "      <td>0.716578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SC</td>\n",
       "      <td>Suites</td>\n",
       "      <td>171</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>0.669591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SC</td>\n",
       "      <td>Uppers</td>\n",
       "      <td>30</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>None</td>\n",
       "      <td>Lounge 954</td>\n",
       "      <td>150</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>None</td>\n",
       "      <td>Lowers</td>\n",
       "      <td>785</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>0.361783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>None</td>\n",
       "      <td>Suites</td>\n",
       "      <td>307</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.042345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tier    location  paid_seats  did_attend  ?column?\n",
       "0      A       Clubs           7    5.000000  0.675676\n",
       "1      A      Corona           3    2.333333  0.636364\n",
       "2      A  Lounge 954          15   12.400000  0.794872\n",
       "3      A      Lowers         260  194.200000  0.744632\n",
       "4      A      Suites         149  107.200000  0.716578\n",
       "..   ...         ...         ...         ...       ...\n",
       "63    SC      Suites         171  114.500000  0.669591\n",
       "64    SC      Uppers          30   22.000000  0.721311\n",
       "65  None  Lounge 954         150   76.000000  0.506667\n",
       "66  None      Lowers         785  284.000000  0.361783\n",
       "67  None      Suites         307   13.000000  0.042345\n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Predicted Attendance\n",
    "\n",
    "# mulitply projected tickets by historical show rate\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT \n",
    "        h.paid_seats, h.did_attend, h.event_date,\n",
    "        CASE\n",
    "        WHEN h.pc_one IN ('A','B','C','D','E','F','G','H','I','J','1','2','3','4','5','6','7','8') THEN 'Lowers'\n",
    "        WHEN h.pc_one IN ('K','L','M') THEN 'Clubs'\n",
    "        WHEN h.pc_one IN ('N','O','P','Q','R','S','T') THEN 'Uppers'\n",
    "        WHEN h.pc_one IN ('U','V','W') THEN 'Suites'\n",
    "        WHEN h.pc_one IN ('X') THEN 'Lounge 954'\n",
    "        WHEN h.pc_one IN ('Y') THEN 'Loft'\n",
    "        WHEN h.pc_one IN ('Z') THEN 'Corona'\n",
    "        END as \"location\"\n",
    "    FROM \n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE \n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.paid_seats != 0)\n",
    "\n",
    "SELECT \n",
    "    g.tier, a.location, sum(a.paid_seats)/count(distinct(a.event_date)) as paid_seats, sum(a.did_attend)/count(distinct(a.event_date)) as did_attend, \n",
    "    sum(a.did_attend)/sum(a.paid_seats)\n",
    "FROM \n",
    "    a\n",
    "LEFT JOIN \n",
    "    custom.cth_game_descriptions g on a.event_date = g.event_date\n",
    "GROUP BY \n",
    "    tier, location\n",
    "ORDER BY \n",
    "    tier, location\"\"\"\n",
    "\n",
    "paid_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "q = \"\"\"\n",
    "WITH a as\n",
    "    (SELECT \n",
    "        h.comp_seats, h.did_attend, h.event_date,\n",
    "        CASE\n",
    "        WHEN h.pc_one IN ('A','B','C','D','E','F','G','H','I','J','1','2','3','4','5','6','7','8') THEN 'Lowers'\n",
    "        WHEN h.pc_one IN ('K','L','M') THEN 'Clubs'\n",
    "        WHEN h.pc_one IN ('N','O','P','Q','R','S','T') THEN 'Uppers'\n",
    "        WHEN h.pc_one IN ('U','V','W') THEN 'Suites'\n",
    "        WHEN h.pc_one IN ('X') THEN 'Lounge 954'\n",
    "        WHEN h.pc_one IN ('Y') THEN 'Loft'\n",
    "        WHEN h.pc_one IN ('Z') THEN 'Corona'\n",
    "        END as \"location\"\n",
    "    FROM \n",
    "        custom.cth_historical_all_1718_2223 h\n",
    "    WHERE \n",
    "        h.season in ('2019-20', '2021-22', '2022-23')\n",
    "        and h.comp_seats != 0)\n",
    "\n",
    "SELECT \n",
    "    g.tier, a.location, sum(a.comp_seats)/count(distinct(a.event_date)) as comp_seats, sum(a.did_attend)/count(distinct(a.event_date)) as did_attend,\n",
    "    sum(a.did_attend)/sum(a.comp_seats)\n",
    "FROM \n",
    "    a\n",
    "LEFT JOIN \n",
    "    custom.cth_game_descriptions g on a.event_date = g.event_date\n",
    "GROUP BY \n",
    "    tier, location\n",
    "ORDER BY \n",
    "    tier, location\"\"\"\n",
    "\n",
    "comp_seats = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "comp_seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['predicted_attendance'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m y \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mnum_parking_transactions\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     68\u001b[0m \u001b[39m#Test Data \u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m xdf2 \u001b[39m=\u001b[39m games[[\u001b[39m'\u001b[39;49m\u001b[39mpredicted_attendance\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mweekend\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtier_num\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m     71\u001b[0m \u001b[39m#Scaling Data\u001b[39;00m\n\u001b[0;32m     72\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(degree\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, include_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\riffere\\Documents\\pandas_party\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['predicted_attendance'] not in index\""
     ]
    }
   ],
   "source": [
    "# 5. Predicted Parking\n",
    "\n",
    "# polynomial model (built by Pavan), multiply by avg atp to get rev\n",
    "\n",
    "q = \"\"\"\n",
    "WITH attendance as\n",
    "    (SELECT \n",
    "        season, event_date, sum(did_attend) as attendance\n",
    "    FROM \n",
    "        custom.cth_historical_all_1718_2122\n",
    "    GROUP BY \n",
    "        event_date, season\n",
    "    UNION\n",
    "    SELECT \n",
    "        '2021-22' as season, event_date, sum(num_seats) as attendance\n",
    "    FROM \n",
    "        custom.cth_playoffs_2122_expanded\n",
    "    GROUP BY \n",
    "        event_date\n",
    "    UNION\n",
    "    SELECT \n",
    "        '2022-23' as season, event_date, sum(entry) as attendance\n",
    "    FROM \n",
    "        custom.cth_attendance_scans_2223\n",
    "    GROUP BY \n",
    "        event_date\n",
    "    ORDER BY \n",
    "        event_date)\n",
    "\n",
    "SELECT \n",
    "    attendance.event_date, tier, coalesce(attendance,0) as ticket_scans, \n",
    "    coalesce(sum(paid_amount),0) as parking_paid_amount, count(*)-1 as num_parking_transactions\n",
    "FROM \n",
    "    attendance\n",
    "LEFT JOIN \n",
    "    custom.parkhub_reporting on attendance.event_date = parkhub_reporting.event_date\n",
    "LEFT JOIN \n",
    "    custom.cth_game_descriptions on attendance.event_date = cth_game_descriptions.event_date\n",
    "    --and df.time_bucket = attendance.action_time_bucket\n",
    "WHERE \n",
    "    attendance.event_date > '2022-10-01'\n",
    "    and event_time != ''\n",
    "    and tier in ('A','B','C','D','E')\n",
    "    and attendance.event_date != '2022-11-09'\n",
    "GROUP BY \n",
    "    attendance.event_date, tier, ticket_scans\n",
    "ORDER BY \n",
    "    attendance.event_date, tier\n",
    "\"\"\"\n",
    "\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "\n",
    "#Historical Parking Data Clean Up \n",
    "df['weekend'] = df.apply(lambda row: 1 if datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 5 \n",
    "    or datetime.weekday(datetime.strptime(row['event_date'], '%Y-%m-%d').date()) == 6 else 0, axis = 1)\n",
    "df['tier_num'] = df.apply(lambda row: 5 if row['tier'] == 'A' else (4 if row['tier'] == 'B' else (3 if row['tier'] == 'C' else \n",
    "    (2 if row['tier'] == 'D' else (1 if row['tier'] == 'E' else 0)))), axis = 1)\n",
    "\n",
    "#2023-2024 Season Data Clean Up \n",
    "games['weekend'] = games.apply(lambda row: 1 if row['dow']=='Sat'  or row['dow']=='Sun'  else 0 , axis=1)\n",
    "games['tier_num'] = games.apply(lambda row: 5 if row['Tier'] == 'A' else (4 if row['Tier'] == 'B' else (3 if row['Tier'] == 'C' else \n",
    "    (2 if row['Tier'] == 'D' else (1 if row['Tier'] == 'E' else 0)))), axis = 1)\n",
    "\n",
    "#Training Data \n",
    "xdf = df[['ticket_scans', 'weekend', 'tier_num']]\n",
    "y = df[['num_parking_transactions']]\n",
    "\n",
    "#Test Data \n",
    "xdf2 = games[['predicted_attendance', 'weekend', 'tier_num']] ## GET PREDICTED ATTENDANCE FROM ABOVE CODE!\n",
    "\n",
    "#Scaling Data\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_features2 = poly.fit_transform(xdf2)\n",
    "poly_features = poly.fit_transform(xdf)\n",
    "\n",
    "polynomial = LinearRegression().fit(poly_features, np.array(y).ravel())\n",
    "predicted = polynomial.predict(poly_features2)\n",
    "\n",
    "games['predicted_parking'] = predicted\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tier</th>\n",
       "      <th>weekday</th>\n",
       "      <th>fandb_percap</th>\n",
       "      <th>merch_percap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.555028</td>\n",
       "      <td>8.385843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.790659</td>\n",
       "      <td>6.055374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.230363</td>\n",
       "      <td>6.952212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.042488</td>\n",
       "      <td>6.211725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.146634</td>\n",
       "      <td>10.892860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.954689</td>\n",
       "      <td>9.780764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.085917</td>\n",
       "      <td>11.192126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.765611</td>\n",
       "      <td>12.363794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.559875</td>\n",
       "      <td>8.635926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.958902</td>\n",
       "      <td>12.266062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.867214</td>\n",
       "      <td>10.775684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.399441</td>\n",
       "      <td>8.278479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.369433</td>\n",
       "      <td>9.572137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.974840</td>\n",
       "      <td>10.480682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.318036</td>\n",
       "      <td>9.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.830444</td>\n",
       "      <td>9.404347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.367596</td>\n",
       "      <td>8.257433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.942891</td>\n",
       "      <td>10.989102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.917610</td>\n",
       "      <td>11.591733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.092543</td>\n",
       "      <td>6.601149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.646437</td>\n",
       "      <td>8.120306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.616015</td>\n",
       "      <td>13.928631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.088187</td>\n",
       "      <td>12.331874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.089343</td>\n",
       "      <td>16.445586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.783678</td>\n",
       "      <td>19.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.883997</td>\n",
       "      <td>10.270747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.913613</td>\n",
       "      <td>31.093106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SC</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.277272</td>\n",
       "      <td>37.428859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tier  weekday  fandb_percap  merch_percap\n",
       "0     A      4.0     22.555028      8.385843\n",
       "1     A      6.0     29.790659      6.055374\n",
       "2     B      0.0     24.230363      6.952212\n",
       "3     B      4.0     25.042488      6.211725\n",
       "4     B      5.0     29.146634     10.892860\n",
       "5     B      6.0     27.954689      9.780764\n",
       "6     C      1.0     26.085917     11.192126\n",
       "7     C      3.0     27.765611     12.363794\n",
       "8     C      4.0     25.559875      8.635926\n",
       "9     C      6.0     24.958902     12.266062\n",
       "10    D      0.0     22.867214     10.775684\n",
       "11    D      2.0     25.399441      8.278479\n",
       "12    D      3.0     25.369433      9.572137\n",
       "13    D      4.0     26.974840     10.480682\n",
       "14    D      5.0     26.318036      9.514300\n",
       "15    E      1.0     20.830444      9.404347\n",
       "16    E      2.0     23.367596      8.257433\n",
       "17    E      3.0     26.942891     10.989102\n",
       "18    E      4.0     24.917610     11.591733\n",
       "19   P1      0.0     35.092543      6.601149\n",
       "20   P1      5.0     37.646437      8.120306\n",
       "21   P2      0.0     40.616015     13.928631\n",
       "22   P2      3.0     38.088187     12.331874\n",
       "23   P3      1.0     39.089343     16.445586\n",
       "24   P3      3.0     42.783678     19.441961\n",
       "25   PS      4.0     20.883997     10.270747\n",
       "26   SC      4.0     52.913613     31.093106\n",
       "27   SC      6.0     50.277272     37.428859"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Predicted F&B & Merch\n",
    "\n",
    "# avg F&B & Merch per caps by tier (add DOW for drink deals and stuff, simply regression model)\n",
    "\n",
    "q = \"\"\"\n",
    "with a as\n",
    "    (select bypass_orderitems_2223.event_date, sum(line_item_gross_revenue) as fandb_rev\n",
    "    from custom.bypass_orderitems_2223\n",
    "    where event_type = 'Hockey'\n",
    "    group by bypass_orderitems_2223.event_date\n",
    "    order by bypass_orderitems_2223.event_date),\n",
    "b as\n",
    "    (select event_date, sum(entry) as entry\n",
    "     from custom.cth_attendance_scans_2223\n",
    "     group by event_date\n",
    "     UNION\n",
    "     select event_date, sum(entry) as entry\n",
    "     from custom.cth_attendance_scans_playoffs_2223\n",
    "     group by event_date),\n",
    "c as\n",
    "    (select event_date, sum(line_item_gross_revenue) as merch_rev\n",
    "     from custom.retailpro_invoice_items\n",
    "     group by event_date),\n",
    "\n",
    "temp as\n",
    "    (select a.event_date, date_part('dw',cast(a.event_date as date)) as weekday, tier, fandb_rev, entry, merch_rev, fandb_rev/entry as fandb_percap, merch_rev/entry as merch_percap\n",
    "    from a\n",
    "    left join b on a.event_date = b.event_date\n",
    "    left join c on a.event_date = c.event_date\n",
    "    left join custom.cth_game_descriptions on a.event_date = cth_game_descriptions.event_date\n",
    "    where a.event_date not like '2022-11-15')\n",
    "\n",
    "select tier, weekday, avg(fandb_percap) as fandb_percap, avg(merch_percap) as merch_percap\n",
    "from temp\n",
    "group by tier, weekday\n",
    "order by tier, weekday\n",
    "\"\"\"\n",
    "\n",
    "df = FLA_Redshift(**rs_creds).query_warehouse(sql_string=q)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. All-in-total\n",
    "\n",
    "# ticket+parking+f&b+merch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
